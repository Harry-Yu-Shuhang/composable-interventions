Bootstrap: docker
From: nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04

%labels
    Author Yushuhang
    Description Container for lm-compose with CUDA 11.8 + PyTorch 2.3 + GPTQ/AWQ support

%environment
    export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
    export TRANSFORMERS_CACHE=/workspace/hf_cache
    export HF_HOME=/workspace/hf_cache
    export CUDA_HOME=/usr/local/cuda
    export PATH=/opt/conda/bin:$PATH
    export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
    export TORCH_CUDA_ARCH_LIST="7.5;8.0;8.6;8.9"

%post
    # 基础依赖
    apt-get update && apt-get install -y \
        git build-essential wget curl vim \
        ca-certificates libglib2.0-0 libsm6 libxrender1 libxext6 \
        libssl-dev libffi-dev libstdc++6 cmake ninja-build \
        && apt-get clean

    # 检查 CUDA 编译器
    if ! command -v nvcc &> /dev/null; then
        echo "⚠️ Warning: nvcc not found in PATH. Please ensure CUDA is usable at runtime." >&2
    else
        echo "✅ nvcc detected: $(which nvcc)"
    fi

    # 安装 Conda
    wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh
    bash miniconda.sh -b -p /opt/conda && rm miniconda.sh
    export PATH=/opt/conda/bin:$PATH

    # 创建 Conda 环境并安装依赖
    /opt/conda/bin/conda create -n lm-compose python=3.11 -y
    /opt/conda/bin/conda run -n lm-compose pip install --no-cache-dir \
        torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 \
        --index-url https://download.pytorch.org/whl/cu118
    /opt/conda/bin/conda run -n lm-compose pip install -U pip setuptools wheel
    /opt/conda/bin/conda run -n lm-compose pip install \
        pandas numpy "huggingface_hub[cli]" transformers accelerate gekko packaging==24.0

    # 克隆主项目（延迟安装 AutoGPTQ/AWQ）
    mkdir -p /workspace && cd /workspace
    git clone https://github.com/Harry-Yu-Shuhang/composable-interventions.git lm-compose
    cd lm-compose
    /opt/conda/bin/conda run -n lm-compose pip install -e .

%runscript
    echo "✅ 容器启动成功！当前目录: $(pwd)"

    source /opt/conda/etc/profile.d/conda.sh
    conda activate lm-compose

    export TORCH_CUDA_ARCH_LIST="7.5;8.0;8.6;8.9"


    # 安装 AutoGPTQ（如未安装）
    if ! python -c "import auto_gptq" 2>/dev/null; then
        echo "📦 安装 AutoGPTQ..."
        cd /workspace/lm-compose/AutoGPTQ
        pip install -e . || echo "❌ AutoGPTQ 安装失败，请检查 CUDA 与编译器配置"
    fi

    # 安装 AutoAWQ（如未安装）
    if ! python -c "import awq" 2>/dev/null; then
        echo "📦 安装 AutoAWQ..."
        cd /workspace/lm-compose/AutoAWQ
        pip install -e .
    fi

    exec "$@"
