#!/bin/bash
#SBATCH --partition=3090_risk
#SBATCH --nodelist=aisurrey15
#SBATCH --job-name=gptq_deepseek
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --gpus-per-node=1
#SBATCH --cpus-per-task=8
#SBATCH --time=12:00:00
#SBATCH --mem=64G
#SBATCH --output=output.log
#SBATCH --error=error.log

set -e

echo "ðŸ” ä»»åŠ¡å¼€å§‹ï¼Œå½“å‰ç›®å½•: $(pwd)" > output.log
cd "$SLURM_SUBMIT_DIR" || { echo "âŒ ç›®å½•ä¸å­˜åœ¨ï¼Œé€€å‡º"; exit 1; }
echo "ðŸ“Œ è¿›å…¥ç›®å½•: $SLURM_SUBMIT_DIR" >> output.log

# ========== Conda åˆå§‹åŒ–å¹¶é‡å»ºçŽ¯å¢ƒ ==========
echo "ðŸ” Conda åˆå§‹åŒ–å¹¶é‡å»ºçŽ¯å¢ƒ: lm-compose" >> output.log
source /mnt/fast/nobackup/users/ly0008/miniconda3/etc/profile.d/conda.sh
eval "$(conda shell.bash hook)"

if conda info --envs | grep -q "lm-compose"; then
    conda remove -n lm-compose --all -y >> output.log 2>> error.log
fi

conda create -n lm-compose python=3.11 -y >> output.log 2>> error.log
conda activate lm-compose || { echo "âŒ conda æ¿€æ´»å¤±è´¥" >> output.log; exit 1; }

# ========== CUDA æ¨¡å—åŠ è½½ï¼ˆå¿…é¡»æ”¾æœ€å‰ï¼‰==========
echo "ðŸ§ª åˆå§‹åŒ– CUDA æ¨¡å—..." >> output.log
module purge
if [ -f /etc/profile.d/modules.sh ]; then
    source /etc/profile.d/modules.sh || echo "âš ï¸ source modules.sh å¤±è´¥" >> output.log
fi
module load cuda/11.8 && echo "âœ… CUDA æ¨¡å—åŠ è½½æˆåŠŸ" >> output.log || echo "âš ï¸ CUDA æ¨¡å—åŠ è½½å¤±è´¥" >> output.log

# ========== CUDA_HOME å¼ºåˆ¶è®¾ç½® ==========
export CUDA_HOME=/vol/cuda/11.8
export PATH=$CUDA_HOME/bin:$CONDA_PREFIX/bin:$PATH
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$CONDA_PREFIX/lib:$LD_LIBRARY_PATH
export PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True"
echo "âœ… å¼ºåˆ¶è®¾ç½® CUDA_HOME ä¸º: $CUDA_HOME" >> output.log

# ========== Debug CUDA ==========
echo "ðŸ“Œ PATH: $PATH" >> output.log
echo "ðŸ“Œ LD_LIBRARY_PATH: $LD_LIBRARY_PATH" >> output.log
echo "ðŸ“Œ nvcc è·¯å¾„: $(which nvcc)" >> output.log
ls -l $(which nvcc) >> output.log 2>> error.log || echo "âš ï¸ nvcc è·¯å¾„æ— æ•ˆ" >> output.log
nvcc --version >> output.log 2>> error.log || echo "âš ï¸ nvcc æ— æ³•æ‰§è¡Œ" >> output.log

# ========== çŽ¯å¢ƒå˜é‡ Debug ==========
echo "ðŸ“Œ PATH: $PATH" >> output.log
echo "ðŸ“Œ LD_LIBRARY_PATH: $LD_LIBRARY_PATH" >> output.log
echo "ðŸ“Œ nvcc è·¯å¾„: $(which nvcc)" >> output.log
nvcc --version >> output.log 2>> error.log || echo "âš ï¸ nvcc æ— æ³•æ‰§è¡Œ" >> output.log
echo "ðŸ“Œ Python: $(which python)" >> output.log
python --version >> output.log

# ========== å®‰è£…ä¾èµ– ==========
conda install -c conda-forge gcc gxx_linux-64 libstdcxx-ng cmake ninja -y >> output.log 2>> error.log

export CXX=$(which x86_64-conda-linux-gnu-g++)
if ! command -v g++ &> /dev/null; then
    ln -sf "$CXX" "$CONDA_PREFIX/bin/g++"
    echo "ðŸ”— g++ è½¯é“¾æŽ¥å·²åˆ›å»º: $CXX" >> output.log
else
    echo "âœ… g++ å·²å­˜åœ¨: $(which g++)" >> output.log
fi
g++ --version >> output.log 2>> error.log

pip install pandas gekko numpy transformers accelerate >> output.log 2>> error.log

# ========== å®‰è£… PyTorch ==========
echo "ðŸ“¦ å®‰è£… PyTorch 2.3.0 + CUDA 11.8" >> output.log
pip install --no-cache-dir --force-reinstall \
  torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 \
  --index-url https://download.pytorch.org/whl/cu118 \
  --extra-index-url https://pypi.org/simple >> output.log 2>> error.log

python -c 'import torch; print("Torch:", torch.__version__, "CUDA OK:", torch.cuda.is_available(), "Device:", torch.cuda.get_device_name(0) if torch.cuda.is_available() else "N/A")' >> output.log 2>> error.log || {
    echo "âŒ PyTorch å¯¼å…¥å¤±è´¥ï¼Œé€€å‡º" >> output.log
    exit 1
}

# ========== å®‰è£… AutoGPTQ å’Œé¡¹ç›® ==========
pip install -e AutoGPTQ >> output.log 2>> error.log || { echo "âŒ å®‰è£… AutoGPTQ å¤±è´¥" >> output.log; exit 1; }
pip install -e AutoAWQ >> output.log 2>> error.log || { echo "âŒ å®‰è£… AutoAWQ å¤±è´¥" >> output.log; exit 1; }
pip install -e . >> output.log 2>> error.log || { echo "âŒ å®‰è£…å½“å‰é¡¹ç›®å¤±è´¥" >> output.log; exit 1; }

# ========== æ¨¡åž‹æ£€æŸ¥ ==========
MODEL_DIR="models/deepseek-math-7b-instruct"
if [ ! -d "$MODEL_DIR" ]; then
    echo "âŒ æ¨¡åž‹ç›®å½•ä¸å­˜åœ¨: $MODEL_DIR" >> output.log
    echo "ðŸ“¥ è¯·å…ˆè¿è¡Œ huggingface-cli ä¸‹è½½æ¨¡åž‹" >> output.log
    exit 1
fi

# ========== GPTQ åŽ‹ç¼© ==========
echo "ðŸ“¦ å¼€å§‹ GPTQ åŽ‹ç¼©ä»»åŠ¡..." >> output.log
python main.py \
    model_name=$MODEL_DIR \
    interventions=[compress] \
    compress=gptq \
    wbits=4 \
    output_dir=compressed_models/deepseek-math-7b-gptq >> output.log 2>> error.log

echo "âœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼" >> output.log
