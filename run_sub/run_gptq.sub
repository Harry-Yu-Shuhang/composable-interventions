#!/bin/bash
#SBATCH --partition=3090_risk
#SBATCH --nodelist=aisurrey15
#SBATCH --job-name=gptq_deepseek
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --gpus-per-node=1
#SBATCH --cpus-per-task=8
#SBATCH --time=12:00:00
#SBATCH --mem=64G
#SBATCH --output=output.log
#SBATCH --error=error.log

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

echo "ðŸ” ä»»åŠ¡å¼€å§‹ï¼Œå½“å‰ç›®å½•: $(pwd)" > output.log
cd "$SLURM_SUBMIT_DIR" || { echo "âŒ ç›®å½•ä¸å­˜åœ¨ï¼Œé€€å‡º"; exit 1; }
echo "ðŸ“Œ è¿›å…¥ç›®å½•: $SLURM_SUBMIT_DIR" >> output.log

export PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True"

# === åŠ è½½æ¨¡å—ç³»ç»Ÿå’Œ CUDA/GCC ===
if [ -f /etc/profile.d/modules.sh ]; then
    source /etc/profile.d/modules.sh
fi

module load gcc/12.2.0
module load cuda/11.8
echo "âœ… åŠ è½½ CUDA å’Œ GCC" >> output.log

# === æ£€æŸ¥ g++ å¯ç”¨æ€§ ===
export CXX=$(which g++) || { echo "âŒ g++ æœªæ‰¾åˆ°ï¼ŒGCC æ¨¡å—æœªæ­£ç¡®åŠ è½½" >> output.log; exit 1; }

# === æ£€æŸ¥ GPU ä¿¡æ¯ ===
echo "ðŸ” GPU è®¾å¤‡ä¿¡æ¯ï¼š" >> output.log
nvidia-smi >> output.log 2>> error.log || echo "âš ï¸ GPU æ£€æµ‹å¤±è´¥" >> output.log

# === Conda çŽ¯å¢ƒå¤„ç†ï¼ˆå¼ºåˆ¶åˆ é™¤é‡å»ºï¼‰===
echo "ðŸ” é‡å»º conda çŽ¯å¢ƒ: lm-compose" >> output.log
source ~/.bashrc

# å¦‚æžœçŽ¯å¢ƒå·²å­˜åœ¨åˆ™åˆ é™¤
if conda info --envs | grep -q "lm-compose"; then
    echo "ðŸ§¹ åˆ é™¤å·²æœ‰çŽ¯å¢ƒ 'lm-compose'..." >> output.log
    conda remove -n lm-compose --all -y >> output.log 2>> error.log
fi

# åˆ›å»ºæ–°çŽ¯å¢ƒ
echo "âš™ï¸ åˆ›å»º conda çŽ¯å¢ƒ 'lm-compose'..." >> output.log
conda create -n lm-compose python=3.11 -y >> output.log 2>> error.log

echo "ðŸš€ æ¿€æ´» conda çŽ¯å¢ƒ" >> output.log
conda activate lm-compose || { echo "âŒ æ¿€æ´»å¤±è´¥" >> output.log; exit 1; }


# === çŽ¯å¢ƒå˜é‡è®¾ç½® ===
export CUDA_HOME=/usr/local/cuda
export PATH=$CUDA_HOME/bin:$PATH
export LD_LIBRARY_PATH=$CONDA_PREFIX/lib:$CUDA_HOME/lib64:$LD_LIBRARY_PATH

# === å®‰è£…ä¾èµ– ===
echo "ðŸ“¦ å®‰è£…ä¾èµ–ï¼ˆconda å’Œ pipï¼‰..." >> output.log
conda install -c conda-forge libstdcxx-ng gxx_linux-64 cmake ninja -y >> output.log 2>> error.log

which pip || { echo "âŒ pip ä¸å¯ç”¨ï¼Œé€€å‡º" >> output.log; exit 1; }

pip install pandas gekko numpy transformers accelerate >> output.log 2>> error.log

# === å®‰è£…é¡¹ç›®å’Œæ’ä»¶ ===
pip install -e . >> output.log 2>> error.log
pip install -e AutoGPTQ || { echo "âŒ å®‰è£… AutoGPTQ å¤±è´¥" >> output.log; exit 1; }
pip install -e AutoAWQ || { echo "âŒ å®‰è£… AutoAWQ å¤±è´¥" >> output.log; exit 1; }

# === CUDA æ‰©å±•æ£€æŸ¥ ===
python -c "from auto_gptq.utils.import_utils import is_cuda_extension_available as check; print('âœ… AutoGPTQ + CUDA Extension OK' if check() else 'âŒ CUDA Extension Missing')" >> output.log 2>> error.log

# === æ¨¡åž‹æ£€æŸ¥ ===
MODEL_DIR="models/deepseek-math-7b-instruct"
if [ ! -d "$MODEL_DIR" ]; then
    echo "âŒ æ¨¡åž‹ç›®å½•ä¸å­˜åœ¨: $MODEL_DIR" >> output.log
    echo "è¯·å…ˆè¿è¡Œï¼šhuggingface-cli download deepseek-ai/deepseek-math-7b-instruct --local-dir $MODEL_DIR --local-dir-use-symlinks False" >> output.log
    exit 1
fi

# === æ‰§è¡Œ GPTQ åŽ‹ç¼© ===
echo "ðŸ“¦ å¼€å§‹ GPTQ åŽ‹ç¼©..." >> output.log
python main.py \
    model_name=$MODEL_DIR \
    interventions=[compress] \
    compress=gptq \
    wbits=4 \
    output_dir=compressed_models/deepseek-math-7b-gptq >> output.log 2>> error.log

echo "âœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆ" >> output.log
