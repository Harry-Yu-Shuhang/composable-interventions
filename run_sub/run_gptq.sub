#!/bin/bash
#SBATCH --partition=3090_risk
#SBATCH --nodelist=aisurrey15
#SBATCH --job-name=gptq_deepseek
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --gpus-per-node=1
#SBATCH --cpus-per-task=8
#SBATCH --time=12:00:00
#SBATCH --mem=64G
#SBATCH --output=output.log
#SBATCH --error=error.log

set -e

echo "ðŸ” ä»»åŠ¡å¼€å§‹ï¼Œå½“å‰ç›®å½•: $(pwd)" > output.log
cd "$SLURM_SUBMIT_DIR" || { echo "âŒ ç›®å½•ä¸å­˜åœ¨ï¼Œé€€å‡º"; exit 1; }
echo "ðŸ“Œ è¿›å…¥ç›®å½•: $SLURM_SUBMIT_DIR" >> output.log

export PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True"

# === Conda çŽ¯å¢ƒå¤„ç† ===
echo "ðŸ” é‡å»º conda çŽ¯å¢ƒ: lm-compose" >> output.log
source /mnt/fast/nobackup/users/ly0008/miniconda3/etc/profile.d/conda.sh

if conda info --envs | grep -q "lm-compose"; then
    echo "ðŸ§¹ åˆ é™¤å·²æœ‰çŽ¯å¢ƒ 'lm-compose'..." >> output.log
    conda remove -n lm-compose --all -y >> output.log 2>> error.log
fi

echo "âš™ï¸ åˆ›å»º conda çŽ¯å¢ƒ 'lm-compose'..." >> output.log
conda create -n lm-compose python=3.11 -y >> output.log 2>> error.log
eval "$(conda shell.bash hook)"
conda activate lm-compose || { echo "âŒ æ¿€æ´» conda çŽ¯å¢ƒå¤±è´¥" >> output.log; exit 1; }

# å°è¯• module åŠ è½½ CUDA
if [ -f /etc/profile.d/modules.sh ]; then
    source /etc/profile.d/modules.sh || true
fi
module load cuda/11.8 || true
echo "âœ… å°è¯•åŠ è½½ CUDA æ¨¡å—" >> output.log

# è‡ªåŠ¨æˆ–æ‰‹åŠ¨è®¾ç½® CUDA_HOME
if command -v nvcc &> /dev/null; then
    export CUDA_HOME=$(dirname $(dirname $(which nvcc)))
    echo "âœ… CUDA_HOME è‡ªåŠ¨è®¾ç½®ä¸º: $CUDA_HOME" >> output.log
elif [ -d /usr/local/cuda-11.8 ]; then
    export CUDA_HOME=/usr/local/cuda-11.8
    echo "âš ï¸ æ‰‹åŠ¨ fallback è®¾ç½® CUDA_HOME ä¸º: $CUDA_HOME" >> output.log
else
    echo "âŒ æœªæ‰¾åˆ° nvccï¼Œä¸”é»˜è®¤è·¯å¾„æ— æ•ˆï¼Œé€€å‡º..." >> output.log
    exit 1
fi

# çŽ¯å¢ƒè·¯å¾„é…ç½®
export PATH=$CUDA_HOME/bin:$CONDA_PREFIX/bin:$PATH
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$CONDA_PREFIX/lib:$LD_LIBRARY_PATH

# === å®‰è£…ç¼–è¯‘å·¥å…·é“¾ ===
conda install -c conda-forge gcc gxx_linux-64 libstdcxx-ng cmake ninja -y >> output.log 2>> error.log

# è®¾ç½® g++ çŽ¯å¢ƒå˜é‡å’Œè½¯é“¾æŽ¥ï¼ˆé¿å…é‡å¤ï¼‰
export CXX=$(which x86_64-conda-linux-gnu-g++)
if ! command -v g++ &> /dev/null; then
    ln -sf "$CXX" "$CONDA_PREFIX/bin/g++"
    echo "ðŸ”— å·²åˆ›å»º g++ è½¯é“¾æŽ¥åˆ° $CXX" >> output.log
else
    echo "âœ… å·²å­˜åœ¨ g++ï¼Œè·³è¿‡è½¯é“¾æŽ¥åˆ›å»º" >> output.log
fi

# æ£€æŸ¥ g++
echo "ðŸ” g++ è·¯å¾„: $(which g++)" >> output.log
g++ --version >> output.log 2>> error.log

# === å®‰è£… Python é€šç”¨ä¾èµ– ===
pip install pandas gekko numpy transformers accelerate || exit 1

# === å®‰è£… PyTorchï¼ˆå¿…é¡»åœ¨ AutoGPTQ å‰ï¼‰===
echo "ðŸ“¦ å®‰è£… PyTorch 2.3.0 + CUDA 11.8..." >> output.log
pip install --no-cache-dir --force-reinstall \
  torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 \
  --index-url https://download.pytorch.org/whl/cu118 \
  --extra-index-url https://pypi.org/simple || { echo "âŒ å®‰è£… PyTorch å¤±è´¥"; exit 1; }

if ! command -v nvcc &> /dev/null; then
    echo "âŒ nvcc ä¸å­˜åœ¨ï¼ŒAutoGPTQ ç¼–è¯‘ä¼šå¤±è´¥ï¼" >> output.log
    exit 1
else
    echo "âœ… nvcc è·¯å¾„: $(which nvcc)" >> output.log
fi


# === å®‰è£… AutoGPTQ å’Œæ’ä»¶ ===
pip install -e AutoGPTQ || { echo "âŒ å®‰è£… AutoGPTQ å¤±è´¥" >> output.log; exit 1; }
pip install -e AutoAWQ || { echo "âŒ å®‰è£… AutoAWQ å¤±è´¥" >> output.log; exit 1; }

# === å®‰è£…å½“å‰é¡¹ç›®æœ¬èº« ===
pip install -e . || { echo "âŒ å®‰è£…å½“å‰é¡¹ç›®å¤±è´¥" >> output.log; exit 1; }

# === æ¨¡åž‹è·¯å¾„æ£€æŸ¥ ===
MODEL_DIR="models/deepseek-math-7b-instruct"
if [ ! -d "$MODEL_DIR" ]; then
    echo "âŒ æ¨¡åž‹ç›®å½•ä¸å­˜åœ¨: $MODEL_DIR" >> output.log
    echo "ðŸ“¥ è¯·å…ˆè¿è¡Œ huggingface-cli ä¸‹è½½æ¨¡åž‹åˆ°è¯¥ç›®å½•" >> output.log
    exit 1
fi

# === æ‰§è¡Œ GPTQ åŽ‹ç¼© ===
echo "ðŸ“¦ å¼€å§‹æ‰§è¡Œ GPTQ åŽ‹ç¼©ä»»åŠ¡..." >> output.log
python main.py \
    model_name=$MODEL_DIR \
    interventions=[compress] \
    compress=gptq \
    wbits=4 \
    output_dir=compressed_models/deepseek-math-7b-gptq >> output.log 2>> error.log

echo "âœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼" >> output.log
