#!/bin/bash
#SBATCH --partition=3090_risk
#SBATCH --nodelist=aisurrey15
#SBATCH --job-name=gptq_deepseek
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --gpus-per-node=1
#SBATCH --cpus-per-task=8
#SBATCH --time=12:00:00
#SBATCH --mem=64G
#SBATCH --output=output.log
#SBATCH --error=error.log

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

echo "ðŸ” ä»»åŠ¡å¼€å§‹ï¼Œå½“å‰ç›®å½•: $(pwd)" > output.log
cd "$SLURM_SUBMIT_DIR" || { echo "âŒ ç›®å½•ä¸å­˜åœ¨ï¼Œé€€å‡º"; exit 1; }
echo "ðŸ“Œ è¿›å…¥ç›®å½•: $SLURM_SUBMIT_DIR" >> output.log

export PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True"

# === Conda çŽ¯å¢ƒå¤„ç† ===
echo "ðŸ” é‡å»º conda çŽ¯å¢ƒ: lm-compose" >> output.log
source /mnt/fast/nobackup/users/ly0008/miniconda3/etc/profile.d/conda.sh

if conda info --envs | grep -q "lm-compose"; then
    echo "ðŸ§¹ åˆ é™¤å·²æœ‰çŽ¯å¢ƒ 'lm-compose'..." >> output.log
    conda remove -n lm-compose --all -y >> output.log 2>> error.log
fi

echo "âš™ï¸ åˆ›å»º conda çŽ¯å¢ƒ 'lm-compose'..." >> output.log
conda create -n lm-compose python=3.11 -y >> output.log 2>> error.log
conda activate lm-compose || { echo "âŒ æ¿€æ´» conda çŽ¯å¢ƒå¤±è´¥" >> output.log; exit 1; }

# === åŠ è½½ CUDA æ¨¡å— ===
if [ -f /etc/profile.d/modules.sh ]; then
    source /etc/profile.d/modules.sh || true
fi
module load cuda/11.8 || true
echo "âœ… å°è¯•åŠ è½½ CUDA æ¨¡å—" >> output.log

# === å®‰è£…ç¼–è¯‘å·¥å…·é“¾ ===
conda install -c conda-forge gcc gxx_linux-64 libstdcxx-ng cmake ninja -y >> output.log 2>> error.log

# è®¾ç½® g++ çŽ¯å¢ƒå˜é‡å’Œè½¯é“¾æŽ¥ï¼ˆé¿å…é‡å¤ï¼‰
export CXX=$(which x86_64-conda-linux-gnu-g++)
if ! command -v g++ &> /dev/null; then
    ln -sf "$CXX" "$CONDA_PREFIX/bin/g++"
    echo "ðŸ”— å·²åˆ›å»º g++ è½¯é“¾æŽ¥åˆ° $CXX" >> output.log
else
    echo "âœ… å·²å­˜åœ¨ g++ï¼Œè·³è¿‡è½¯é“¾æŽ¥åˆ›å»º" >> output.log
fi

# === çŽ¯å¢ƒå˜é‡è®¾ç½® ===
export CUDA_HOME=/usr/local/cuda
export PATH=$CONDA_PREFIX/bin:$CUDA_HOME/bin:$PATH
export LD_LIBRARY_PATH=$CONDA_PREFIX/lib:$CUDA_HOME/lib64:$LD_LIBRARY_PATH

# æ£€æŸ¥ g++
echo "ðŸ” g++ è·¯å¾„: $(which g++)" >> output.log
g++ --version >> output.log 2>> error.log

# === å®‰è£… Python é€šç”¨ä¾èµ– ===
pip install pandas gekko numpy transformers accelerate || exit 1

# === å®‰è£… PyTorchï¼ˆå¿…é¡»åœ¨ AutoGPTQ å‰ï¼‰===
echo "ðŸ“¦ å®‰è£… PyTorch 2.3.0 + CUDA 11.8..." >> output.log
pip install --no-cache-dir --force-reinstall \
  torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 \
  --index-url https://download.pytorch.org/whl/cu118 \
  --extra-index-url https://pypi.org/simple || { echo "âŒ å®‰è£… PyTorch å¤±è´¥"; exit 1; }

# === å®‰è£… AutoGPTQ å’Œæ’ä»¶ ===
pip install -e AutoGPTQ || { echo "âŒ å®‰è£… AutoGPTQ å¤±è´¥" >> output.log; exit 1; }
pip install -e AutoAWQ || { echo "âŒ å®‰è£… AutoAWQ å¤±è´¥" >> output.log; exit 1; }

# === å®‰è£…å½“å‰é¡¹ç›®æœ¬èº« ===
pip install -e . || { echo "âŒ å®‰è£…å½“å‰é¡¹ç›®å¤±è´¥" >> output.log; exit 1; }


# === æ¨¡åž‹è·¯å¾„æ£€æŸ¥ ===
MODEL_DIR="models/deepseek-math-7b-instruct"
if [ ! -d "$MODEL_DIR" ]; then
    echo "âŒ æ¨¡åž‹ç›®å½•ä¸å­˜åœ¨: $MODEL_DIR" >> output.log
    echo "ðŸ“¥ è¯·å…ˆè¿è¡Œ huggingface-cli ä¸‹è½½æ¨¡åž‹åˆ°è¯¥ç›®å½•" >> output.log
    exit 1
fi

# === æ‰§è¡Œ GPTQ åŽ‹ç¼© ===
echo "ðŸ“¦ å¼€å§‹æ‰§è¡Œ GPTQ åŽ‹ç¼©ä»»åŠ¡..." >> output.log
python main.py \
    model_name=$MODEL_DIR \
    interventions=[compress] \
    compress=gptq \
    wbits=4 \
    output_dir=compressed_models/deepseek-math-7b-gptq >> output.log 2>> error.log

echo "âœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼" >> output.log
