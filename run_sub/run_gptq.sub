#!/bin/bash
#SBATCH --partition=3090_risk
#SBATCH --nodelist=aisurrey15
#SBATCH --job-name=gptq_deepseek
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --gpus-per-node=1
#SBATCH --cpus-per-task=8
#SBATCH --time=12:00:00
#SBATCH --mem=64G
#SBATCH --output=output.log
#SBATCH --error=error.log

set -e  # 遇到错误立即退出

echo "🔍 任务开始，当前目录: $(pwd)" > output.log
cd "$SLURM_SUBMIT_DIR" || { echo "❌ 目录不存在，退出"; exit 1; }
echo "📌 进入目录: $SLURM_SUBMIT_DIR" >> output.log

export PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True"

# === Conda 环境处理（强制删除重建）===
echo "🔁 重建 conda 环境: lm-compose" >> output.log
source /mnt/fast/nobackup/users/ly0008/miniconda3/etc/profile.d/conda.sh

if conda info --envs | grep -q "lm-compose"; then
    echo "🧹 删除已有环境 'lm-compose'..." >> output.log
    conda remove -n lm-compose --all -y >> output.log 2>> error.log
fi

echo "⚙️ 创建 conda 环境 'lm-compose' 并安装 gcc..." >> output.log
conda create -n lm-compose python=3.11 -y >> output.log 2>> error.log
conda activate lm-compose || { echo "❌ 激活失败" >> output.log; exit 1; }

# 加载 CUDA 模块
if [ -f /etc/profile.d/modules.sh ]; then
    source /etc/profile.d/modules.sh
fi
module load cuda/11.8
echo "✅ 已加载 CUDA 模块" >> output.log

# 安装编译工具链
conda install -c conda-forge gcc gxx_linux-64 libstdcxx-ng cmake ninja -y >> output.log 2>> error.log

# 设置 g++ 环境变量和软链接（避免重复）
export CXX=$(which x86_64-conda-linux-gnu-g++)
if ! command -v g++ &> /dev/null; then
    ln -sf "$CXX" "$CONDA_PREFIX/bin/g++"
    echo "🔗 已创建 g++ 软链接到 $CXX" >> output.log
else
    echo "✅ 已存在 g++，跳过软链接创建" >> output.log
fi

# === 环境变量设置 ===
export CUDA_HOME=/usr/local/cuda
export PATH=$CONDA_PREFIX/bin:$CUDA_HOME/bin:$PATH
export LD_LIBRARY_PATH=$CONDA_PREFIX/lib:$CUDA_HOME/lib64:$LD_LIBRARY_PATH

# 检查 g++ 是否可用
echo "🔍 g++ 路径: $(which g++)" >> output.log
g++ --version >> output.log 2>> error.log

# === 安装 Python 依赖 ===
echo "📦 安装 Python 依赖..." >> output.log
pip install pandas gekko numpy transformers accelerate >> output.log 2>> error.log

# === 安装项目和插件 ===
pip install -e . >> output.log 2>> error.log
pip install -e AutoGPTQ --config-settings editable_mode=compat || { echo "❌ 安装 AutoGPTQ 失败" >> output.log; exit 1; }
pip install -e AutoAWQ || { echo "❌ 安装 AutoAWQ 失败" >> output.log; exit 1; }

# === CUDA 扩展检查 ===
python -c "from auto_gptq.utils.import_utils import is_cuda_extension_available as check; print('✅ AutoGPTQ + CUDA Extension OK' if check() else '❌ CUDA Extension Missing')" >> output.log 2>> error.log

# === 模型检查 ===
MODEL_DIR="models/deepseek-math-7b-instruct"
if [ ! -d "$MODEL_DIR" ]; then
    echo "❌ 模型目录不存在: $MODEL_DIR" >> output.log
    echo "请先运行：huggingface-cli download deepseek-ai/deepseek-math-7b-instruct --local-dir $MODEL_DIR --local-dir-use-symlinks False" >> output.log
    exit 1
fi

# === 执行 GPTQ 压缩 ===
echo "📦 开始 GPTQ 压缩..." >> output.log
python main.py \
    model_name=$MODEL_DIR \
    interventions=[compress] \
    compress=gptq \
    wbits=4 \
    output_dir=compressed_models/deepseek-math-7b-gptq >> output.log 2>> error.log

echo "✅ 所有任务完成" >> output.log
