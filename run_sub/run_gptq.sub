#!/bin/bash

#SBATCH --partition=3090_risk
#SBATCH --nodelist=aisurrey15
#SBATCH --job-name=gptq_deepseek
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --gpus-per-node=1
#SBATCH --cpus-per-task=8
#SBATCH --time=12:00:00
#SBATCH --mem=64G
#SBATCH --output=output.log
#SBATCH --error=error.log

echo "🔍 任务开始，当前目录: $(pwd)" > output.log
cd "$SLURM_SUBMIT_DIR" || { echo "❌ 目录不存在，退出"; exit 1; }
echo "📌 进入目录: $SLURM_SUBMIT_DIR" >> output.log

export PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True"

# === 加载模块系统和 CUDA ===
if [ -f /etc/profile.d/modules.sh ]; then
    source /etc/profile.d/modules.sh
fi

AVAILABLE_CUDA=$(module spider cuda 2>&1 | grep -Eo 'cuda/11\.8' | tail -n1)
if [[ -n "$AVAILABLE_CUDA" ]]; then
    module load "$AVAILABLE_CUDA"
    echo "✅ 加载 CUDA: $AVAILABLE_CUDA" >> output.log
else
    echo "⚠️ 找不到 CUDA 11.8" >> output.log
fi

# === 检查 GPU ===
echo "🔍 GPU 设备信息：" >> output.log
nvidia-smi >> output.log 2>> error.log || echo "⚠️ GPU 检测失败" >> output.log

# === Conda 环境判断 ===
echo "🔍 检查是否已有 conda 环境: lm-compose" >> output.log
source ~/.bashrc

if ! conda info --envs | grep -q "lm-compose"; then
    echo "⚙️ 创建 conda 环境 'lm-compose'..." >> output.log
    conda create -n lm-compose python=3.11 -y >> output.log 2>> error.log
fi

echo "🚀 激活 conda 环境" >> output.log
conda activate lm-compose || { echo "❌ 激活失败" >> output.log; exit 1; }

# === 环境变量设置 ===
export CUDA_HOME=/usr/local/cuda
export PATH=$CUDA_HOME/bin:$PATH
export LD_LIBRARY_PATH=$CONDA_PREFIX/lib:$CUDA_HOME/lib64:$LD_LIBRARY_PATH

# === 安装依赖包和编译工具 ===
echo "📦 安装依赖..." >> output.log
conda install -c conda-forge libstdcxx-ng gxx_linux-64 cmake ninja -y >> output.log 2>> error.log
pip install pandas gekko numpy transformers accelerate >> output.log 2>> error.log

# === 安装项目和插件 ===
pip install -e . >> output.log 2>> error.log
pip install -e AutoGPTQ >> output.log 2>> error.log
pip install -e AutoAWQ >> output.log 2>> error.log

# === 编译 AutoGPTQ CUDA 扩展（必要）===
python AutoGPTQ/setup_cuda.py install >> output.log 2>> error.log
python -c "from auto_gptq.utils.import_utils import is_cuda_extension_available as check; print('✅ CUDA Extension OK' if check() else '❌ CUDA Extension Missing')" >> output.log

# === 检查模型路径 ===
MODEL_DIR="models/deepseek-math-7b-instruct"
if [ ! -d "$MODEL_DIR" ]; then
    echo "❌ 模型目录不存在: $MODEL_DIR" >> output.log
    echo "请先运行：huggingface-cli download deepseek-ai/deepseek-math-7b-instruct --local-dir $MODEL_DIR --local-dir-use-symlinks False" >> output.log
    exit 1
fi

# === 执行 GPTQ 压缩 ===
echo "📦 开始 GPTQ 压缩..." >> output.log
python main.py \
    model_name=$MODEL_DIR \
    interventions=[compress] \
    compress=gptq \
    wbits=4 \
    output_dir=compressed_models/deepseek-math-7b-gptq >> output.log 2>> error.log

echo "✅ 所有任务完成" >> output.log