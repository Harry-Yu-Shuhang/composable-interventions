defaults:
  - edit: ft  # Choose any of [memit, lora, ft]
  - compression: wanda  # Choose any of [wanda, sparsegpt, gptq, awq]
  - unlearn: none  # Choose any of [cut]
  - _self_

model_name: meta-llama/Meta-Llama-3-8B
#meta-llama/Meta-Llama-3-8B
#meta-llama/Llama-2-7b-chat-hf
dtype: torch.bfloat16
device: 0
model_parallel: true
seed: 0
tag: "default"
wandb: disabled # disabled or online
interventions: []  # List of interventions, choose any number of [edit, compress, unlearn]

alg_name: FT # overwritten by edit config but needs to be here
edit_dataset: "zsre"
stats_dir: "/scratch/sux7mp/stats"
max_length: 30
batch_size: 50

save: out/
save_model: null
eval_zero_shot: false
compress: false
method: none
sparsity_ratio: 0.0
compression_dataset: c4
dataset: c4

number_of_edits: 50
edit_set: 50

load_ckpt: False
ckpt_path: /scratch/sux7mp/saved_models/checkpoint_20231221_113020.pth
save_ckpt: True