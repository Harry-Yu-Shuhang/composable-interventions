{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import ast\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import wandb\n",
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting_columns = [\n",
    "    # Overall\n",
    "    \"tag\",\n",
    "    # \"seed\",\n",
    "    \"_timestamp\",\n",
    "\n",
    "    # Interventions\n",
    "    \"interventions\", \"edit\", \"unlearn\", \"compression\", \"model_name\",\n",
    "\n",
    "    # Editing\n",
    "    # \"edit_set\", \n",
    "    \"edit_dataset\", \"number_of_edits\",\n",
    "\n",
    "    # Unlearning\n",
    "    \"rmu_layer_id\",\n",
    "\n",
    "    # Compression\n",
    "    \"wbits\", \"compression_dataset\", \"sparsity_ratio\",\n",
    "]\n",
    "evaluation_columns = [\n",
    "    \"qa_question_count_limit\",  # An artifical max number of questions to ask during evaluation. Should be none when not debugging.\n",
    "    \"mmlu accuracy\",            # The accuracy of the model on the MMLU dataset. This measures overall model utility. Llama-3 should be ~62%\n",
    "    \"wmdp_bio accuracy\",        # The accuracy of the model on the WMDP bio split. This is the unlearning target. Should be ~25% when RMU is applied.\n",
    "    \"wmdp_cyber accuracy\",      # The accuracy of the model on the WMDP cyber split. This is the unlearning target. Should be ~25% when RMU is applied.\n",
    "    \"PPL\",                      # TODO:\n",
    "    \"PPL edits\",                # Perplexity for the edits. Should be low when editing is applied.\n",
    "    \"PPl QA\",                   # Perplexity for the QA. Should be low when QA is applied.\n",
    "    \"Generalization\",           # TODO: \n",
    "    \"FLOPs\",                    # TODO: \n",
    "    \"Success recall\",           # TODO:\n",
    "    \"Generalization recall\",    # TODO:\n",
    "    \"Locality\",                 # TODO:\n",
    "    \"Average bits\",             # TODO:\n",
    "    \"Rewrite accuracy\",         # TODO:\n",
    "    \"PPl edits unmasked\",       # TODO:\n",
    "    \"Local recall\",             # TODO:\n",
    "    \"Latency\",                  # TODO:\n",
    "]\n",
    "relevant_columns = setting_columns + evaluation_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/Composable_Interventions: 100%|██████████| 303/303 [00:02<00:00, 148.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing run n0iel6ok: '_timestamp'\n",
      "Error processing run xr5mede5: '_timestamp'\n",
      "Error processing run 27f8pxs0: '_timestamp'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace 'username/project_name' with your specific project path\n",
    "# Composable_Interventions\n",
    "project_paths = [\n",
    "    'dri-ice/Composable_Interventions',\n",
    "    # 'dri-ice/AK_Tests'\n",
    "]\n",
    "\n",
    "filter_dict = { \n",
    "    \"state\": \"finished\",\n",
    "    # \"created_at\": {\"$gte\": \"2024-05-20\"}\n",
    "}\n",
    "data_frames = []\n",
    "for project_path in project_paths:\n",
    "    runs = api.runs(project_path, filters=filter_dict)\n",
    "    \n",
    "    # Iterate over eachrun and capture the config and summary metrics\n",
    "    for run in tqdm(runs, desc=project_path):\n",
    "        try:\n",
    "            run_start_datetime = datetime.fromtimestamp(run.summary_metrics[\"_timestamp\"])\n",
    "            start_cutoff = datetime.strptime(\"2024-05-18 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "            end_cutoff = datetime.strptime(\"2024-05-23 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "            if run_start_datetime < start_cutoff or run_start_datetime > end_cutoff:\n",
    "                continue\n",
    "\n",
    "            skip_tags = [\"test\", \"hparam_search\"]\n",
    "            should_skip = False\n",
    "            for tag in skip_tags:\n",
    "                if tag in run.config[\"tag\"].lower():\n",
    "                    should_skip = True\n",
    "            \n",
    "            if should_skip:\n",
    "                continue\n",
    "\n",
    "            config_frame = pd.DataFrame([run.config])\n",
    "            summary_frame = pd.DataFrame([run.summary_metrics])\n",
    "            combined_frame = pd.concat([config_frame, summary_frame], axis=1)\n",
    "            data_frames.append(combined_frame)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing run {run.id}: {e}\")\n",
    "\n",
    "# Sort by 'tag' and '_timestamp' in descending order to have the most recent run first\n",
    "all_runs_df = pd.concat(data_frames, ignore_index=True)[relevant_columns]\n",
    "all_runs_df[\"interventions\"] = all_runs_df[\"interventions\"].astype(str)\n",
    "\n",
    "# WARNING: WHAT DOES EDIT SET 50 MEAN COMPARED TO EDIT SET 1?\n",
    "# all_runs_df = all_runs_df[all_runs_df[\"edit_set\"] == 50]\n",
    "# all_runs_df_sorted = all_runs_df.sort_values(by=['tag', '_timestamp'], ascending=[True, False])\n",
    "all_runs_df[\"date\"] = pd.to_datetime(all_runs_df[\"_timestamp\"], unit='s')\n",
    "all_runs_df_sorted = all_runs_df.sort_values(by=['_timestamp'], ascending=[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>_timestamp</th>\n",
       "      <th>interventions</th>\n",
       "      <th>edit</th>\n",
       "      <th>unlearn</th>\n",
       "      <th>compression</th>\n",
       "      <th>model_name</th>\n",
       "      <th>edit_dataset</th>\n",
       "      <th>number_of_edits</th>\n",
       "      <th>rmu_layer_id</th>\n",
       "      <th>...</th>\n",
       "      <th>FLOPs</th>\n",
       "      <th>Success recall</th>\n",
       "      <th>Generalization recall</th>\n",
       "      <th>Locality</th>\n",
       "      <th>Average bits</th>\n",
       "      <th>Rewrite accuracy</th>\n",
       "      <th>PPl edits unmasked</th>\n",
       "      <th>Local recall</th>\n",
       "      <th>Latency</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rmu-none</td>\n",
       "      <td>1.716351e+09</td>\n",
       "      <td>['unlearn']</td>\n",
       "      <td>none</td>\n",
       "      <td>rmu</td>\n",
       "      <td>none</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.92 TFLOPS</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>0.020667</td>\n",
       "      <td>0.027140</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>5.251807e+02</td>\n",
       "      <td>0.027449</td>\n",
       "      <td>96.211963</td>\n",
       "      <td>2024-05-22 04:14:27.846383810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AWQ8bit-to-lora</td>\n",
       "      <td>1.716351e+09</td>\n",
       "      <td>['compress', 'edit']</td>\n",
       "      <td>lora</td>\n",
       "      <td>none</td>\n",
       "      <td>awq</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.052772</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.393250e+04</td>\n",
       "      <td>0.052387</td>\n",
       "      <td>515.406013</td>\n",
       "      <td>2024-05-22 04:10:40.129939795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AWQ2bit-to-lora</td>\n",
       "      <td>1.716351e+09</td>\n",
       "      <td>['compress', 'edit']</td>\n",
       "      <td>lora</td>\n",
       "      <td>none</td>\n",
       "      <td>awq</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.070556</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.089636</td>\n",
       "      <td>7.574332e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>519.011764</td>\n",
       "      <td>2024-05-22 04:05:45.239004850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AWQ4bit-to-lora</td>\n",
       "      <td>1.716351e+09</td>\n",
       "      <td>['compress', 'edit']</td>\n",
       "      <td>lora</td>\n",
       "      <td>none</td>\n",
       "      <td>awq</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.085162</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.342348e+04</td>\n",
       "      <td>0.085194</td>\n",
       "      <td>519.676339</td>\n",
       "      <td>2024-05-22 04:05:43.669849396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ft-rmu</td>\n",
       "      <td>1.716351e+09</td>\n",
       "      <td>['edit', 'unlearn']</td>\n",
       "      <td>ft</td>\n",
       "      <td>rmu</td>\n",
       "      <td>none</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.92 TFLOPS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.784444</td>\n",
       "      <td>0.114612</td>\n",
       "      <td>15.999968</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.431615e+02</td>\n",
       "      <td>0.114261</td>\n",
       "      <td>101.909465</td>\n",
       "      <td>2024-05-22 04:04:48.395482302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Compress_AWQ2bit</td>\n",
       "      <td>1.716224e+09</td>\n",
       "      <td>['compress']</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>awq</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.020036e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>87.598504</td>\n",
       "      <td>2024-05-20 16:59:38.218446016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>Compress_AWQ8bit</td>\n",
       "      <td>1.716224e+09</td>\n",
       "      <td>['compress']</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>awq</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.030760</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>4.443523e+02</td>\n",
       "      <td>0.030682</td>\n",
       "      <td>88.839530</td>\n",
       "      <td>2024-05-20 16:59:32.776091576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Compress_AWQ4bit</td>\n",
       "      <td>1.716224e+09</td>\n",
       "      <td>['compress']</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>awq</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.012381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030575</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>4.668763e+02</td>\n",
       "      <td>0.029872</td>\n",
       "      <td>87.954436</td>\n",
       "      <td>2024-05-20 16:59:29.555692434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Compress_AWQ2bit</td>\n",
       "      <td>1.716224e+09</td>\n",
       "      <td>['compress']</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>awq</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.020036e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>87.735735</td>\n",
       "      <td>2024-05-20 16:58:04.464708805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Compress_AWQ8bit</td>\n",
       "      <td>1.716224e+09</td>\n",
       "      <td>['compress']</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>awq</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.030760</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>4.443523e+02</td>\n",
       "      <td>0.030682</td>\n",
       "      <td>86.592992</td>\n",
       "      <td>2024-05-20 16:56:57.587842226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  tag    _timestamp         interventions  edit unlearn  \\\n",
       "0            rmu-none  1.716351e+09           ['unlearn']  none     rmu   \n",
       "11    AWQ8bit-to-lora  1.716351e+09  ['compress', 'edit']  lora    none   \n",
       "13    AWQ2bit-to-lora  1.716351e+09  ['compress', 'edit']  lora    none   \n",
       "12    AWQ4bit-to-lora  1.716351e+09  ['compress', 'edit']  lora    none   \n",
       "2              ft-rmu  1.716351e+09   ['edit', 'unlearn']    ft     rmu   \n",
       "..                ...           ...                   ...   ...     ...   \n",
       "290  Compress_AWQ2bit  1.716224e+09          ['compress']  none    none   \n",
       "281  Compress_AWQ8bit  1.716224e+09          ['compress']  none    none   \n",
       "280  Compress_AWQ4bit  1.716224e+09          ['compress']  none    none   \n",
       "278  Compress_AWQ2bit  1.716224e+09          ['compress']  none    none   \n",
       "294  Compress_AWQ8bit  1.716224e+09          ['compress']  none    none   \n",
       "\n",
       "    compression                  model_name edit_dataset  number_of_edits  \\\n",
       "0          none  meta-llama/Meta-Llama-3-8B         zsre               50   \n",
       "11          awq  meta-llama/Meta-Llama-3-8B         zsre               50   \n",
       "13          awq  meta-llama/Meta-Llama-3-8B         zsre               50   \n",
       "12          awq  meta-llama/Meta-Llama-3-8B         zsre               50   \n",
       "2          none  meta-llama/Meta-Llama-3-8B         zsre               50   \n",
       "..          ...                         ...          ...              ...   \n",
       "290         awq  meta-llama/Meta-Llama-3-8B         zsre               50   \n",
       "281         awq  meta-llama/Meta-Llama-3-8B         zsre               50   \n",
       "280         awq  meta-llama/Meta-Llama-3-8B         zsre               50   \n",
       "278         awq  meta-llama/Meta-Llama-3-8B         zsre               50   \n",
       "294         awq  meta-llama/Meta-Llama-3-8B         zsre               50   \n",
       "\n",
       "     rmu_layer_id  ...        FLOPs Success recall  Generalization recall  \\\n",
       "0             3.0  ...  1.92 TFLOPS       0.008889               0.020667   \n",
       "11           -1.0  ...           -1       1.000000               0.630000   \n",
       "13           -1.0  ...           -1       0.070556               0.040000   \n",
       "12           -1.0  ...           -1       1.000000               0.750000   \n",
       "2             5.0  ...  1.92 TFLOPS       1.000000               0.784444   \n",
       "..            ...  ...          ...            ...                    ...   \n",
       "290           NaN  ...           -1       0.000000               0.000000   \n",
       "281           NaN  ...           -1       0.006667               0.010000   \n",
       "280           NaN  ...           -1       0.012381               0.000000   \n",
       "278           NaN  ...           -1       0.000000               0.000000   \n",
       "294           NaN  ...           -1       0.006667               0.010000   \n",
       "\n",
       "     Locality  Average bits  Rewrite accuracy  PPl edits unmasked  \\\n",
       "0    0.027140     16.000000          0.008889        5.251807e+02   \n",
       "11   0.052772      8.250000          1.000000        1.393250e+04   \n",
       "13   0.000000      2.250000          0.089636        7.574332e+04   \n",
       "12   0.085162      4.250000          1.000000        1.342348e+04   \n",
       "2    0.114612     15.999968          1.000000        6.431615e+02   \n",
       "..        ...           ...               ...                 ...   \n",
       "290  0.000000      2.250000          0.000000        1.020036e+06   \n",
       "281  0.030760      8.250000          0.006667        4.443523e+02   \n",
       "280  0.030575      4.250000          0.012821        4.668763e+02   \n",
       "278  0.000000      2.250000          0.000000        1.020036e+06   \n",
       "294  0.030760      8.250000          0.006667        4.443523e+02   \n",
       "\n",
       "     Local recall     Latency                          date  \n",
       "0        0.027449   96.211963 2024-05-22 04:14:27.846383810  \n",
       "11       0.052387  515.406013 2024-05-22 04:10:40.129939795  \n",
       "13       0.000000  519.011764 2024-05-22 04:05:45.239004850  \n",
       "12       0.085194  519.676339 2024-05-22 04:05:43.669849396  \n",
       "2        0.114261  101.909465 2024-05-22 04:04:48.395482302  \n",
       "..            ...         ...                           ...  \n",
       "290      0.000000   87.598504 2024-05-20 16:59:38.218446016  \n",
       "281      0.030682   88.839530 2024-05-20 16:59:32.776091576  \n",
       "280      0.029872   87.954436 2024-05-20 16:59:29.555692434  \n",
       "278      0.000000   87.735735 2024-05-20 16:58:04.464708805  \n",
       "294      0.030682   86.592992 2024-05-20 16:56:57.587842226  \n",
       "\n",
       "[300 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_runs_df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_139302/4290825372.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_runs_df_deduplicated[\"interventions\"] = all_runs_df_deduplicated[\"interventions\"].apply(lambda x : ast.literal_eval(x))\n",
      "/tmp/ipykernel_139302/4290825372.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metrics[\"model_name\"] = metrics[\"model_name\"].apply(lambda x : rename_dict.get(x, None))\n",
      "/tmp/ipykernel_139302/4290825372.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metrics[\"edit\"] = metrics[\"edit\"].apply(lambda x : rename_dict.get(x, None))\n",
      "/tmp/ipykernel_139302/4290825372.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metrics[\"compression\"] = metrics[\"compression\"].apply(lambda x : rename_dict.get(x, None))\n",
      "/tmp/ipykernel_139302/4290825372.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metrics[\"unlearn\"] = metrics[\"unlearn\"].apply(lambda x : rename_dict.get(x, None))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tag\n",
       "AWQ2bit-to-ft              1\n",
       "lora-to-SparseGPT0.25%     1\n",
       "lora-to-AWQ3bit            1\n",
       "lora-to-AWQ4bit            1\n",
       "lora-to-AWQ5bit            1\n",
       "                          ..\n",
       "SparseGPT0.55%-to-memit    1\n",
       "SparseGPT0.65%-to-ft       1\n",
       "SparseGPT0.65%-to-lora     1\n",
       "SparseGPT0.65%-to-memit    1\n",
       "wanda0.65\\%-rmu            1\n",
       "Name: count, Length: 186, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicates, keeping only the first occurrence (which is the most recent due to sorting)\n",
    "# all_runs_df_deduplicated = all_runs_df_sorted.drop_duplicates(subset=[col for col in setting_columns if col not in [\"_timestamp\", \"tag\", \"date\"]], keep=\"first\")\n",
    "all_runs_df_deduplicated = all_runs_df_sorted.drop_duplicates(subset=\"tag\", keep=\"first\")\n",
    "# all_runs_df_deduplicated = all_runs_df_sorted\n",
    "all_runs_df_deduplicated[\"interventions\"] = all_runs_df_deduplicated[\"interventions\"].apply(lambda x : ast.literal_eval(x))\n",
    "\n",
    "rename_dict = {\n",
    "    \"meta-llama/Meta-Llama-3-8B\" : \"Llama-3 (8b)\",\n",
    "    \"ft\" : \"Fine-tune\",\n",
    "    \"memit\" : \"MEMIT\",\n",
    "    \"lora\" : \"Lora\",\n",
    "    \"wanda\" : \"Wanda\",\n",
    "    \"sparsegpt\" : \"SparseGPT\",\n",
    "    \"gptq\" : \"GPTQ\",\n",
    "    \"awq\" : \"AWQ\",\n",
    "    \"rmu\" : \"RMU\",\n",
    "}\n",
    "metrics = all_runs_df_deduplicated\n",
    "metrics[\"model_name\"] = metrics[\"model_name\"].apply(lambda x : rename_dict.get(x, None))\n",
    "metrics[\"edit\"] = metrics[\"edit\"].apply(lambda x : rename_dict.get(x, None))\n",
    "metrics[\"compression\"] = metrics[\"compression\"].apply(lambda x : rename_dict.get(x, None))\n",
    "metrics[\"unlearn\"] = metrics[\"unlearn\"].apply(lambda x : rename_dict.get(x, None))\n",
    "all_runs_df_deduplicated = metrics\n",
    "all_runs_df_deduplicated.value_counts(\"tag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>_timestamp</th>\n",
       "      <th>interventions</th>\n",
       "      <th>edit</th>\n",
       "      <th>unlearn</th>\n",
       "      <th>compression</th>\n",
       "      <th>model_name</th>\n",
       "      <th>edit_dataset</th>\n",
       "      <th>number_of_edits</th>\n",
       "      <th>rmu_layer_id</th>\n",
       "      <th>...</th>\n",
       "      <th>FLOPs</th>\n",
       "      <th>Success recall</th>\n",
       "      <th>Generalization recall</th>\n",
       "      <th>Locality</th>\n",
       "      <th>Average bits</th>\n",
       "      <th>Rewrite accuracy</th>\n",
       "      <th>PPl edits unmasked</th>\n",
       "      <th>Local recall</th>\n",
       "      <th>Latency</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>SparseGPT0.65%-to-memit</td>\n",
       "      <td>1.716348e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>759.86 GFLOPS</td>\n",
       "      <td>0.116222</td>\n",
       "      <td>0.057889</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>6.249982</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>1358.275513</td>\n",
       "      <td>0.010438</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 03:17:58.787498713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>SparseGPT0.25%-to-memit</td>\n",
       "      <td>1.716348e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.47 TFLOPS</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.041359</td>\n",
       "      <td>12.249977</td>\n",
       "      <td>0.819231</td>\n",
       "      <td>451.862762</td>\n",
       "      <td>0.042053</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 03:15:44.578335047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>SparseGPT0.45%-to-memit</td>\n",
       "      <td>1.716348e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.12 TFLOPS</td>\n",
       "      <td>0.649556</td>\n",
       "      <td>0.435111</td>\n",
       "      <td>0.023404</td>\n",
       "      <td>9.249988</td>\n",
       "      <td>0.649556</td>\n",
       "      <td>458.593323</td>\n",
       "      <td>0.023942</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 03:15:22.386393309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>SparseGPT0.45%-to-lora</td>\n",
       "      <td>1.716347e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Lora</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>982.73 GFLOPS</td>\n",
       "      <td>0.746111</td>\n",
       "      <td>0.214667</td>\n",
       "      <td>0.025034</td>\n",
       "      <td>9.249988</td>\n",
       "      <td>0.746765</td>\n",
       "      <td>1741.787231</td>\n",
       "      <td>0.024861</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 02:55:08.137873888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>SparseGPT0.65%-to-lora</td>\n",
       "      <td>1.716346e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Lora</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>625.37 GFLOPS</td>\n",
       "      <td>0.441556</td>\n",
       "      <td>0.181889</td>\n",
       "      <td>0.020420</td>\n",
       "      <td>6.249982</td>\n",
       "      <td>0.443071</td>\n",
       "      <td>1556.614868</td>\n",
       "      <td>0.020079</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 02:54:03.460087299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>SparseGPT0.45%-to-ft</td>\n",
       "      <td>1.716346e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.12 TFLOPS</td>\n",
       "      <td>0.929667</td>\n",
       "      <td>0.644667</td>\n",
       "      <td>0.048091</td>\n",
       "      <td>9.249988</td>\n",
       "      <td>0.929667</td>\n",
       "      <td>561.806335</td>\n",
       "      <td>0.047011</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 02:51:42.515434980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>SparseGPT0.65%-to-ft</td>\n",
       "      <td>1.716346e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>759.86 GFLOPS</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.543889</td>\n",
       "      <td>0.010484</td>\n",
       "      <td>6.249982</td>\n",
       "      <td>0.974762</td>\n",
       "      <td>1071.286987</td>\n",
       "      <td>0.010011</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 02:51:32.372437716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>SparseGPT0.25%-to-ft</td>\n",
       "      <td>1.716346e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.47 TFLOPS</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.663333</td>\n",
       "      <td>0.080201</td>\n",
       "      <td>12.249977</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>518.634399</td>\n",
       "      <td>0.080455</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 02:50:44.011991501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>SparseGPT0.25%-to-lora</td>\n",
       "      <td>1.716346e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Lora</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.34 TFLOPS</td>\n",
       "      <td>0.898000</td>\n",
       "      <td>0.517667</td>\n",
       "      <td>0.032262</td>\n",
       "      <td>12.249977</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>2683.486572</td>\n",
       "      <td>0.032788</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 02:50:15.668058157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>memit-to-SparseGPT0.25%</td>\n",
       "      <td>1.716345e+09</td>\n",
       "      <td>[edit, compress]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.47 TFLOPS</td>\n",
       "      <td>0.776111</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.032233</td>\n",
       "      <td>12.249977</td>\n",
       "      <td>0.776111</td>\n",
       "      <td>472.074982</td>\n",
       "      <td>0.032887</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 02:30:45.327311277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>memit-to-SparseGPT0.65%</td>\n",
       "      <td>1.716345e+09</td>\n",
       "      <td>[edit, compress]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>759.83 GFLOPS</td>\n",
       "      <td>0.016222</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.012560</td>\n",
       "      <td>6.249982</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>1564.170044</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 02:29:58.692099094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>memit-to-SparseGPT0.45%</td>\n",
       "      <td>1.716345e+09</td>\n",
       "      <td>[edit, compress]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.12 TFLOPS</td>\n",
       "      <td>0.547111</td>\n",
       "      <td>0.553778</td>\n",
       "      <td>0.055855</td>\n",
       "      <td>9.249987</td>\n",
       "      <td>0.548157</td>\n",
       "      <td>470.489136</td>\n",
       "      <td>0.056049</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 02:29:16.555516005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>SparseGPT0.75%-to-lora</td>\n",
       "      <td>1.716345e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Lora</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>446.67 GFLOPS</td>\n",
       "      <td>0.043222</td>\n",
       "      <td>0.056556</td>\n",
       "      <td>0.027078</td>\n",
       "      <td>4.749976</td>\n",
       "      <td>0.046333</td>\n",
       "      <td>2341.310791</td>\n",
       "      <td>0.024972</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 02:21:46.844654799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>SparseGPT0.55%-to-lora</td>\n",
       "      <td>1.716344e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Lora</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>804.02 GFLOPS</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.358889</td>\n",
       "      <td>0.030426</td>\n",
       "      <td>7.749985</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>1123.241943</td>\n",
       "      <td>0.030011</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 02:20:27.639491081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>SparseGPT0.35%-to-lora</td>\n",
       "      <td>1.716344e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Lora</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.16 TFLOPS</td>\n",
       "      <td>0.768000</td>\n",
       "      <td>0.438889</td>\n",
       "      <td>0.011856</td>\n",
       "      <td>10.749991</td>\n",
       "      <td>0.768000</td>\n",
       "      <td>2290.002197</td>\n",
       "      <td>0.011132</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 02:19:55.668187380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Compress_SparseGPT0.65%</td>\n",
       "      <td>1.716344e+09</td>\n",
       "      <td>[compress]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>759.83 GFLOPS</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.017918</td>\n",
       "      <td>6.249982</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>1724.813477</td>\n",
       "      <td>0.016757</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 02:18:41.787098169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ft-to-SparseGPT0.65%</td>\n",
       "      <td>1.716344e+09</td>\n",
       "      <td>[edit, compress]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>759.86 GFLOPS</td>\n",
       "      <td>0.101889</td>\n",
       "      <td>0.118889</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>6.249982</td>\n",
       "      <td>0.103303</td>\n",
       "      <td>1295.767212</td>\n",
       "      <td>0.013156</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 02:11:42.009056091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Compress_SparseGPT0.45%</td>\n",
       "      <td>1.716344e+09</td>\n",
       "      <td>[compress]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.12 TFLOPS</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.018812</td>\n",
       "      <td>9.249987</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>627.921265</td>\n",
       "      <td>0.019049</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 02:10:16.541721821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>lora-to-SparseGPT0.45%</td>\n",
       "      <td>1.716344e+09</td>\n",
       "      <td>[edit, compress]</td>\n",
       "      <td>Lora</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>982.73 GFLOPS</td>\n",
       "      <td>0.270889</td>\n",
       "      <td>0.211889</td>\n",
       "      <td>0.023672</td>\n",
       "      <td>9.249987</td>\n",
       "      <td>0.272444</td>\n",
       "      <td>3888.788330</td>\n",
       "      <td>0.023632</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 02:07:20.147166729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Compress_SparseGPT0.25%</td>\n",
       "      <td>1.716344e+09</td>\n",
       "      <td>[compress]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.47 TFLOPS</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>0.020667</td>\n",
       "      <td>0.027378</td>\n",
       "      <td>12.249977</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>538.687683</td>\n",
       "      <td>0.028015</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 02:06:58.100267887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>lora-to-SparseGPT0.65%</td>\n",
       "      <td>1.716343e+09</td>\n",
       "      <td>[edit, compress]</td>\n",
       "      <td>Lora</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>625.37 GFLOPS</td>\n",
       "      <td>0.057889</td>\n",
       "      <td>0.067222</td>\n",
       "      <td>0.021068</td>\n",
       "      <td>6.249982</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>6892.447266</td>\n",
       "      <td>0.020438</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 01:56:41.736150503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>ft-to-SparseGPT0.25%</td>\n",
       "      <td>1.716343e+09</td>\n",
       "      <td>[edit, compress]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.47 TFLOPS</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.728000</td>\n",
       "      <td>0.097582</td>\n",
       "      <td>12.249977</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>643.528748</td>\n",
       "      <td>0.097284</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 01:55:47.334988117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>ft-to-SparseGPT0.45%</td>\n",
       "      <td>1.716343e+09</td>\n",
       "      <td>[edit, compress]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.12 TFLOPS</td>\n",
       "      <td>0.627444</td>\n",
       "      <td>0.426333</td>\n",
       "      <td>0.081399</td>\n",
       "      <td>9.249988</td>\n",
       "      <td>0.627444</td>\n",
       "      <td>533.667908</td>\n",
       "      <td>0.081566</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 01:55:36.951574564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>lora-to-SparseGPT0.75%</td>\n",
       "      <td>1.716342e+09</td>\n",
       "      <td>[edit, compress]</td>\n",
       "      <td>Lora</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>446.67 GFLOPS</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.010445</td>\n",
       "      <td>4.749975</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>8469.304688</td>\n",
       "      <td>0.010150</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 01:42:09.540604830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>lora-to-SparseGPT0.55%</td>\n",
       "      <td>1.716342e+09</td>\n",
       "      <td>[edit, compress]</td>\n",
       "      <td>Lora</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>804.02 GFLOPS</td>\n",
       "      <td>0.301889</td>\n",
       "      <td>0.152556</td>\n",
       "      <td>0.057905</td>\n",
       "      <td>7.749985</td>\n",
       "      <td>0.306857</td>\n",
       "      <td>3462.212158</td>\n",
       "      <td>0.056868</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 01:41:30.580134153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>lora-to-SparseGPT0.25%</td>\n",
       "      <td>1.716342e+09</td>\n",
       "      <td>[edit, compress]</td>\n",
       "      <td>Lora</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.34 TFLOPS</td>\n",
       "      <td>0.719000</td>\n",
       "      <td>0.416889</td>\n",
       "      <td>0.026145</td>\n",
       "      <td>12.249977</td>\n",
       "      <td>0.719000</td>\n",
       "      <td>3876.779785</td>\n",
       "      <td>0.025983</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 01:40:16.717908621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>lora-to-SparseGPT0.35%</td>\n",
       "      <td>1.716342e+09</td>\n",
       "      <td>[edit, compress]</td>\n",
       "      <td>Lora</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.16 TFLOPS</td>\n",
       "      <td>0.770667</td>\n",
       "      <td>0.509000</td>\n",
       "      <td>0.018785</td>\n",
       "      <td>10.749990</td>\n",
       "      <td>0.770667</td>\n",
       "      <td>3430.806396</td>\n",
       "      <td>0.019038</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 01:40:15.219367266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>SparseGPT0.75%-to-ft</td>\n",
       "      <td>1.716342e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>581.16 GFLOPS</td>\n",
       "      <td>0.591222</td>\n",
       "      <td>0.164222</td>\n",
       "      <td>0.048263</td>\n",
       "      <td>4.749976</td>\n",
       "      <td>0.595540</td>\n",
       "      <td>2826.004150</td>\n",
       "      <td>0.044795</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 01:36:34.799863100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>SparseGPT0.55%-to-ft</td>\n",
       "      <td>1.716342e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>938.5 GFLOPS</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.558444</td>\n",
       "      <td>0.022021</td>\n",
       "      <td>7.749984</td>\n",
       "      <td>0.945897</td>\n",
       "      <td>671.375671</td>\n",
       "      <td>0.021927</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 01:34:49.547302961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>SparseGPT0.35%-to-ft</td>\n",
       "      <td>1.716342e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3 TFLOPS</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.740556</td>\n",
       "      <td>0.069641</td>\n",
       "      <td>10.749990</td>\n",
       "      <td>0.972000</td>\n",
       "      <td>532.846558</td>\n",
       "      <td>0.069511</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 01:33:19.494725704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>ft-to-SparseGPT0.55%</td>\n",
       "      <td>1.716340e+09</td>\n",
       "      <td>[edit, compress]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>938.5 GFLOPS</td>\n",
       "      <td>0.290778</td>\n",
       "      <td>0.172889</td>\n",
       "      <td>0.056207</td>\n",
       "      <td>7.749984</td>\n",
       "      <td>0.291039</td>\n",
       "      <td>726.520935</td>\n",
       "      <td>0.056038</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 01:00:15.654988289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>ft-to-SparseGPT0.75%</td>\n",
       "      <td>1.716340e+09</td>\n",
       "      <td>[edit, compress]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>581.16 GFLOPS</td>\n",
       "      <td>0.044333</td>\n",
       "      <td>0.018667</td>\n",
       "      <td>0.020208</td>\n",
       "      <td>4.749975</td>\n",
       "      <td>0.044333</td>\n",
       "      <td>3449.776855</td>\n",
       "      <td>0.017045</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 00:59:57.457068205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>ft-to-SparseGPT0.35%</td>\n",
       "      <td>1.716340e+09</td>\n",
       "      <td>[edit, compress]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3 TFLOPS</td>\n",
       "      <td>0.849444</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.093635</td>\n",
       "      <td>10.749990</td>\n",
       "      <td>0.849444</td>\n",
       "      <td>610.655029</td>\n",
       "      <td>0.093257</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 00:59:23.139783144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Compress_SparseGPT0.55%</td>\n",
       "      <td>1.716339e+09</td>\n",
       "      <td>[compress]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>938.5 GFLOPS</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.011487</td>\n",
       "      <td>7.749984</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>858.126221</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 00:48:03.682067156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Compress_SparseGPT0.75%</td>\n",
       "      <td>1.716339e+09</td>\n",
       "      <td>[compress]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>581.16 GFLOPS</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011907</td>\n",
       "      <td>4.749975</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>3640.602539</td>\n",
       "      <td>0.010438</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 00:47:55.690675497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Compress_SparseGPT0.35%</td>\n",
       "      <td>1.716339e+09</td>\n",
       "      <td>[compress]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3 TFLOPS</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020667</td>\n",
       "      <td>0.025261</td>\n",
       "      <td>10.749990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>559.900635</td>\n",
       "      <td>0.025726</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 00:47:40.249751091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>SparseGPT0.35%-to-memit</td>\n",
       "      <td>1.716339e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3 TFLOPS</td>\n",
       "      <td>0.846000</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.025195</td>\n",
       "      <td>10.749990</td>\n",
       "      <td>0.848944</td>\n",
       "      <td>435.939575</td>\n",
       "      <td>0.025726</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 00:47:28.574797630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>SparseGPT0.75%-to-memit</td>\n",
       "      <td>1.716339e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>581.16 GFLOPS</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.041842</td>\n",
       "      <td>4.749975</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>6655.474609</td>\n",
       "      <td>0.034868</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 00:47:22.558988810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>SparseGPT0.55%-to-memit</td>\n",
       "      <td>1.716339e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>938.5 GFLOPS</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.208889</td>\n",
       "      <td>0.010335</td>\n",
       "      <td>7.749984</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>632.922729</td>\n",
       "      <td>0.010011</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 00:47:17.975588322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>memit-to-SparseGPT0.75%</td>\n",
       "      <td>1.716337e+09</td>\n",
       "      <td>[edit, compress]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>581.16 GFLOPS</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016914</td>\n",
       "      <td>4.749975</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>3912.391357</td>\n",
       "      <td>0.015855</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 00:17:27.040256977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>memit-to-SparseGPT0.35%</td>\n",
       "      <td>1.716337e+09</td>\n",
       "      <td>[edit, compress]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3 TFLOPS</td>\n",
       "      <td>0.717667</td>\n",
       "      <td>0.567667</td>\n",
       "      <td>0.049839</td>\n",
       "      <td>10.749990</td>\n",
       "      <td>0.717667</td>\n",
       "      <td>471.752991</td>\n",
       "      <td>0.050077</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 00:16:45.510542630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>memit-to-SparseGPT0.55%</td>\n",
       "      <td>1.716337e+09</td>\n",
       "      <td>[edit, compress]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>938.5 GFLOPS</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.265000</td>\n",
       "      <td>0.020967</td>\n",
       "      <td>7.749984</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>659.518127</td>\n",
       "      <td>0.020650</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-22 00:16:26.593446970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>sparsegpt0.65\\%-rmu</td>\n",
       "      <td>1.716237e+09</td>\n",
       "      <td>[compress, unlearn]</td>\n",
       "      <td>None</td>\n",
       "      <td>RMU</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>759.86 GFLOPS</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.022232</td>\n",
       "      <td>6.249982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1688.532227</td>\n",
       "      <td>0.020173</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-20 20:26:57.591763496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>sparsegpt0.45\\%-rmu</td>\n",
       "      <td>1.716237e+09</td>\n",
       "      <td>[compress, unlearn]</td>\n",
       "      <td>None</td>\n",
       "      <td>RMU</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.12 TFLOPS</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.023685</td>\n",
       "      <td>9.249988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>637.708252</td>\n",
       "      <td>0.023586</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-20 20:26:14.456046343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>sparsegpt0.25\\%-rmu</td>\n",
       "      <td>1.716237e+09</td>\n",
       "      <td>[compress, unlearn]</td>\n",
       "      <td>None</td>\n",
       "      <td>RMU</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.47 TFLOPS</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.025238</td>\n",
       "      <td>0.041017</td>\n",
       "      <td>12.249977</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>481.484344</td>\n",
       "      <td>0.040736</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-20 20:24:09.416608095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>rmu-sparsegpt0.45\\%</td>\n",
       "      <td>1.716234e+09</td>\n",
       "      <td>[unlearn, compress]</td>\n",
       "      <td>None</td>\n",
       "      <td>RMU</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.12 TFLOPS</td>\n",
       "      <td>0.020714</td>\n",
       "      <td>0.021667</td>\n",
       "      <td>0.036096</td>\n",
       "      <td>9.249988</td>\n",
       "      <td>0.021154</td>\n",
       "      <td>637.052124</td>\n",
       "      <td>0.036055</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-20 19:38:30.983223438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>rmu-sparsegpt0.65\\%</td>\n",
       "      <td>1.716234e+09</td>\n",
       "      <td>[unlearn, compress]</td>\n",
       "      <td>None</td>\n",
       "      <td>RMU</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>759.86 GFLOPS</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.024438</td>\n",
       "      <td>6.249982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1573.433228</td>\n",
       "      <td>0.022101</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-20 19:36:36.984816551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>rmu-sparsegpt0.25\\%</td>\n",
       "      <td>1.716234e+09</td>\n",
       "      <td>[unlearn, compress]</td>\n",
       "      <td>None</td>\n",
       "      <td>RMU</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.47 TFLOPS</td>\n",
       "      <td>0.017714</td>\n",
       "      <td>0.012857</td>\n",
       "      <td>0.040960</td>\n",
       "      <td>12.249977</td>\n",
       "      <td>0.018154</td>\n",
       "      <td>480.607880</td>\n",
       "      <td>0.039888</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-20 19:35:36.819632053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         tag    _timestamp        interventions       edit  \\\n",
       "52   SparseGPT0.65%-to-memit  1.716348e+09     [compress, edit]      MEMIT   \n",
       "56   SparseGPT0.25%-to-memit  1.716348e+09     [compress, edit]      MEMIT   \n",
       "54   SparseGPT0.45%-to-memit  1.716348e+09     [compress, edit]      MEMIT   \n",
       "76    SparseGPT0.45%-to-lora  1.716347e+09     [compress, edit]       Lora   \n",
       "75    SparseGPT0.65%-to-lora  1.716346e+09     [compress, edit]       Lora   \n",
       "73      SparseGPT0.45%-to-ft  1.716346e+09     [compress, edit]  Fine-tune   \n",
       "72      SparseGPT0.65%-to-ft  1.716346e+09     [compress, edit]  Fine-tune   \n",
       "74      SparseGPT0.25%-to-ft  1.716346e+09     [compress, edit]  Fine-tune   \n",
       "77    SparseGPT0.25%-to-lora  1.716346e+09     [compress, edit]       Lora   \n",
       "66   memit-to-SparseGPT0.25%  1.716345e+09     [edit, compress]      MEMIT   \n",
       "65   memit-to-SparseGPT0.65%  1.716345e+09     [edit, compress]      MEMIT   \n",
       "67   memit-to-SparseGPT0.45%  1.716345e+09     [edit, compress]      MEMIT   \n",
       "108   SparseGPT0.75%-to-lora  1.716345e+09     [compress, edit]       Lora   \n",
       "106   SparseGPT0.55%-to-lora  1.716344e+09     [compress, edit]       Lora   \n",
       "109   SparseGPT0.35%-to-lora  1.716344e+09     [compress, edit]       Lora   \n",
       "71   Compress_SparseGPT0.65%  1.716344e+09           [compress]       None   \n",
       "98      ft-to-SparseGPT0.65%  1.716344e+09     [edit, compress]  Fine-tune   \n",
       "84   Compress_SparseGPT0.45%  1.716344e+09           [compress]       None   \n",
       "100   lora-to-SparseGPT0.45%  1.716344e+09     [edit, compress]       Lora   \n",
       "85   Compress_SparseGPT0.25%  1.716344e+09           [compress]       None   \n",
       "101   lora-to-SparseGPT0.65%  1.716343e+09     [edit, compress]       Lora   \n",
       "102     ft-to-SparseGPT0.25%  1.716343e+09     [edit, compress]  Fine-tune   \n",
       "103     ft-to-SparseGPT0.45%  1.716343e+09     [edit, compress]  Fine-tune   \n",
       "113   lora-to-SparseGPT0.75%  1.716342e+09     [edit, compress]       Lora   \n",
       "114   lora-to-SparseGPT0.55%  1.716342e+09     [edit, compress]       Lora   \n",
       "128   lora-to-SparseGPT0.25%  1.716342e+09     [edit, compress]       Lora   \n",
       "115   lora-to-SparseGPT0.35%  1.716342e+09     [edit, compress]       Lora   \n",
       "151     SparseGPT0.75%-to-ft  1.716342e+09     [compress, edit]  Fine-tune   \n",
       "152     SparseGPT0.55%-to-ft  1.716342e+09     [compress, edit]  Fine-tune   \n",
       "153     SparseGPT0.35%-to-ft  1.716342e+09     [compress, edit]  Fine-tune   \n",
       "158     ft-to-SparseGPT0.55%  1.716340e+09     [edit, compress]  Fine-tune   \n",
       "157     ft-to-SparseGPT0.75%  1.716340e+09     [edit, compress]  Fine-tune   \n",
       "159     ft-to-SparseGPT0.35%  1.716340e+09     [edit, compress]  Fine-tune   \n",
       "163  Compress_SparseGPT0.55%  1.716339e+09           [compress]       None   \n",
       "164  Compress_SparseGPT0.75%  1.716339e+09           [compress]       None   \n",
       "165  Compress_SparseGPT0.35%  1.716339e+09           [compress]       None   \n",
       "188  SparseGPT0.35%-to-memit  1.716339e+09     [compress, edit]      MEMIT   \n",
       "191  SparseGPT0.75%-to-memit  1.716339e+09     [compress, edit]      MEMIT   \n",
       "177  SparseGPT0.55%-to-memit  1.716339e+09     [compress, edit]      MEMIT   \n",
       "174  memit-to-SparseGPT0.75%  1.716337e+09     [edit, compress]      MEMIT   \n",
       "195  memit-to-SparseGPT0.35%  1.716337e+09     [edit, compress]      MEMIT   \n",
       "173  memit-to-SparseGPT0.55%  1.716337e+09     [edit, compress]      MEMIT   \n",
       "242      sparsegpt0.65\\%-rmu  1.716237e+09  [compress, unlearn]       None   \n",
       "243      sparsegpt0.45\\%-rmu  1.716237e+09  [compress, unlearn]       None   \n",
       "244      sparsegpt0.25\\%-rmu  1.716237e+09  [compress, unlearn]       None   \n",
       "251      rmu-sparsegpt0.45\\%  1.716234e+09  [unlearn, compress]       None   \n",
       "252      rmu-sparsegpt0.65\\%  1.716234e+09  [unlearn, compress]       None   \n",
       "253      rmu-sparsegpt0.25\\%  1.716234e+09  [unlearn, compress]       None   \n",
       "\n",
       "    unlearn compression    model_name edit_dataset  number_of_edits  \\\n",
       "52     None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "56     None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "54     None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "76     None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "75     None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "73     None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "72     None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "74     None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "77     None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "66     None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "65     None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "67     None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "108    None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "106    None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "109    None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "71     None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "98     None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "84     None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "100    None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "85     None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "101    None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "102    None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "103    None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "113    None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "114    None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "128    None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "115    None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "151    None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "152    None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "153    None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "158    None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "157    None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "159    None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "163    None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "164    None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "165    None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "188    None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "191    None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "177    None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "174    None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "195    None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "173    None   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "242     RMU   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "243     RMU   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "244     RMU   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "251     RMU   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "252     RMU   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "253     RMU   SparseGPT  Llama-3 (8b)         zsre               50   \n",
       "\n",
       "     rmu_layer_id  ...          FLOPs Success recall  Generalization recall  \\\n",
       "52           -1.0  ...  759.86 GFLOPS       0.116222               0.057889   \n",
       "56           -1.0  ...    1.47 TFLOPS       0.820000               0.800000   \n",
       "54           -1.0  ...    1.12 TFLOPS       0.649556               0.435111   \n",
       "76           -1.0  ...  982.73 GFLOPS       0.746111               0.214667   \n",
       "75           -1.0  ...  625.37 GFLOPS       0.441556               0.181889   \n",
       "73           -1.0  ...    1.12 TFLOPS       0.929667               0.644667   \n",
       "72           -1.0  ...  759.86 GFLOPS       0.972222               0.543889   \n",
       "74           -1.0  ...    1.47 TFLOPS       0.995000               0.663333   \n",
       "77           -1.0  ...    1.34 TFLOPS       0.898000               0.517667   \n",
       "66            NaN  ...    1.47 TFLOPS       0.776111               0.705000   \n",
       "65            NaN  ...  759.83 GFLOPS       0.016222               0.023000   \n",
       "67            NaN  ...    1.12 TFLOPS       0.547111               0.553778   \n",
       "108           NaN  ...  446.67 GFLOPS       0.043222               0.056556   \n",
       "106           NaN  ...  804.02 GFLOPS       0.626667               0.358889   \n",
       "109           NaN  ...    1.16 TFLOPS       0.768000               0.438889   \n",
       "71            NaN  ...  759.83 GFLOPS       0.008889               0.004444   \n",
       "98           -1.0  ...  759.86 GFLOPS       0.101889               0.118889   \n",
       "84            NaN  ...    1.12 TFLOPS       0.008889               0.016667   \n",
       "100          -1.0  ...  982.73 GFLOPS       0.270889               0.211889   \n",
       "85            NaN  ...    1.47 TFLOPS       0.008889               0.020667   \n",
       "101          -1.0  ...  625.37 GFLOPS       0.057889               0.067222   \n",
       "102          -1.0  ...    1.47 TFLOPS       0.990000               0.728000   \n",
       "103          -1.0  ...    1.12 TFLOPS       0.627444               0.426333   \n",
       "113           NaN  ...  446.67 GFLOPS       0.023333               0.039556   \n",
       "114           NaN  ...  804.02 GFLOPS       0.301889               0.152556   \n",
       "128          -1.0  ...    1.34 TFLOPS       0.719000               0.416889   \n",
       "115           NaN  ...    1.16 TFLOPS       0.770667               0.509000   \n",
       "151           NaN  ...  581.16 GFLOPS       0.591222               0.164222   \n",
       "152           NaN  ...   938.5 GFLOPS       0.946667               0.558444   \n",
       "153           NaN  ...     1.3 TFLOPS       0.970000               0.740556   \n",
       "158           NaN  ...   938.5 GFLOPS       0.290778               0.172889   \n",
       "157           NaN  ...  581.16 GFLOPS       0.044333               0.018667   \n",
       "159           NaN  ...     1.3 TFLOPS       0.849444               0.570000   \n",
       "163           NaN  ...   938.5 GFLOPS       0.008889               0.006667   \n",
       "164           NaN  ...  581.16 GFLOPS       0.018333               0.000000   \n",
       "165           NaN  ...     1.3 TFLOPS       0.000000               0.020667   \n",
       "188           NaN  ...     1.3 TFLOPS       0.846000               0.753333   \n",
       "191           NaN  ...  581.16 GFLOPS       0.024000               0.004000   \n",
       "177           NaN  ...   938.5 GFLOPS       0.305556               0.208889   \n",
       "174           NaN  ...  581.16 GFLOPS       0.018333               0.000000   \n",
       "195           NaN  ...     1.3 TFLOPS       0.717667               0.567667   \n",
       "173           NaN  ...   938.5 GFLOPS       0.291667               0.265000   \n",
       "242           5.0  ...  759.86 GFLOPS       0.000000               0.006667   \n",
       "243           5.0  ...    1.12 TFLOPS       0.000000               0.005000   \n",
       "244           5.0  ...    1.47 TFLOPS       0.005714               0.025238   \n",
       "251           5.0  ...    1.12 TFLOPS       0.020714               0.021667   \n",
       "252           5.0  ...  759.86 GFLOPS       0.000000               0.006667   \n",
       "253           5.0  ...    1.47 TFLOPS       0.017714               0.012857   \n",
       "\n",
       "     Locality  Average bits  Rewrite accuracy  PPl edits unmasked  \\\n",
       "52   0.010900      6.249982          0.116667         1358.275513   \n",
       "56   0.041359     12.249977          0.819231          451.862762   \n",
       "54   0.023404      9.249988          0.649556          458.593323   \n",
       "76   0.025034      9.249988          0.746765         1741.787231   \n",
       "75   0.020420      6.249982          0.443071         1556.614868   \n",
       "73   0.048091      9.249988          0.929667          561.806335   \n",
       "72   0.010484      6.249982          0.974762         1071.286987   \n",
       "74   0.080201     12.249977          0.995000          518.634399   \n",
       "77   0.032262     12.249977          0.900000         2683.486572   \n",
       "66   0.032233     12.249977          0.776111          472.074982   \n",
       "65   0.012560      6.249982          0.016667         1564.170044   \n",
       "67   0.055855      9.249987          0.548157          470.489136   \n",
       "108  0.027078      4.749976          0.046333         2341.310791   \n",
       "106  0.030426      7.749985          0.626667         1123.241943   \n",
       "109  0.011856     10.749991          0.768000         2290.002197   \n",
       "71   0.017918      6.249982          0.008889         1724.813477   \n",
       "98   0.013285      6.249982          0.103303         1295.767212   \n",
       "84   0.018812      9.249987          0.008889          627.921265   \n",
       "100  0.023672      9.249987          0.272444         3888.788330   \n",
       "85   0.027378     12.249977          0.008889          538.687683   \n",
       "101  0.021068      6.249982          0.059000         6892.447266   \n",
       "102  0.097582     12.249977          0.990000          643.528748   \n",
       "103  0.081399      9.249988          0.627444          533.667908   \n",
       "113  0.010445      4.749975          0.027500         8469.304688   \n",
       "114  0.057905      7.749985          0.306857         3462.212158   \n",
       "128  0.026145     12.249977          0.719000         3876.779785   \n",
       "115  0.018785     10.749990          0.770667         3430.806396   \n",
       "151  0.048263      4.749976          0.595540         2826.004150   \n",
       "152  0.022021      7.749984          0.945897          671.375671   \n",
       "153  0.069641     10.749990          0.972000          532.846558   \n",
       "158  0.056207      7.749984          0.291039          726.520935   \n",
       "157  0.020208      4.749975          0.044333         3449.776855   \n",
       "159  0.093635     10.749990          0.849444          610.655029   \n",
       "163  0.011487      7.749984          0.008889          858.126221   \n",
       "164  0.011907      4.749975          0.018333         3640.602539   \n",
       "165  0.025261     10.749990          0.000000          559.900635   \n",
       "188  0.025195     10.749990          0.848944          435.939575   \n",
       "191  0.041842      4.749975          0.025000         6655.474609   \n",
       "177  0.010335      7.749984          0.305556          632.922729   \n",
       "174  0.016914      4.749975          0.018333         3912.391357   \n",
       "195  0.049839     10.749990          0.717667          471.752991   \n",
       "173  0.020967      7.749984          0.291667          659.518127   \n",
       "242  0.022232      6.249982          0.000000         1688.532227   \n",
       "243  0.023685      9.249988          0.000000          637.708252   \n",
       "244  0.041017     12.249977          0.006154          481.484344   \n",
       "251  0.036096      9.249988          0.021154          637.052124   \n",
       "252  0.024438      6.249982          0.000000         1573.433228   \n",
       "253  0.040960     12.249977          0.018154          480.607880   \n",
       "\n",
       "     Local recall  Latency                          date  \n",
       "52       0.010438     -1.0 2024-05-22 03:17:58.787498713  \n",
       "56       0.042053     -1.0 2024-05-22 03:15:44.578335047  \n",
       "54       0.023942     -1.0 2024-05-22 03:15:22.386393309  \n",
       "76       0.024861     -1.0 2024-05-22 02:55:08.137873888  \n",
       "75       0.020079     -1.0 2024-05-22 02:54:03.460087299  \n",
       "73       0.047011     -1.0 2024-05-22 02:51:42.515434980  \n",
       "72       0.010011     -1.0 2024-05-22 02:51:32.372437716  \n",
       "74       0.080455     -1.0 2024-05-22 02:50:44.011991501  \n",
       "77       0.032788     -1.0 2024-05-22 02:50:15.668058157  \n",
       "66       0.032887     -1.0 2024-05-22 02:30:45.327311277  \n",
       "65       0.011261     -1.0 2024-05-22 02:29:58.692099094  \n",
       "67       0.056049     -1.0 2024-05-22 02:29:16.555516005  \n",
       "108      0.024972     -1.0 2024-05-22 02:21:46.844654799  \n",
       "106      0.030011     -1.0 2024-05-22 02:20:27.639491081  \n",
       "109      0.011132     -1.0 2024-05-22 02:19:55.668187380  \n",
       "71       0.016757     -1.0 2024-05-22 02:18:41.787098169  \n",
       "98       0.013156     -1.0 2024-05-22 02:11:42.009056091  \n",
       "84       0.019049     -1.0 2024-05-22 02:10:16.541721821  \n",
       "100      0.023632     -1.0 2024-05-22 02:07:20.147166729  \n",
       "85       0.028015     -1.0 2024-05-22 02:06:58.100267887  \n",
       "101      0.020438     -1.0 2024-05-22 01:56:41.736150503  \n",
       "102      0.097284     -1.0 2024-05-22 01:55:47.334988117  \n",
       "103      0.081566     -1.0 2024-05-22 01:55:36.951574564  \n",
       "113      0.010150     -1.0 2024-05-22 01:42:09.540604830  \n",
       "114      0.056868     -1.0 2024-05-22 01:41:30.580134153  \n",
       "128      0.025983     -1.0 2024-05-22 01:40:16.717908621  \n",
       "115      0.019038     -1.0 2024-05-22 01:40:15.219367266  \n",
       "151      0.044795     -1.0 2024-05-22 01:36:34.799863100  \n",
       "152      0.021927     -1.0 2024-05-22 01:34:49.547302961  \n",
       "153      0.069511     -1.0 2024-05-22 01:33:19.494725704  \n",
       "158      0.056038     -1.0 2024-05-22 01:00:15.654988289  \n",
       "157      0.017045     -1.0 2024-05-22 00:59:57.457068205  \n",
       "159      0.093257     -1.0 2024-05-22 00:59:23.139783144  \n",
       "163      0.011400     -1.0 2024-05-22 00:48:03.682067156  \n",
       "164      0.010438     -1.0 2024-05-22 00:47:55.690675497  \n",
       "165      0.025726     -1.0 2024-05-22 00:47:40.249751091  \n",
       "188      0.025726     -1.0 2024-05-22 00:47:28.574797630  \n",
       "191      0.034868     -1.0 2024-05-22 00:47:22.558988810  \n",
       "177      0.010011     -1.0 2024-05-22 00:47:17.975588322  \n",
       "174      0.015855     -1.0 2024-05-22 00:17:27.040256977  \n",
       "195      0.050077     -1.0 2024-05-22 00:16:45.510542630  \n",
       "173      0.020650     -1.0 2024-05-22 00:16:26.593446970  \n",
       "242      0.020173     -1.0 2024-05-20 20:26:57.591763496  \n",
       "243      0.023586     -1.0 2024-05-20 20:26:14.456046343  \n",
       "244      0.040736     -1.0 2024-05-20 20:24:09.416608095  \n",
       "251      0.036055     -1.0 2024-05-20 19:38:30.983223438  \n",
       "252      0.022101     -1.0 2024-05-20 19:36:36.984816551  \n",
       "253      0.039888     -1.0 2024-05-20 19:35:36.819632053  \n",
       "\n",
       "[48 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_runs_df_deduplicated[all_runs_df_deduplicated[\"compression\"] == \"SparseGPT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "# Math for determining number of interventions\n",
    "awq_settings = 5\n",
    "gptq_settings = 4 # only support quantize to [2, 3, 4, 8] bits.\n",
    "wanda_count = 6\n",
    "sparsegpt_count = 6\n",
    "editor_settings = 3\n",
    "composition_factor = 2\n",
    "\n",
    "editor_count = composition_factor * (awq_settings + gptq_settings + wanda_count + sparsegpt_count + 1) * editor_settings\n",
    "print(editor_count // 2)\n",
    "\n",
    "rmu_count = composition_factor * (awq_settings + gptq_settings + wanda_count + sparsegpt_count + editor_settings)\n",
    "print(rmu_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag                                             rmu-none\n",
       "_timestamp                             1716351267.846384\n",
       "interventions                                  [unlearn]\n",
       "edit                                                None\n",
       "unlearn                                              RMU\n",
       "compression                                         None\n",
       "model_name                                  Llama-3 (8b)\n",
       "edit_dataset                                        zsre\n",
       "number_of_edits                                       50\n",
       "rmu_layer_id                                         3.0\n",
       "wbits                                                 16\n",
       "compression_dataset                                   c4\n",
       "sparsity_ratio                                       0.0\n",
       "qa_question_count_limit                             None\n",
       "mmlu accuracy                                   0.563168\n",
       "wmdp_bio accuracy                               0.252946\n",
       "wmdp_cyber accuracy                             0.273276\n",
       "PPL                                             5.584755\n",
       "PPL edits                                   40857.453125\n",
       "PPl QA                                        401.121002\n",
       "Generalization                                  0.020667\n",
       "FLOPs                                        1.92 TFLOPS\n",
       "Success recall                                  0.008889\n",
       "Generalization recall                           0.020667\n",
       "Locality                                         0.02714\n",
       "Average bits                                        16.0\n",
       "Rewrite accuracy                                0.008889\n",
       "PPl edits unmasked                            525.180725\n",
       "Local recall                                    0.027449\n",
       "Latency                                        96.211963\n",
       "date                       2024-05-22 04:14:27.846383810\n",
       "Name: 0, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>_timestamp</th>\n",
       "      <th>interventions</th>\n",
       "      <th>edit</th>\n",
       "      <th>unlearn</th>\n",
       "      <th>compression</th>\n",
       "      <th>model_name</th>\n",
       "      <th>edit_dataset</th>\n",
       "      <th>number_of_edits</th>\n",
       "      <th>rmu_layer_id</th>\n",
       "      <th>...</th>\n",
       "      <th>FLOPs</th>\n",
       "      <th>Success recall</th>\n",
       "      <th>Generalization recall</th>\n",
       "      <th>Locality</th>\n",
       "      <th>Average bits</th>\n",
       "      <th>Rewrite accuracy</th>\n",
       "      <th>PPl edits unmasked</th>\n",
       "      <th>Local recall</th>\n",
       "      <th>Latency</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ft-rmu</td>\n",
       "      <td>1.716351e+09</td>\n",
       "      <td>[edit, unlearn]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>RMU</td>\n",
       "      <td>None</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.92 TFLOPS</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.784444</td>\n",
       "      <td>0.114612</td>\n",
       "      <td>15.999968</td>\n",
       "      <td>1.00</td>\n",
       "      <td>643.161499</td>\n",
       "      <td>0.114261</td>\n",
       "      <td>101.909465</td>\n",
       "      <td>2024-05-22 04:04:48.395482302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>memit-rmu</td>\n",
       "      <td>1.716351e+09</td>\n",
       "      <td>[edit, unlearn]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>RMU</td>\n",
       "      <td>None</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.92 TFLOPS</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.047172</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.99</td>\n",
       "      <td>518.951538</td>\n",
       "      <td>0.046733</td>\n",
       "      <td>94.809404</td>\n",
       "      <td>2024-05-22 04:03:53.009504080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>lora-rmu</td>\n",
       "      <td>1.716237e+09</td>\n",
       "      <td>[edit, unlearn]</td>\n",
       "      <td>Lora</td>\n",
       "      <td>RMU</td>\n",
       "      <td>None</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.79 TFLOPS</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.618571</td>\n",
       "      <td>0.057981</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>25660.986328</td>\n",
       "      <td>0.058719</td>\n",
       "      <td>512.197093</td>\n",
       "      <td>2024-05-20 20:31:09.500632286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           tag    _timestamp    interventions       edit unlearn compression  \\\n",
       "2       ft-rmu  1.716351e+09  [edit, unlearn]  Fine-tune     RMU        None   \n",
       "1    memit-rmu  1.716351e+09  [edit, unlearn]      MEMIT     RMU        None   \n",
       "238   lora-rmu  1.716237e+09  [edit, unlearn]       Lora     RMU        None   \n",
       "\n",
       "       model_name edit_dataset  number_of_edits  rmu_layer_id  ...  \\\n",
       "2    Llama-3 (8b)         zsre               50           5.0  ...   \n",
       "1    Llama-3 (8b)         zsre               50           5.0  ...   \n",
       "238  Llama-3 (8b)         zsre               50           5.0  ...   \n",
       "\n",
       "           FLOPs Success recall  Generalization recall  Locality  \\\n",
       "2    1.92 TFLOPS           1.00               0.784444  0.114612   \n",
       "1    1.92 TFLOPS           0.99               0.886667  0.047172   \n",
       "238  1.79 TFLOPS           1.00               0.618571  0.057981   \n",
       "\n",
       "     Average bits  Rewrite accuracy  PPl edits unmasked  Local recall  \\\n",
       "2       15.999968              1.00          643.161499      0.114261   \n",
       "1       16.000000              0.99          518.951538      0.046733   \n",
       "238     16.000000              1.00        25660.986328      0.058719   \n",
       "\n",
       "        Latency                          date  \n",
       "2    101.909465 2024-05-22 04:04:48.395482302  \n",
       "1     94.809404 2024-05-22 04:03:53.009504080  \n",
       "238  512.197093 2024-05-20 20:31:09.500632286  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(categories[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnlearn\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(categories[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnlearn\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     34\u001b[0m display(categories[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEdit to Unlearn\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(categories[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEdit to Unlearn\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     37\u001b[0m display(categories[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnlearn to Edit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(categories[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnlearn to Edit\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = all_runs_df_deduplicated\n",
    "\n",
    "categories = {\n",
    "    \"No Intervention\": data[data[\"interventions\"].apply(lambda x: x == [])].copy(),\n",
    "    \"Editing\": data[data[\"interventions\"].apply(lambda x: x == [\"edit\"])].copy(),\n",
    "    \"Compression\": data[data[\"interventions\"].apply(lambda x: x == [\"compress\"])].copy(),\n",
    "    \"Edit to Compression\": data[data[\"interventions\"].apply(lambda x: x == [\"edit\", \"compress\"])].copy(),\n",
    "    \"Compression to Edit\": data[data[\"interventions\"].apply(lambda x: x == [\"compress\", \"edit\"])].copy(),\n",
    "    \"Unlearn\": data[data[\"interventions\"].apply(lambda x: x == [\"unlearn\"])].copy(),\n",
    "    \"Edit to Unlearn\": data[data[\"interventions\"].apply(lambda x: x == [\"edit\", \"unlearn\"])].copy(),\n",
    "    \"Unlearn to Edit\": data[data[\"interventions\"].apply(lambda x: x == [\"unlearn\", \"edit\"])].copy(),\n",
    "    \"Compress to Unlearn\": data[data[\"interventions\"].apply(lambda x: x == [\"compress\", \"unlearn\"])].copy(),\n",
    "    \"Unlearn to Compress\": data[data[\"interventions\"].apply(lambda x: x == [\"unlearn\", \"compress\"])].copy()\n",
    "}\n",
    "\n",
    "# assert len(categories[\"No Intervention\"]) == 0 # Should be 1\n",
    "\n",
    "# display(categories[\"Editing\"])\n",
    "assert len(categories[\"Editing\"]) == 3, f\"{len(categories['Editing'])} != 3\"\n",
    "\n",
    "# display(categories[\"Compression\"])\n",
    "# assert len(categories[\"Compression\"]) == (awq_settings + gptq_settings + wanda_count + sparsegpt_count), f\"{len(categories['Compression'])} != {awq_settings + gptq_settings + wanda_count + sparsegpt_count}\"\n",
    "\n",
    "# display(categories[\"Edit to Compression\"])\n",
    "assert len(categories[\"Edit to Compression\"]) == editor_count // 2, f\"{len(categories['Edit to Compression'])} != {editor_count // 2}\"\n",
    "\n",
    "# display(categories[\"Compression to Edit\"])\n",
    "# Missing Wanda0.25%-to-lora, Wanda0.45%-to-lora, Wanda0.65%-to-lora, \n",
    "assert len(categories[\"Compression to Edit\"]) == (editor_count // 2 )- 3, f\"{len(categories['Compression to Edit'])} != {editor_count // 2}\" # TODO: Fix this by getting the latest results\n",
    "\n",
    "display(categories[\"Unlearn\"].iloc[0])\n",
    "assert len(categories[\"Unlearn\"]) == 1, f\"{len(categories['Unlearn'])} != 1\"\n",
    "\n",
    "display(categories[\"Edit to Unlearn\"])\n",
    "assert len(categories[\"Edit to Unlearn\"]) == 0\n",
    "\n",
    "display(categories[\"Unlearn to Edit\"])\n",
    "assert len(categories[\"Unlearn to Edit\"]) == 0\n",
    "\n",
    "display(categories[\"Compress to Unlearn\"])\n",
    "assert len(categories[\"Compress to Unlearn\"]) == 0\n",
    "\n",
    "display(categories[\"Unlearn to Compress\"])\n",
    "assert len(categories[\"Unlearn to Compress\"]) == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_flops(value):\n",
    "    \"\"\" Format FLOPs with three significant figures and appropriate suffix. \"\"\"\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            value = clean_numeric_value(value)\n",
    "        if abs(value) < 1e6:  # Less than 1 million (below Mega)\n",
    "            return \"{:.3g}k\".format(value / 1e3)\n",
    "        elif abs(value) < 1e9:  # Mega to Giga range\n",
    "            return \"{:.3g}M\".format(value / 1e6)\n",
    "        elif abs(value) < 1e12:  # Giga to Tera range\n",
    "            return \"{:.3g}G\".format(value / 1e9)\n",
    "        else:  # Tera and above\n",
    "            return \"{:.3g}T\".format(value / 1e12)\n",
    "    except Exception as e:\n",
    "        print(f\"Error formatting FLOPs value {value}: {e}\")\n",
    "        return \"---\"\n",
    "\n",
    "def escape_latex_special_chars(s):\n",
    "    \"\"\" Escape special characters in LaTeX strings. \"\"\"\n",
    "    return str(s).replace('%', '\\\\%').replace('_', '\\\\_').replace('&', '\\\\&').replace('#', '\\\\#').replace('$', '\\\\$')\n",
    "\n",
    "def clean_numeric_value(value):\n",
    "    \"\"\" Convert a string with units to a numeric value. \"\"\"\n",
    "    try:\n",
    "        value = str(value)\n",
    "        if ' TFLOPS' in value:\n",
    "            return float(value.replace(' TFLOPS', '')) * 1e12\n",
    "        if ' GFLOPS' in value:\n",
    "            return float(value.replace(' GFLOPS', '')) * 1e9\n",
    "        if ' MFLOPS' in value:\n",
    "            return float(value.replace(' MFLOPS', '')) * 1e6\n",
    "        if ' kFLOPS' in value:\n",
    "            return float(value.replace(' kFLOPS', '')) * 1e3\n",
    "        return pd.to_numeric(value, errors='coerce')\n",
    "    except Exception as e:\n",
    "        print(f\"Error cleaning value {value}: {e}\")\n",
    "        return pd.NA\n",
    "\n",
    "def categorize_and_generate_latex(data):\n",
    "    # Define categories based on the provided criteria\n",
    "    categories = {\n",
    "    \"No Intervention\": data[data['interventions'].apply(lambda x: x == [])].copy(),\n",
    "    \"Editing\": data[data['interventions'].apply(lambda x: x == ['edit'])].copy(),\n",
    "    \"Compression\": data[data['interventions'].apply(lambda x: x == ['compress'])].copy(),\n",
    "    \"Edit to Compression\": data[data['interventions'].apply(lambda x: x == ['edit', 'compress'])].copy(),\n",
    "    \"Compression to Edit\": data[data['interventions'].apply(lambda x: x == ['compress', 'edit'])].copy(),\n",
    "    \"Unlearn\": data[data['interventions'].apply(lambda x: x == ['unlearn'])].copy(),\n",
    "    \"Edit to Unlearn\": data[data['interventions'].apply(lambda x: x == ['edit', 'unlearn'])].copy(),\n",
    "    \"Unlearn to Edit\": data[data['interventions'].apply(lambda x: x == ['unlearn', 'edit'])].copy(),\n",
    "    \"Compress to Unlearn\": data[data['interventions'].apply(lambda x: x == ['compress', 'unlearn'])].copy(),\n",
    "    \"Unlearn to Compress\": data[data['interventions'].apply(lambda x: x == ['unlearn', 'compress'])].copy()\n",
    "}\n",
    "    # Clean numeric columns\n",
    "    for col in [\"FLOPs\", \"Latency\"]:\n",
    "        if col in data.columns:\n",
    "            data.loc[:, col] = data[col].apply(clean_numeric_value)\n",
    "            data.loc[:, col] = pd.to_numeric(data[col], errors='coerce')  # Ensure all values are numeric\n",
    "\n",
    "    # Column mappings\n",
    "    column_mappings = {\n",
    "        \"Success\": \"Rewrite accuracy\",\n",
    "        \"Generalization\": \"Generalization\",\n",
    "        \"Locality\": \"Locality\",\n",
    "        \"Avg. Bits\": \"Average bits\",\n",
    "        \"FLOPs\": \"FLOPs\",\n",
    "        \"PPL\": \"PPL\",\n",
    "        \"MMLU\": \"mmlu accuracy\",\n",
    "        \"WMDP Bio\": \"wmdp_bio accuracy\",\n",
    "        \"WMDP Cyber\": \"wmdp_cyber accuracy\"\n",
    "    }\n",
    "    latex_columns = [\"Success\", \"Generalization\", \"Locality\", \"Avg. Bits\", \"FLOPs\", \"PPL\", \"MMLU\", \"WMDP Bio\", \"WMDP Cyber\"]\n",
    "\n",
    "    # Initialize output string\n",
    "    output_str = \"\"\n",
    "\n",
    "    for category, group in categories.items():\n",
    "        if group.empty:\n",
    "            continue\n",
    "        # output_str += f\"\\\\textbf{{{category}}} \\\\\\\\ \\\\midline\\n\"\n",
    "        for _, row in group.iterrows():\n",
    "            # Calculate mean and std for each relevant column within the group\n",
    "            stats = {}\n",
    "            for latex_col, csv_col in column_mappings.items():\n",
    "                if csv_col in row.index:\n",
    "                    value = row[csv_col]\n",
    "                    if pd.isna(value):\n",
    "                        stats[latex_col] = \"---\"\n",
    "                    else:\n",
    "                        # Custom formatting for FLOPs and Latency\n",
    "                        if latex_col == \"FLOPs\":\n",
    "                            mean_str = format_flops(value)\n",
    "                            stats[latex_col] = escape_latex_special_chars(mean_str)\n",
    "                        elif latex_col == \"Latency\":\n",
    "                            mean_str = f\"{value:.3f}s\"\n",
    "                            stats[latex_col] = escape_latex_special_chars(mean_str)\n",
    "                        else:\n",
    "                            mean_str = f\"{value:.3f}\"\n",
    "                            stats[latex_col] = escape_latex_special_chars(mean_str)\n",
    "                else:\n",
    "                    stats[latex_col] = \"---\"\n",
    "\n",
    "            # Prepare the LaTeX row for the current group\n",
    "            latex_row = escape_latex_special_chars(row['tag'])  # Use the tag name directly without escaping\n",
    "            for column in latex_columns:\n",
    "                latex_row += \" & \" + stats.get(column, \"---\")\n",
    "            latex_row += \" \\\\\\\\\"\n",
    "\n",
    "            # Append to output string\n",
    "            output_str += latex_row + \"\\n\"\n",
    "        \n",
    "        output_str += \"\\\\midrule\\n\"\n",
    "\n",
    "    return output_str\n",
    "\n",
    "latex_rows_with_categories = categorize_and_generate_latex(all_runs_df_deduplicated)\n",
    "print(latex_rows_with_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the font family to serif\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "# Assuming 'metrics' DataFrame is already loaded from the CSV\n",
    "\n",
    "# Define the criteria for filtering\n",
    "selected_method = 'AWQ'\n",
    "edit_method = [\"FT\"]\n",
    "\n",
    "# Filter based on the criteria\n",
    "edit_then_compress = categories['Edit to Compression']\n",
    "compress_then_edit = categories['Compression to Edit']\n",
    "\n",
    "# Filter based on selected method\n",
    "edit_then_compress = edit_then_compress[edit_then_compress['compression']==selected_method]\n",
    "compress_then_edit = compress_then_edit[compress_then_edit['compression']==selected_method]\n",
    "\n",
    "# Add baselines to dfs\n",
    "baseline = categories['Editing']\n",
    "baseline['wbits'] = 16\n",
    "edit_then_compress = pd.concat([edit_then_compress, baseline], axis=0)\n",
    "compress_then_edit = pd.concat([compress_then_edit, baseline], axis=0)\n",
    "\n",
    "# Sort by 'wbits' in ascending order\n",
    "edit_then_compress = edit_then_compress.sort_values(by='wbits')\n",
    "compress_then_edit = compress_then_edit.sort_values(by='wbits')\n",
    "\n",
    "# Define the metrics to plot\n",
    "metrics_to_plot = ['Rewrite accuracy', 'Generalization', 'mmlu']\n",
    "x_axis_metric = 'wbits'\n",
    "\n",
    "# Compute baselines\n",
    "# edit_then_compress_baselines = {model: edit_then_compress[(edit_then_compress['model_name'] == model) & (edit_then_compress['sparsity_ratio'] == 0)][metrics_to_plot].mean() for model in included_models}\n",
    "# compress_then_edit_baselines = {model: compress_then_edit[(compress_then_edit['model_name'] == model) & (compress_then_edit['sparsity_ratio'] == 0)][metrics_to_plot].mean() for model in included_models}\n",
    "# edit_then_compress_baselines = categories['No Intervention']\n",
    "# compress_then_edit_baselines = categories['No Intervention']\n",
    "\n",
    "# Define plot parameters\n",
    "title_fontsize = 20\n",
    "label_fontsize = 20\n",
    "legend_fontsize = 18\n",
    "tick_fontsize = 18\n",
    "line_width = 3\n",
    "marker_size = 8\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, len(metrics_to_plot), figsize=(15, 5))\n",
    "\n",
    "# Iterate over each metric and plot\n",
    "for i, metric in enumerate(metrics_to_plot):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot the data with scatter and lines\n",
    "    ax.plot(edit_then_compress['wbits'], edit_then_compress[metric], linestyle='--', marker='o', markerfacecolor='purple', color='purple', label='Edit then compress',\n",
    "            linewidth=line_width, markersize=marker_size, markeredgewidth=line_width)\n",
    "    ax.plot(compress_then_edit['wbits'], compress_then_edit[metric], linestyle='-', marker='o', markerfacecolor='none', color='purple', label='Compress then edit',\n",
    "            linewidth=line_width, markersize=marker_size, markeredgewidth=line_width)\n",
    "    \n",
    "    # Fill the area between the lines\n",
    "    ax.fill_between(edit_then_compress['wbits'], edit_then_compress[metric], compress_then_edit[metric], color='purple', alpha=0.2)\n",
    "    \n",
    "    # Integrate baselines into the scatter plots\n",
    "    for model in included_models:\n",
    "        baseline_edit = edit_then_compress_baselines[metric]\n",
    "        baseline_compress = compress_then_edit_baselines[metric]\n",
    "        \n",
    "        if x_axis_metric == 'Average bits':\n",
    "            baseline_x = 16\n",
    "            ax.set_xlim(2, 16)\n",
    "        elif x_axis_metric == 'sparsity_ratio':\n",
    "            baseline_x = 0.0\n",
    "            ax.set_xlim(0, 1)\n",
    "        else:\n",
    "            baseline_x = 0  # Adjust based on your default x-axis range\n",
    "\n",
    "        # Add baselines to the scatter plots\n",
    "        # ax.scatter([baseline_x], [baseline_edit], color='purple', marker='o', s=marker_size**2, edgecolor='purple', linewidth=line_width)\n",
    "        # ax.scatter([baseline_x], [baseline_compress], color='purple', marker='o', s=marker_size**2, edgecolor='purple', linewidth=line_width)\n",
    "    if x_axis_metric == 'wbits':\n",
    "        ax.set_xlabel('Bits', fontsize=label_fontsize)\n",
    "    else:\n",
    "        ax.set_xlabel(x_axis_metric, fontsize=label_fontsize)\n",
    "    if metric == 'Rewrite accuracy':\n",
    "        ax.set_ylabel('Edit success', fontsize=label_fontsize)\n",
    "    else:\n",
    "        ax.set_ylabel(metric, fontsize=label_fontsize)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "\n",
    "# Move the legend to the bottom of the figure\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', fontsize=legend_fontsize, ncol=2)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.1, 1, 1])  # Adjust the bottom margin to make space for the legend\n",
    "plt.show()\n",
    "plt.savefig('figures/memit-gptq.pdf', format='pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
