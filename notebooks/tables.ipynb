{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import ast\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import wandb\n",
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting_columns = [\n",
    "    # Overall\n",
    "    \"tag\",\n",
    "    # \"seed\",\n",
    "    \"_timestamp\",\n",
    "\n",
    "    # Interventions\n",
    "    \"interventions\", \"edit\", \"unlearn\", \"compression\", \"model_name\",\n",
    "\n",
    "    # Editing\n",
    "    # \"edit_set\", \n",
    "    \"edit_dataset\", \"number_of_edits\",\n",
    "\n",
    "    # Unlearning\n",
    "    \"rmu_layer_id\",\n",
    "\n",
    "    # Compression\n",
    "    \"wbits\", \"compression_dataset\", \"sparsity_ratio\",\n",
    "]\n",
    "evaluation_columns = [\n",
    "    \"qa_question_count_limit\",  # An artifical max number of questions to ask during evaluation. Should be none when not debugging.\n",
    "    \"mmlu accuracy\",            # The accuracy of the model on the MMLU dataset. This measures overall model utility. Llama-3 should be ~62%\n",
    "    \"wmdp_bio accuracy\",        # The accuracy of the model on the WMDP bio split. This is the unlearning target. Should be ~25% when RMU is applied.\n",
    "    \"wmdp_cyber accuracy\",      # The accuracy of the model on the WMDP cyber split. This is the unlearning target. Should be ~25% when RMU is applied.\n",
    "    \"PPL\",                      # TODO:\n",
    "    \"PPL edits\",                # Perplexity for the edits. Should be low when editing is applied.\n",
    "    \"PPl QA\",                   # Perplexity for the QA. Should be low when QA is applied.\n",
    "    \"Generalization\",           # TODO: \n",
    "    \"FLOPs\",                    # TODO: \n",
    "    \"Success recall\",           # TODO:\n",
    "    \"Generalization recall\",    # TODO:\n",
    "    \"Locality\",                 # TODO:\n",
    "    \"Average bits\",             # TODO:\n",
    "    \"Rewrite accuracy\",         # TODO:\n",
    "    \"PPl edits unmasked\",       # TODO:\n",
    "    \"Local recall\",             # TODO:\n",
    "    \"Latency\",                  # TODO:\n",
    "]\n",
    "relevant_columns = setting_columns + evaluation_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/Composable_Interventions: 100%|██████████| 305/305 [00:02<00:00, 150.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing run n0iel6ok: '_timestamp'\n",
      "Error processing run xr5mede5: '_timestamp'\n",
      "Error processing run 27f8pxs0: '_timestamp'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace 'username/project_name' with your specific project path\n",
    "# Composable_Interventions\n",
    "project_paths = [\n",
    "    'dri-ice/Composable_Interventions',\n",
    "    # 'dri-ice/AK_Tests'\n",
    "]\n",
    "\n",
    "filter_dict = { \n",
    "    \"state\": \"finished\",\n",
    "    # \"created_at\": {\"$gte\": \"2024-05-20\"}\n",
    "}\n",
    "data_frames = []\n",
    "for project_path in project_paths:\n",
    "    runs = api.runs(project_path, filters=filter_dict)\n",
    "    \n",
    "    # Iterate over eachrun and capture the config and summary metrics\n",
    "    for run in tqdm(runs, desc=project_path):\n",
    "        try:\n",
    "            run_start_datetime = datetime.fromtimestamp(run.summary_metrics[\"_timestamp\"])\n",
    "            start_cutoff = datetime.strptime(\"2024-05-18 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "            end_cutoff = datetime.strptime(\"2024-05-23 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "            if run_start_datetime < start_cutoff or run_start_datetime > end_cutoff:\n",
    "                continue\n",
    "\n",
    "            skip_tags = [\"test\", \"hparam_search\"]\n",
    "            should_skip = False\n",
    "            for tag in skip_tags:\n",
    "                if tag in run.config[\"tag\"].lower():\n",
    "                    should_skip = True\n",
    "            \n",
    "            if should_skip:\n",
    "                continue\n",
    "\n",
    "            config_frame = pd.DataFrame([run.config])\n",
    "            summary_frame = pd.DataFrame([run.summary_metrics])\n",
    "            combined_frame = pd.concat([config_frame, summary_frame], axis=1)\n",
    "            data_frames.append(combined_frame)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing run {run.id}: {e}\")\n",
    "\n",
    "# Sort by 'tag' and '_timestamp' in descending order to have the most recent run first\n",
    "all_runs_df = pd.concat(data_frames, ignore_index=True)[relevant_columns]\n",
    "all_runs_df[\"interventions\"] = all_runs_df[\"interventions\"].astype(str)\n",
    "\n",
    "# WARNING: WHAT DOES EDIT SET 50 MEAN COMPARED TO EDIT SET 1?\n",
    "# all_runs_df = all_runs_df[all_runs_df[\"edit_set\"] == 50]\n",
    "# all_runs_df_sorted = all_runs_df.sort_values(by=['tag', '_timestamp'], ascending=[True, False])\n",
    "all_runs_df[\"date\"] = pd.to_datetime(all_runs_df[\"_timestamp\"], unit='s')\n",
    "all_runs_df_sorted = all_runs_df.sort_values(by=['_timestamp'], ascending=[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Ensure that max number of questions is set to None \n",
    "# TODO: Ensure that rmu_layer_id is 3. This was originaly set to 5, but Kyle decided to rerun the evals last minute with a better hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_143838/787060927.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_runs_df_deduplicated[\"interventions\"] = all_runs_df_deduplicated[\"interventions\"].apply(lambda x : ast.literal_eval(x))\n",
      "/tmp/ipykernel_143838/787060927.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metrics[\"model_name\"] = metrics[\"model_name\"].apply(lambda x : rename_dict.get(x, None))\n",
      "/tmp/ipykernel_143838/787060927.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metrics[\"edit\"] = metrics[\"edit\"].apply(lambda x : rename_dict.get(x, None))\n",
      "/tmp/ipykernel_143838/787060927.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metrics[\"compression\"] = metrics[\"compression\"].apply(lambda x : rename_dict.get(x, None))\n",
      "/tmp/ipykernel_143838/787060927.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metrics[\"unlearn\"] = metrics[\"unlearn\"].apply(lambda x : rename_dict.get(x, None))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tag\n",
       "AWQ2bit-to-ft              1\n",
       "lora-to-SparseGPT0.35%     1\n",
       "lora-to-AWQ4bit            1\n",
       "lora-to-AWQ5bit            1\n",
       "lora-to-AWQ6bit            1\n",
       "                          ..\n",
       "SparseGPT0.55%-to-memit    1\n",
       "SparseGPT0.65%-to-ft       1\n",
       "SparseGPT0.65%-to-lora     1\n",
       "SparseGPT0.65%-to-memit    1\n",
       "wanda0.65\\%-rmu            1\n",
       "Name: count, Length: 187, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicates, keeping only the first occurrence (which is the most recent due to sorting)\n",
    "# all_runs_df_deduplicated = all_runs_df_sorted.drop_duplicates(subset=[col for col in setting_columns if col not in [\"_timestamp\", \"tag\", \"date\"]], keep=\"first\")\n",
    "all_runs_df_deduplicated = all_runs_df_sorted.drop_duplicates(subset=\"tag\", keep=\"first\")\n",
    "all_runs_df_deduplicated[\"interventions\"] = all_runs_df_deduplicated[\"interventions\"].apply(lambda x : ast.literal_eval(x))\n",
    "\n",
    "rename_dict = {\n",
    "    \"meta-llama/Meta-Llama-3-8B\" : \"Llama-3 (8b)\",\n",
    "    \"ft\" : \"Fine-tune\",\n",
    "    \"memit\" : \"MEMIT\",\n",
    "    \"lora\" : \"Lora\",\n",
    "    \"wanda\" : \"Wanda\",\n",
    "    \"sparsegpt\" : \"SparseGPT\",\n",
    "    \"gptq\" : \"GPTQ\",\n",
    "    \"awq\" : \"AWQ\",\n",
    "    \"rmu\" : \"RMU\",\n",
    "}\n",
    "metrics = all_runs_df_deduplicated\n",
    "metrics[\"model_name\"] = metrics[\"model_name\"].apply(lambda x : rename_dict.get(x, None))\n",
    "metrics[\"edit\"] = metrics[\"edit\"].apply(lambda x : rename_dict.get(x, None))\n",
    "metrics[\"compression\"] = metrics[\"compression\"].apply(lambda x : rename_dict.get(x, None))\n",
    "metrics[\"unlearn\"] = metrics[\"unlearn\"].apply(lambda x : rename_dict.get(x, None))\n",
    "all_runs_df_deduplicated = metrics\n",
    "all_runs_df_deduplicated.value_counts(\"tag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "# TODO: Get a second pair of eyes on this this math\n",
    "\n",
    "# Math for determining number of interventions\n",
    "awq_settings = 5\n",
    "gptq_settings = 4 # only support quantize to [2, 3, 4, 8] bits.\n",
    "wanda_count = 6\n",
    "sparsegpt_count = 6\n",
    "editor_settings = 3\n",
    "composition_factor = 2\n",
    "\n",
    "editor_count = composition_factor * (awq_settings + gptq_settings + wanda_count + sparsegpt_count + 1) * editor_settings\n",
    "print(editor_count // 2)\n",
    "\n",
    "rmu_count = composition_factor * (awq_settings + gptq_settings + wanda_count + sparsegpt_count + editor_settings)\n",
    "print(rmu_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = all_runs_df_deduplicated\n",
    "\n",
    "categories = {\n",
    "    \"No Intervention\": data[data[\"interventions\"].apply(lambda x: x == [])].copy(),\n",
    "    \"Editing\": data[data[\"interventions\"].apply(lambda x: x == [\"edit\"])].copy(),\n",
    "    \"Compression\": data[data[\"interventions\"].apply(lambda x: x == [\"compress\"])].copy(),\n",
    "    \"Edit to Compression\": data[data[\"interventions\"].apply(lambda x: x == [\"edit\", \"compress\"])].copy(),\n",
    "    \"Compression to Edit\": data[data[\"interventions\"].apply(lambda x: x == [\"compress\", \"edit\"])].copy(),\n",
    "    \"Unlearn\": data[data[\"interventions\"].apply(lambda x: x == [\"unlearn\"])].copy(),\n",
    "    \"Edit to Unlearn\": data[data[\"interventions\"].apply(lambda x: x == [\"edit\", \"unlearn\"])].copy(),\n",
    "    \"Unlearn to Edit\": data[data[\"interventions\"].apply(lambda x: x == [\"unlearn\", \"edit\"])].copy(),\n",
    "    \"Compress to Unlearn\": data[data[\"interventions\"].apply(lambda x: x == [\"compress\", \"unlearn\"])].copy(),\n",
    "    \"Unlearn to Compress\": data[data[\"interventions\"].apply(lambda x: x == [\"unlearn\", \"compress\"])].copy()\n",
    "}\n",
    "\n",
    "assert len(categories[\"No Intervention\"]) == 1, f\"{len(categories['No Intervention'])} != 1\"\n",
    "assert len(categories[\"Editing\"]) == 3, f\"{len(categories['Editing'])} != 3\"\n",
    "\n",
    "# display(categories[\"Compression\"])\n",
    "# assert len(categories[\"Compression\"]) == (awq_settings + gptq_settings + wanda_count + sparsegpt_count), f\"{len(categories['Compression'])} != {awq_settings + gptq_settings + wanda_count + sparsegpt_count}\"\n",
    "\n",
    "assert len(categories[\"Edit to Compression\"]) == editor_count // 2, f\"{len(categories['Edit to Compression'])} != {editor_count // 2}\"\n",
    "\n",
    "# display(categories[\"Compression to Edit\"])\n",
    "# Missing Wanda0.25%-to-lora, Wanda0.45%-to-lora, Wanda0.65%-to-lora, \n",
    "# assert len(categories[\"Compression to Edit\"]) == (editor_count // 2 )- 3, f\"{len(categories['Compression to Edit'])} != {editor_count // 2}\" # TODO: Fix this by getting the latest results\n",
    "assert len(categories[\"Unlearn\"]) == 1, f\"{len(categories['Unlearn'])} != 1\"\n",
    "assert len(categories[\"Edit to Unlearn\"]) == 3\n",
    "assert len(categories[\"Unlearn to Edit\"]) == 3, f\"{len(categories['Unlearn to Edit'])} != 3\"\n",
    "\n",
    "# display(categories[\"Compress to Unlearn\"])\n",
    "# assert len(categories[\"Compress to Unlearn\"]) == rmu_count // 2, f\"{len(categories['Compress to Unlearn'])} != {rmu_count // 2}\"\n",
    "\n",
    "# display(categories[\"Unlearn to Compress\"])\n",
    "# assert len(categories[\"Unlearn to Compress\"]) == rmu_count // 2, f\"{len(categories['Unlearn to Compress'])} != {rmu_count // 2}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None & 0.009 & 0.021 & 0.027 & 16.000 & 1.92T & 5.540 & 0.621 & 0.714 & 0.442 \\\\\n",
      "\\midrule\n",
      "lora\\_Edit & 1.000 & 0.647 & 0.030 & 16.000 & 1.79T & 21.656 & 0.607 & 0.700 & 0.444 \\\\\n",
      "memit\\_Edit & 0.990 & 0.887 & 0.050 & 16.000 & 1.92T & 5.570 & 0.602 & 0.687 & 0.435 \\\\\n",
      "ft\\_Edit & 1.000 & 0.769 & 0.117 & 16.000 & 1.92T & 5.570 & 0.611 & 0.690 & 0.438 \\\\\n",
      "\\midrule\n",
      "Compress\\_GPTQ8bit & 0.009 & 0.021 & 0.024 & 8.250 & -0.001k & 5.539 & 0.622 & 0.713 & 0.439 \\\\\n",
      "Compress\\_GPTQ4bit & 0.000 & 0.009 & 0.018 & 4.250 & -0.001k & 14.088 & 0.600 & 0.682 & 0.441 \\\\\n",
      "Compress\\_GPTQ2bit & 0.000 & 0.000 & 0.023 & 2.250 & -0.001k & 2089.334 & 0.237 & 0.254 & 0.255 \\\\\n",
      "Compress\\_AWQ4bit & 0.000 & 0.011 & 0.027 & 4.250 & -0.001k & 5.911 & 0.598 & 0.687 & 0.456 \\\\\n",
      "Compress\\_AWQ8bit & 0.009 & 0.021 & 0.027 & 8.250 & -0.001k & 5.540 & 0.621 & 0.713 & 0.444 \\\\\n",
      "Compress\\_AWQ2bit & 0.000 & 0.000 & 0.000 & 2.250 & -0.001k & 1748954.750 & 0.269 & 0.240 & 0.246 \\\\\n",
      "Compress\\_SparseGPT0.65\\% & 0.009 & 0.004 & 0.018 & 6.250 & 760G & 21.760 & 0.246 & 0.263 & 0.268 \\\\\n",
      "Compress\\_SparseGPT0.45\\% & 0.009 & 0.017 & 0.019 & 9.250 & 1.12T & 7.434 & 0.533 & 0.636 & 0.395 \\\\\n",
      "Compress\\_SparseGPT0.25\\% & 0.009 & 0.021 & 0.027 & 12.250 & 1.47T & 5.866 & 0.606 & 0.692 & 0.432 \\\\\n",
      "Compress\\_Wanda0.65\\% & 0.021 & 0.017 & 0.023 & 6.251 & 760G & 48.091 & 0.229 & 0.248 & 0.265 \\\\\n",
      "Compress\\_Wanda0.45\\% & 0.009 & 0.014 & 0.017 & 9.251 & 1.12T & 7.516 & 0.526 & 0.609 & 0.388 \\\\\n",
      "Compress\\_Wanda0.25\\% & 0.009 & 0.017 & 0.029 & 12.250 & 1.47T & 5.843 & 0.605 & 0.694 & 0.434 \\\\\n",
      "Compress\\_GPTQ3bit & 0.009 & 0.007 & 0.017 & 3.250 & -0.001k & 8.585 & 0.471 & 0.519 & 0.374 \\\\\n",
      "Compress\\_AWQ6bit & 0.004 & 0.021 & 0.033 & 6.250 & -0.001k & 5.559 & 0.622 & 0.713 & 0.444 \\\\\n",
      "Compress\\_AWQ5bit & 0.009 & 0.011 & 0.023 & 5.250 & -0.001k & 5.623 & 0.623 & 0.704 & 0.435 \\\\\n",
      "Compress\\_SparseGPT0.55\\% & 0.009 & 0.007 & 0.011 & 7.750 & 938G & 10.511 & 0.444 & 0.536 & 0.358 \\\\\n",
      "Compress\\_SparseGPT0.75\\% & 0.018 & 0.000 & 0.012 & 4.750 & 581G & 81.077 & 0.229 & 0.248 & 0.266 \\\\\n",
      "Compress\\_SparseGPT0.35\\% & 0.000 & 0.021 & 0.025 & 10.750 & 1.3T & 6.356 & 0.584 & 0.666 & 0.429 \\\\\n",
      "Compress\\_AWQ3bit & 0.009 & 0.007 & 0.015 & 3.250 & -0.001k & 7.470 & 0.527 & 0.634 & 0.406 \\\\\n",
      "Compress\\_Wanda0.75\\% & 0.022 & 0.008 & 0.020 & 4.750 & 581G & 287.622 & 0.230 & 0.253 & 0.266 \\\\\n",
      "Compress\\_Wanda0.55\\% & 0.009 & 0.000 & 0.005 & 7.752 & 939G & 12.476 & 0.351 & 0.361 & 0.312 \\\\\n",
      "Compress\\_Wanda0.35\\% & 0.009 & 0.017 & 0.028 & 10.752 & 1.3T & 6.311 & 0.581 & 0.660 & 0.419 \\\\\n",
      "\\midrule\n",
      "memit-to-GPTQ8bit & 0.787 & 0.743 & 0.014 & 8.250 & -0.001k & 5.569 & 0.594 & 0.683 & 0.442 \\\\\n",
      "memit-to-GPTQ4bit & 0.678 & 0.616 & 0.011 & 4.250 & -0.001k & 22.040 & 0.570 & 0.660 & 0.430 \\\\\n",
      "memit-to-GPTQ2bit & 0.016 & 0.010 & 0.026 & 2.250 & -0.001k & 1430.710 & 0.234 & 0.252 & 0.266 \\\\\n",
      "lora-to-GPTQ8bit & 1.000 & 0.715 & 0.048 & 8.250 & -0.001k & 23.464 & 0.607 & 0.686 & 0.446 \\\\\n",
      "ft-to-GPTQ8bit & 1.000 & 0.782 & 0.109 & 8.250 & -0.001k & 5.568 & 0.611 & 0.695 & 0.435 \\\\\n",
      "ft-to-GPTQ4bit & 0.859 & 0.592 & 0.110 & 4.250 & -0.001k & 19.882 & 0.589 & 0.658 & 0.417 \\\\\n",
      "lora-to-GPTQ4bit & 0.729 & 0.505 & 0.036 & 4.250 & -0.001k & 85.702 & 0.584 & 0.679 & 0.425 \\\\\n",
      "ft-to-GPTQ2bit & 0.004 & 0.000 & 0.016 & 2.250 & -0.001k & 2284.261 & 0.233 & 0.254 & 0.253 \\\\\n",
      "lora-to-GPTQ2bit & 0.000 & 0.000 & 0.017 & 2.250 & -0.001k & 9494.032 & 0.252 & 0.236 & 0.250 \\\\\n",
      "memit-to-AWQ8bit & 0.802 & 0.767 & 0.013 & 8.250 & -0.001k & 5.568 & 0.592 & 0.684 & 0.441 \\\\\n",
      "memit-to-AWQ4bit & 0.790 & 0.761 & 0.012 & 4.250 & -0.001k & 5.945 & 0.567 & 0.658 & 0.430 \\\\\n",
      "memit-to-AWQ2bit & 0.000 & 0.000 & 0.000 & 2.250 & -0.001k & 1738131.875 & 0.269 & 0.240 & 0.246 \\\\\n",
      "lora-to-AWQ8bit & 1.000 & 0.690 & 0.057 & 8.250 & -0.001k & 23.326 & 0.605 & 0.683 & 0.447 \\\\\n",
      "lora-to-AWQ2bit & 0.000 & 0.000 & 0.000 & 2.250 & -0.001k & 1770048.625 & 0.247 & 0.247 & 0.243 \\\\\n",
      "ft-to-AWQ2bit & 0.000 & 0.000 & 0.000 & 2.250 & -0.001k & 1749999.250 & 0.269 & 0.240 & 0.246 \\\\\n",
      "ft-to-AWQ4bit & 0.985 & 0.722 & 0.126 & 4.250 & -0.001k & 5.944 & 0.591 & 0.665 & 0.424 \\\\\n",
      "ft-to-AWQ8bit & 1.000 & 0.782 & 0.109 & 8.250 & -0.001k & 5.568 & 0.610 & 0.689 & 0.437 \\\\\n",
      "lora-to-AWQ4bit & 0.914 & 0.644 & 0.041 & 4.250 & -0.001k & 25.178 & 0.589 & 0.666 & 0.430 \\\\\n",
      "memit-to-SparseGPT0.25\\% & 0.776 & 0.705 & 0.032 & 12.250 & 1.47T & 5.892 & 0.588 & 0.672 & 0.413 \\\\\n",
      "memit-to-SparseGPT0.65\\% & 0.017 & 0.023 & 0.013 & 6.250 & 760G & 21.666 & 0.247 & 0.269 & 0.267 \\\\\n",
      "memit-to-SparseGPT0.45\\% & 0.548 & 0.554 & 0.056 & 9.250 & 1.12T & 7.463 & 0.520 & 0.608 & 0.396 \\\\\n",
      "ft-to-SparseGPT0.65\\% & 0.103 & 0.120 & 0.013 & 6.250 & 760G & 21.500 & 0.267 & 0.299 & 0.269 \\\\\n",
      "lora-to-GPTQ3bit & 0.248 & 0.121 & 0.005 & 3.250 & -0.001k & 45.371 & 0.445 & 0.495 & 0.340 \\\\\n",
      "memit-to-Wanda0.65\\% & 0.021 & 0.013 & 0.021 & 6.251 & 760G & 48.744 & 0.230 & 0.249 & 0.265 \\\\\n",
      "lora-to-SparseGPT0.45\\% & 0.272 & 0.212 & 0.024 & 9.250 & 983G & 16.021 & 0.509 & 0.560 & 0.355 \\\\\n",
      "memit-to-Wanda0.45\\% & 0.679 & 0.567 & 0.015 & 9.251 & 1.12T & 7.555 & 0.502 & 0.588 & 0.370 \\\\\n",
      "memit-to-Wanda0.25\\% & 0.701 & 0.688 & 0.030 & 12.250 & 1.47T & 5.869 & 0.589 & 0.672 & 0.414 \\\\\n",
      "lora-to-SparseGPT0.65\\% & 0.059 & 0.071 & 0.021 & 6.250 & 625G & 74.336 & 0.303 & 0.340 & 0.286 \\\\\n",
      "ft-to-SparseGPT0.25\\% & 0.990 & 0.728 & 0.098 & 12.250 & 1.47T & 5.907 & 0.595 & 0.676 & 0.423 \\\\\n",
      "ft-to-SparseGPT0.45\\% & 0.627 & 0.427 & 0.081 & 9.250 & 1.12T & 7.503 & 0.528 & 0.604 & 0.386 \\\\\n",
      "lora-to-SparseGPT0.75\\% & 0.028 & 0.043 & 0.010 & 4.750 & 447G & 327.745 & 0.253 & 0.259 & 0.263 \\\\\n",
      "lora-to-SparseGPT0.55\\% & 0.307 & 0.159 & 0.058 & 7.750 & 804G & 27.011 & 0.427 & 0.518 & 0.334 \\\\\n",
      "lora-to-SparseGPT0.25\\% & 0.719 & 0.417 & 0.026 & 12.250 & 1.34T & 14.088 & 0.598 & 0.661 & 0.420 \\\\\n",
      "lora-to-SparseGPT0.35\\% & 0.771 & 0.509 & 0.019 & 10.750 & 1.16T & 14.827 & 0.572 & 0.638 & 0.395 \\\\\n",
      "lora-to-AWQ6bit & 1.000 & 0.760 & 0.078 & 6.250 & -0.001k & 22.438 & 0.611 & 0.685 & 0.449 \\\\\n",
      "lora-to-AWQ5bit & 1.000 & 0.790 & 0.086 & 5.250 & -0.001k & 23.278 & 0.607 & 0.684 & 0.440 \\\\\n",
      "lora-to-AWQ3bit & 0.585 & 0.457 & 0.051 & 3.250 & -0.001k & 34.765 & 0.515 & 0.600 & 0.390 \\\\\n",
      "ft-to-GPTQ3bit & 0.215 & 0.104 & 0.037 & 3.250 & -0.001k & 9.563 & 0.371 & 0.351 & 0.293 \\\\\n",
      "lora-to-Wanda0.65\\% & 0.033 & 0.041 & 0.002 & 6.251 & 626G & 315.495 & 0.238 & 0.241 & 0.282 \\\\\n",
      "lora-to-Wanda0.45\\% & 0.263 & 0.222 & 0.026 & 9.251 & 983G & 16.356 & 0.496 & 0.541 & 0.381 \\\\\n",
      "lora-to-Wanda0.25\\% & 0.834 & 0.508 & 0.038 & 12.250 & 1.34T & 14.110 & 0.595 & 0.672 & 0.425 \\\\\n",
      "ft-to-Wanda0.25\\% & 0.978 & 0.764 & 0.113 & 12.250 & 1.47T & 5.881 & 0.594 & 0.676 & 0.437 \\\\\n",
      "ft-to-Wanda0.45\\% & 0.682 & 0.541 & 0.057 & 9.251 & 1.12T & 7.568 & 0.519 & 0.585 & 0.375 \\\\\n",
      "ft-to-Wanda0.65\\% & 0.069 & 0.114 & 0.018 & 6.251 & 760G & 47.048 & 0.229 & 0.248 & 0.265 \\\\\n",
      "lora-to-Wanda0.75\\% & 0.019 & 0.029 & 0.004 & 4.750 & 447G & 2447.285 & 0.255 & 0.267 & 0.247 \\\\\n",
      "lora-to-Wanda0.55\\% & 0.210 & 0.084 & 0.045 & 7.752 & 804G & 40.685 & 0.356 & 0.395 & 0.312 \\\\\n",
      "lora-to-Wanda0.35\\% & 0.792 & 0.419 & 0.033 & 10.752 & 1.16T & 15.584 & 0.566 & 0.644 & 0.408 \\\\\n",
      "ft-to-SparseGPT0.55\\% & 0.291 & 0.173 & 0.056 & 7.750 & 938G & 10.574 & 0.439 & 0.524 & 0.350 \\\\\n",
      "ft-to-SparseGPT0.75\\% & 0.044 & 0.019 & 0.020 & 4.750 & 581G & 88.113 & 0.231 & 0.250 & 0.265 \\\\\n",
      "ft-to-SparseGPT0.35\\% & 0.849 & 0.570 & 0.094 & 10.750 & 1.3T & 6.397 & 0.569 & 0.643 & 0.418 \\\\\n",
      "ft-to-AWQ6bit & 1.000 & 0.799 & 0.127 & 6.250 & -0.001k & 5.587 & 0.612 & 0.690 & 0.436 \\\\\n",
      "ft-to-AWQ5bit & 1.000 & 0.773 & 0.134 & 5.250 & -0.001k & 5.659 & 0.611 & 0.685 & 0.427 \\\\\n",
      "ft-to-AWQ3bit & 0.825 & 0.521 & 0.080 & 3.250 & -0.001k & 7.560 & 0.508 & 0.581 & 0.405 \\\\\n",
      "ft-to-Wanda0.75\\% & 0.013 & 0.024 & 0.021 & 4.750 & 581G & 358.873 & 0.230 & 0.251 & 0.273 \\\\\n",
      "ft-to-Wanda0.55\\% & 0.294 & 0.203 & 0.033 & 7.752 & 939G & 12.481 & 0.356 & 0.371 & 0.320 \\\\\n",
      "memit-to-GPTQ3bit & 0.136 & 0.151 & 0.032 & 3.250 & -0.001k & 9.605 & 0.389 & 0.325 & 0.302 \\\\\n",
      "ft-to-Wanda0.35\\% & 0.919 & 0.714 & 0.092 & 10.752 & 1.3T & 6.348 & 0.569 & 0.638 & 0.412 \\\\\n",
      "memit-to-SparseGPT0.75\\% & 0.018 & 0.000 & 0.017 & 4.750 & 581G & 83.071 & 0.230 & 0.252 & 0.265 \\\\\n",
      "memit-to-SparseGPT0.35\\% & 0.718 & 0.568 & 0.050 & 10.750 & 1.3T & 6.382 & 0.560 & 0.642 & 0.404 \\\\\n",
      "memit-to-SparseGPT0.55\\% & 0.292 & 0.265 & 0.021 & 7.750 & 938G & 10.499 & 0.423 & 0.495 & 0.358 \\\\\n",
      "memit-to-AWQ6bit & 0.762 & 0.761 & 0.013 & 6.250 & -0.001k & 5.587 & 0.591 & 0.682 & 0.446 \\\\\n",
      "memit-to-AWQ3bit & 0.594 & 0.673 & 0.010 & 3.250 & -0.001k & 7.509 & 0.480 & 0.586 & 0.402 \\\\\n",
      "memit-to-AWQ5bit & 0.732 & 0.747 & 0.017 & 5.250 & -0.001k & 5.653 & 0.585 & 0.668 & 0.426 \\\\\n",
      "memit-to-Wanda0.55\\% & 0.310 & 0.223 & 0.014 & 7.752 & 939G & 12.554 & 0.348 & 0.353 & 0.314 \\\\\n",
      "memit-to-Wanda0.35\\% & 0.774 & 0.669 & 0.030 & 10.752 & 1.3T & 6.338 & 0.553 & 0.627 & 0.403 \\\\\n",
      "memit-to-Wanda0.75\\% & 0.023 & 0.024 & 0.011 & 4.750 & 581G & 285.152 & 0.231 & 0.251 & 0.279 \\\\\n",
      "\\midrule\n",
      "AWQ8bit-to-lora & 1.000 & 0.630 & 0.053 & 8.250 & -0.001k & 12.976 & 0.620 & 0.695 & 0.446 \\\\\n",
      "AWQ2bit-to-lora & 0.090 & 0.057 & 0.000 & 2.250 & -0.001k & 86477.578 & 0.235 & 0.247 & 0.264 \\\\\n",
      "AWQ4bit-to-lora & 1.000 & 0.749 & 0.085 & 4.250 & -0.001k & 21.969 & 0.585 & 0.653 & 0.435 \\\\\n",
      "GPTQ4bit-to-memit & 0.850 & 0.695 & 0.023 & 4.250 & -0.001k & 6.381 & 0.575 & 0.656 & 0.435 \\\\\n",
      "GPTQ8bit-to-memit & 0.843 & 0.764 & 0.012 & 8.250 & -0.001k & 5.570 & 0.599 & 0.681 & 0.438 \\\\\n",
      "GPTQ2bit-to-memit & 0.004 & 0.002 & 0.005 & 2.250 & -0.001k & 886242.562 & 0.230 & 0.246 & 0.259 \\\\\n",
      "AWQ4bit-to-memit & 0.953 & 0.925 & 0.015 & 4.250 & -0.001k & 5.974 & 0.572 & 0.656 & 0.425 \\\\\n",
      "AWQ2bit-to-memit & 0.000 & 0.000 & 0.000 & 2.250 & -0.001k & 987989.875 & 0.269 & 0.240 & 0.246 \\\\\n",
      "AWQ8bit-to-memit & 0.869 & 0.859 & 0.019 & 8.250 & -0.001k & 5.595 & 0.597 & 0.684 & 0.447 \\\\\n",
      "AWQ4bit-to-ft & 1.000 & 0.814 & 0.132 & 4.250 & -0.001k & 5.966 & 0.575 & 0.650 & 0.432 \\\\\n",
      "AWQ2bit-to-ft & 0.000 & 0.000 & 0.000 & 2.250 & -0.001k & 41847.629 & 0.247 & 0.247 & 0.243 \\\\\n",
      "AWQ8bit-to-ft & 0.995 & 0.854 & 0.130 & 8.250 & -0.001k & 5.594 & 0.597 & 0.679 & 0.437 \\\\\n",
      "SparseGPT0.65\\%-to-memit & 0.117 & 0.058 & 0.011 & 6.250 & 760G & 22.829 & 0.307 & 0.383 & 0.288 \\\\\n",
      "SparseGPT0.25\\%-to-memit & 0.819 & 0.799 & 0.041 & 12.250 & 1.47T & 5.893 & 0.588 & 0.684 & 0.431 \\\\\n",
      "SparseGPT0.45\\%-to-memit & 0.650 & 0.435 & 0.023 & 9.250 & 1.12T & 7.493 & 0.520 & 0.624 & 0.399 \\\\\n",
      "SparseGPT0.45\\%-to-lora & 0.747 & 0.215 & 0.025 & 9.250 & 983G & 9.853 & 0.517 & 0.612 & 0.379 \\\\\n",
      "SparseGPT0.65\\%-to-lora & 0.443 & 0.182 & 0.020 & 6.250 & 625G & 26.532 & 0.300 & 0.359 & 0.276 \\\\\n",
      "SparseGPT0.45\\%-to-ft & 0.930 & 0.645 & 0.048 & 9.250 & 1.12T & 7.479 & 0.530 & 0.614 & 0.402 \\\\\n",
      "SparseGPT0.65\\%-to-ft & 0.975 & 0.544 & 0.010 & 6.250 & 760G & 18.766 & 0.310 & 0.379 & 0.298 \\\\\n",
      "SparseGPT0.25\\%-to-ft & 0.995 & 0.664 & 0.080 & 12.250 & 1.47T & 5.897 & 0.601 & 0.680 & 0.423 \\\\\n",
      "SparseGPT0.25\\%-to-lora & 0.900 & 0.521 & 0.032 & 12.250 & 1.34T & 9.897 & 0.594 & 0.674 & 0.398 \\\\\n",
      "GPTQ3bit-to-lora & 0.020 & 0.012 & 0.006 & 3.250 & -0.001k & 11.147 & 0.393 & 0.485 & 0.321 \\\\\n",
      "AWQ3bit-to-lora & 1.000 & 0.730 & 0.027 & 3.250 & -0.001k & 34.592 & 0.504 & 0.594 & 0.382 \\\\\n",
      "AWQ5bit-to-lora & 1.000 & 0.634 & 0.008 & 5.250 & -0.001k & 15.592 & 0.617 & 0.683 & 0.437 \\\\\n",
      "AWQ6bit-to-lora & 1.000 & 0.774 & 0.049 & 6.250 & -0.001k & 34.765 & 0.585 & 0.661 & 0.439 \\\\\n",
      "SparseGPT0.75\\%-to-lora & 0.046 & 0.058 & 0.027 & 4.750 & 447G & 116.025 & 0.236 & 0.247 & 0.265 \\\\\n",
      "SparseGPT0.55\\%-to-lora & 0.627 & 0.362 & 0.030 & 7.750 & 804G & 12.102 & 0.426 & 0.503 & 0.335 \\\\\n",
      "SparseGPT0.35\\%-to-lora & 0.768 & 0.439 & 0.012 & 10.750 & 1.16T & 9.216 & 0.570 & 0.656 & 0.396 \\\\\n",
      "GPTQ3bit-to-ft & 0.122 & 0.071 & 0.008 & 3.250 & -0.001k & 10.431 & 0.416 & 0.526 & 0.350 \\\\\n",
      "Wanda0.65\\%-to-memit & 0.029 & 0.027 & 0.012 & 6.251 & 760G & 42.283 & 0.229 & 0.251 & 0.265 \\\\\n",
      "Wanda0.45\\%-to-memit & 0.604 & 0.527 & 0.035 & 9.251 & 1.12T & 7.540 & 0.511 & 0.591 & 0.383 \\\\\n",
      "Wanda0.25\\%-to-memit & 0.948 & 0.919 & 0.037 & 12.250 & 1.47T & 5.871 & 0.571 & 0.653 & 0.434 \\\\\n",
      "Wanda0.65\\%-to-ft & 0.442 & 0.188 & 0.031 & 6.251 & 760G & 41.628 & 0.230 & 0.249 & 0.266 \\\\\n",
      "Wanda0.25\\%-to-ft & 0.990 & 0.732 & 0.060 & 12.250 & 1.47T & 5.866 & 0.600 & 0.685 & 0.430 \\\\\n",
      "Wanda0.45\\%-to-ft & 0.939 & 0.623 & 0.050 & 9.251 & 1.12T & 7.517 & 0.523 & 0.599 & 0.384 \\\\\n",
      "SparseGPT0.75\\%-to-ft & 0.596 & 0.166 & 0.048 & 4.750 & 581G & 96.330 & 0.231 & 0.240 & 0.267 \\\\\n",
      "SparseGPT0.55\\%-to-ft & 0.946 & 0.558 & 0.022 & 7.750 & 938G & 10.292 & 0.450 & 0.540 & 0.355 \\\\\n",
      "SparseGPT0.35\\%-to-ft & 0.972 & 0.741 & 0.070 & 10.750 & 1.3T & 6.400 & 0.579 & 0.657 & 0.431 \\\\\n",
      "Wanda0.55\\%-to-lora & 0.815 & 0.354 & 0.014 & 7.752 & 804G & 15.014 & 0.348 & 0.346 & 0.314 \\\\\n",
      "Wanda0.75\\%-to-lora & 0.063 & 0.072 & 0.008 & 4.750 & 447G & 318.062 & 0.229 & 0.248 & 0.264 \\\\\n",
      "Wanda0.35\\%-to-lora & 0.896 & 0.396 & 0.023 & 10.752 & 1.16T & 7.977 & 0.574 & 0.639 & 0.400 \\\\\n",
      "GPTQ3bit-to-memit & 0.053 & 0.048 & 0.008 & 3.250 & -0.001k & 10.595 & 0.415 & 0.517 & 0.322 \\\\\n",
      "AWQ6bit-to-ft & 0.995 & 0.839 & 0.152 & 6.250 & -0.001k & 5.613 & 0.602 & 0.684 & 0.436 \\\\\n",
      "AWQ5bit-to-ft & 0.995 & 0.838 & 0.130 & 5.250 & -0.001k & 5.677 & 0.597 & 0.675 & 0.425 \\\\\n",
      "AWQ3bit-to-ft & 1.000 & 0.744 & 0.062 & 3.250 & -0.001k & 7.563 & 0.513 & 0.601 & 0.404 \\\\\n",
      "SparseGPT0.35\\%-to-memit & 0.849 & 0.753 & 0.025 & 10.750 & 1.3T & 6.388 & 0.573 & 0.661 & 0.421 \\\\\n",
      "SparseGPT0.75\\%-to-memit & 0.025 & 0.006 & 0.042 & 4.750 & 581G & 3646.392 & 0.235 & 0.242 & 0.255 \\\\\n",
      "SparseGPT0.55\\%-to-memit & 0.306 & 0.209 & 0.010 & 7.750 & 938G & 10.366 & 0.423 & 0.512 & 0.351 \\\\\n",
      "Wanda0.75\\%-to-ft & 0.047 & 0.065 & 0.015 & 4.750 & 581G & 236.109 & 0.229 & 0.255 & 0.273 \\\\\n",
      "Wanda0.55\\%-to-ft & 0.834 & 0.401 & 0.010 & 7.752 & 939G & 12.235 & 0.358 & 0.364 & 0.320 \\\\\n",
      "Wanda0.35\\%-to-ft & 0.959 & 0.739 & 0.037 & 10.752 & 1.3T & 6.326 & 0.578 & 0.658 & 0.409 \\\\\n",
      "AWQ6bit-to-memit & 0.954 & 0.889 & 0.027 & 6.250 & -0.001k & 5.620 & 0.584 & 0.673 & 0.440 \\\\\n",
      "AWQ3bit-to-memit & 0.916 & 0.873 & 0.029 & 3.250 & -0.001k & 7.567 & 0.473 & 0.577 & 0.393 \\\\\n",
      "Wanda0.55\\%-to-memit & 0.271 & 0.109 & 0.009 & 7.752 & 939G & 12.126 & 0.307 & 0.330 & 0.313 \\\\\n",
      "AWQ5bit-to-memit & 0.999 & 0.979 & 0.038 & 5.250 & -0.001k & 5.685 & 0.593 & 0.670 & 0.430 \\\\\n",
      "Wanda0.35\\%-to-memit & 0.829 & 0.769 & 0.031 & 10.752 & 1.3T & 6.344 & 0.555 & 0.631 & 0.417 \\\\\n",
      "Wanda0.75\\%-to-memit & 0.029 & 0.022 & 0.011 & 4.750 & 581G & 415.243 & 0.231 & 0.249 & 0.263 \\\\\n",
      "GPTQ4bit-to-lora & 0.064 & 0.074 & 0.009 & 4.250 & -0.001k & 8.252 & 0.570 & 0.654 & 0.397 \\\\\n",
      "GPTQ2bit-to-lora & 0.000 & 0.004 & 0.011 & 2.250 & -0.001k & 923830.812 & 0.251 & 0.250 & 0.253 \\\\\n",
      "GPTQ8bit-to-lora & 1.000 & 0.720 & 0.040 & 8.250 & -0.001k & 16.659 & 0.611 & 0.693 & 0.433 \\\\\n",
      "GPTQ4bit-to-ft & 0.274 & 0.172 & 0.025 & 4.250 & -0.001k & 6.340 & 0.590 & 0.672 & 0.435 \\\\\n",
      "GPTQ8bit-to-ft & 0.995 & 0.766 & 0.111 & 8.250 & -0.001k & 5.573 & 0.610 & 0.690 & 0.438 \\\\\n",
      "GPTQ2bit-to-ft & 0.000 & 0.004 & 0.003 & 2.250 & -0.001k & 894258.000 & 0.266 & 0.240 & 0.238 \\\\\n",
      "\\midrule\n",
      "rmu-none & 0.009 & 0.021 & 0.027 & 16.000 & 1.92T & 5.585 & 0.563 & 0.253 & 0.273 \\\\\n",
      "\\midrule\n",
      "ft-rmu & 1.000 & 0.784 & 0.115 & 16.000 & 1.92T & 5.593 & 0.596 & 0.427 & 0.282 \\\\\n",
      "memit-rmu & 0.990 & 0.887 & 0.047 & 16.000 & 1.92T & 5.584 & 0.591 & 0.588 & 0.350 \\\\\n",
      "lora-rmu & 1.000 & 0.619 & 0.058 & 16.000 & 1.79T & 34.557 & 0.598 & 0.591 & 0.329 \\\\\n",
      "\\midrule\n",
      "rmu-memit & 0.797 & 0.889 & 0.024 & 16.000 & 1.92T & 5.586 & 0.571 & 0.521 & 0.296 \\\\\n",
      "rmu-ft & 0.995 & 0.784 & 0.116 & 16.000 & 1.92T & 5.591 & 0.601 & 0.522 & 0.307 \\\\\n",
      "rmu-lora & 1.000 & 0.615 & 0.054 & 16.000 & 1.79T & 12.828 & 0.596 & 0.537 & 0.310 \\\\\n",
      "\\midrule\n",
      "gptq4bit-rmu & 0.000 & 0.000 & 0.032 & 4.250 & -0.001k & 6.353 & 0.589 & 0.647 & 0.421 \\\\\n",
      "gptq2bit-rmu & 0.003 & 0.007 & 0.005 & 2.250 & -0.001k & 1017825.938 & 0.230 & 0.247 & 0.254 \\\\\n",
      "gptq8bit-rmu & 0.013 & 0.010 & 0.033 & 8.250 & -0.001k & 5.580 & 0.578 & 0.296 & 0.272 \\\\\n",
      "sparsegpt0.65\\\\%-rmu & 0.000 & 0.007 & 0.022 & 6.250 & 760G & 30.263 & 0.232 & 0.251 & 0.273 \\\\\n",
      "sparsegpt0.45\\\\%-rmu & 0.000 & 0.006 & 0.024 & 9.250 & 1.12T & 7.859 & 0.517 & 0.378 & 0.325 \\\\\n",
      "sparsegpt0.25\\\\%-rmu & 0.006 & 0.025 & 0.041 & 12.250 & 1.47T & 5.925 & 0.589 & 0.412 & 0.286 \\\\\n",
      "wanda0.65\\\\%-rmu & 0.003 & 0.010 & 0.023 & 6.251 & 760G & 45.535 & 0.229 & 0.248 & 0.265 \\\\\n",
      "wanda0.45\\\\%-rmu & 0.007 & 0.007 & 0.038 & 9.251 & 1.12T & 7.545 & 0.525 & 0.595 & 0.393 \\\\\n",
      "wanda0.25\\\\%-rmu & 0.013 & 0.010 & 0.048 & 12.250 & 1.47T & 5.862 & 0.597 & 0.632 & 0.350 \\\\\n",
      "awq4bit-rmu & 0.013 & 0.005 & 0.031 & 4.250 & -0.001k & 6.061 & 0.501 & 0.262 & 0.257 \\\\\n",
      "awq2bit-rmu & 0.000 & 0.000 & 0.000 & 2.250 & -0.001k & 1749321.750 & 0.269 & 0.240 & 0.246 \\\\\n",
      "awq8bit-rmu & 0.007 & 0.010 & 0.031 & 8.250 & -0.001k & 5.713 & 0.598 & 0.309 & 0.268 \\\\\n",
      "\\midrule\n",
      "rmu-awq3bit & 0.000 & 0.021 & 0.014 & 3.250 & -0.001k & 7.509 & 0.473 & 0.259 & 0.265 \\\\\n",
      "rmu-awq2bit & 0.000 & 0.000 & 0.000 & 2.250 & -0.001k & 1788716.625 & 0.269 & 0.240 & 0.246 \\\\\n",
      "rmu-gptq2bit & 0.000 & 0.000 & 0.024 & 2.250 & -0.001k & 3451.666 & 0.241 & 0.250 & 0.240 \\\\\n",
      "rmu-gptq4bit & 0.015 & 0.019 & 0.026 & 4.250 & -0.001k & 12.881 & 0.584 & 0.359 & 0.267 \\\\\n",
      "rmu-gptq8bit & 0.013 & 0.010 & 0.032 & 8.250 & -0.001k & 5.562 & 0.603 & 0.423 & 0.269 \\\\\n",
      "rmu-sparsegpt0.45\\\\% & 0.021 & 0.022 & 0.036 & 9.250 & 1.12T & 8.143 & 0.466 & 0.259 & 0.266 \\\\\n",
      "rmu-sparsegpt0.65\\\\% & 0.000 & 0.007 & 0.024 & 6.250 & 760G & 35.974 & 0.231 & 0.247 & 0.264 \\\\\n",
      "rmu-sparsegpt0.25\\\\% & 0.018 & 0.013 & 0.041 & 12.250 & 1.47T & 5.926 & 0.570 & 0.284 & 0.270 \\\\\n",
      "rmu-wanda0.65\\\\% & 0.003 & 0.010 & 0.026 & 6.251 & 760G & 52.669 & 0.229 & 0.255 & 0.266 \\\\\n",
      "rmu-awq8bit & 0.013 & 0.015 & 0.031 & 8.250 & -0.001k & 5.560 & 0.604 & 0.440 & 0.275 \\\\\n",
      "rmu-wanda0.45\\\\% & 0.007 & 0.007 & 0.036 & 9.251 & 1.12T & 7.708 & 0.502 & 0.428 & 0.290 \\\\\n",
      "rmu-wanda0.25\\\\% & 0.006 & 0.010 & 0.045 & 12.250 & 1.47T & 5.882 & 0.575 & 0.311 & 0.268 \\\\\n",
      "rmu-awq4bit & 0.018 & 0.010 & 0.036 & 4.250 & -0.001k & 5.950 & 0.581 & 0.396 & 0.270 \\\\\n",
      "\\midrule\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def format_flops(value):\n",
    "    \"\"\" Format FLOPs with three significant figures and appropriate suffix. \"\"\"\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            value = clean_numeric_value(value)\n",
    "        if abs(value) < 1e6:  # Less than 1 million (below Mega)\n",
    "            return \"{:.3g}k\".format(value / 1e3)\n",
    "        elif abs(value) < 1e9:  # Mega to Giga range\n",
    "            return \"{:.3g}M\".format(value / 1e6)\n",
    "        elif abs(value) < 1e12:  # Giga to Tera range\n",
    "            return \"{:.3g}G\".format(value / 1e9)\n",
    "        else:  # Tera and above\n",
    "            return \"{:.3g}T\".format(value / 1e12)\n",
    "    except Exception as e:\n",
    "        print(f\"Error formatting FLOPs value {value}: {e}\")\n",
    "        return \"---\"\n",
    "\n",
    "def escape_latex_special_chars(s):\n",
    "    \"\"\" Escape special characters in LaTeX strings. \"\"\"\n",
    "    return str(s).replace('%', '\\\\%').replace('_', '\\\\_').replace('&', '\\\\&').replace('#', '\\\\#').replace('$', '\\\\$')\n",
    "\n",
    "def clean_numeric_value(value):\n",
    "    \"\"\" Convert a string with units to a numeric value. \"\"\"\n",
    "    try:\n",
    "        value = str(value)\n",
    "        if ' TFLOPS' in value:\n",
    "            return float(value.replace(' TFLOPS', '')) * 1e12\n",
    "        if ' GFLOPS' in value:\n",
    "            return float(value.replace(' GFLOPS', '')) * 1e9\n",
    "        if ' MFLOPS' in value:\n",
    "            return float(value.replace(' MFLOPS', '')) * 1e6\n",
    "        if ' kFLOPS' in value:\n",
    "            return float(value.replace(' kFLOPS', '')) * 1e3\n",
    "        return pd.to_numeric(value, errors='coerce')\n",
    "    except Exception as e:\n",
    "        print(f\"Error cleaning value {value}: {e}\")\n",
    "        return pd.NA\n",
    "\n",
    "def categorize_and_generate_latex(data):\n",
    "    # Define categories based on the provided criteria\n",
    "    categories = {\n",
    "    \"No Intervention\": data[data['interventions'].apply(lambda x: x == [])].copy(),\n",
    "    \"Editing\": data[data['interventions'].apply(lambda x: x == ['edit'])].copy(),\n",
    "    \"Compression\": data[data['interventions'].apply(lambda x: x == ['compress'])].copy(),\n",
    "    \"Edit to Compression\": data[data['interventions'].apply(lambda x: x == ['edit', 'compress'])].copy(),\n",
    "    \"Compression to Edit\": data[data['interventions'].apply(lambda x: x == ['compress', 'edit'])].copy(),\n",
    "    \"Unlearn\": data[data['interventions'].apply(lambda x: x == ['unlearn'])].copy(),\n",
    "    \"Edit to Unlearn\": data[data['interventions'].apply(lambda x: x == ['edit', 'unlearn'])].copy(),\n",
    "    \"Unlearn to Edit\": data[data['interventions'].apply(lambda x: x == ['unlearn', 'edit'])].copy(),\n",
    "    \"Compress to Unlearn\": data[data['interventions'].apply(lambda x: x == ['compress', 'unlearn'])].copy(),\n",
    "    \"Unlearn to Compress\": data[data['interventions'].apply(lambda x: x == ['unlearn', 'compress'])].copy()\n",
    "}\n",
    "    # Clean numeric columns\n",
    "    for col in [\"FLOPs\", \"Latency\"]:\n",
    "        if col in data.columns:\n",
    "            data.loc[:, col] = data[col].apply(clean_numeric_value)\n",
    "            data.loc[:, col] = pd.to_numeric(data[col], errors='coerce')  # Ensure all values are numeric\n",
    "\n",
    "    # Column mappings\n",
    "    column_mappings = {\n",
    "        \"Success\": \"Rewrite accuracy\",\n",
    "        \"Generalization\": \"Generalization\",\n",
    "        \"Locality\": \"Locality\",\n",
    "        \"Avg. Bits\": \"Average bits\",\n",
    "        \"FLOPs\": \"FLOPs\",\n",
    "        \"PPL\": \"PPL\",\n",
    "        \"MMLU\": \"mmlu accuracy\",\n",
    "        \"WMDP Bio\": \"wmdp_bio accuracy\",\n",
    "        \"WMDP Cyber\": \"wmdp_cyber accuracy\"\n",
    "    }\n",
    "    latex_columns = [\"Success\", \"Generalization\", \"Locality\", \"Avg. Bits\", \"FLOPs\", \"PPL\", \"MMLU\", \"WMDP Bio\", \"WMDP Cyber\"]\n",
    "\n",
    "    # Initialize output string\n",
    "    output_str = \"\"\n",
    "\n",
    "    for category, group in categories.items():\n",
    "        if group.empty:\n",
    "            continue\n",
    "        # output_str += f\"\\\\textbf{{{category}}} \\\\\\\\ \\\\midline\\n\"\n",
    "        for _, row in group.iterrows():\n",
    "            # Calculate mean and std for each relevant column within the group\n",
    "            stats = {}\n",
    "            for latex_col, csv_col in column_mappings.items():\n",
    "                if csv_col in row.index:\n",
    "                    value = row[csv_col]\n",
    "                    if pd.isna(value):\n",
    "                        stats[latex_col] = \"---\"\n",
    "                    else:\n",
    "                        # Custom formatting for FLOPs and Latency\n",
    "                        if latex_col == \"FLOPs\":\n",
    "                            mean_str = format_flops(value)\n",
    "                            stats[latex_col] = escape_latex_special_chars(mean_str)\n",
    "                        elif latex_col == \"Latency\":\n",
    "                            mean_str = f\"{value:.3f}s\"\n",
    "                            stats[latex_col] = escape_latex_special_chars(mean_str)\n",
    "                        else:\n",
    "                            mean_str = f\"{value:.3f}\"\n",
    "                            stats[latex_col] = escape_latex_special_chars(mean_str)\n",
    "                else:\n",
    "                    stats[latex_col] = \"---\"\n",
    "\n",
    "            # Prepare the LaTeX row for the current group\n",
    "            latex_row = escape_latex_special_chars(row['tag'])  # Use the tag name directly without escaping\n",
    "            for column in latex_columns:\n",
    "                latex_row += \" & \" + stats.get(column, \"---\")\n",
    "            latex_row += \" \\\\\\\\\"\n",
    "\n",
    "            # Append to output string\n",
    "            output_str += latex_row + \"\\n\"\n",
    "        \n",
    "        output_str += \"\\\\midrule\\n\"\n",
    "\n",
    "    return output_str\n",
    "\n",
    "latex_rows_with_categories = categorize_and_generate_latex(all_runs_df_deduplicated)\n",
    "print(latex_rows_with_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'included_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m ax\u001b[38;5;241m.\u001b[39mfill_between(edit_then_compress[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwbits\u001b[39m\u001b[38;5;124m'\u001b[39m], edit_then_compress[metric], compress_then_edit[metric], color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpurple\u001b[39m\u001b[38;5;124m'\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Integrate baselines into the scatter plots\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[43mincluded_models\u001b[49m:\n\u001b[1;32m     67\u001b[0m     baseline_edit \u001b[38;5;241m=\u001b[39m edit_then_compress_baselines[metric]\n\u001b[1;32m     68\u001b[0m     baseline_compress \u001b[38;5;241m=\u001b[39m compress_then_edit_baselines[metric]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'included_models' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the font family to serif\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "# Assuming 'metrics' DataFrame is already loaded from the CSV\n",
    "\n",
    "# Define the criteria for filtering\n",
    "selected_method = 'AWQ'\n",
    "edit_method = [\"FT\"]\n",
    "\n",
    "# Filter based on the criteria\n",
    "edit_then_compress = categories['Edit to Compression']\n",
    "compress_then_edit = categories['Compression to Edit']\n",
    "\n",
    "# Filter based on selected method\n",
    "edit_then_compress = edit_then_compress[edit_then_compress['compression']==selected_method]\n",
    "compress_then_edit = compress_then_edit[compress_then_edit['compression']==selected_method]\n",
    "\n",
    "# Add baselines to dfs\n",
    "baseline = categories['Editing']\n",
    "baseline['wbits'] = 16\n",
    "edit_then_compress = pd.concat([edit_then_compress, baseline], axis=0)\n",
    "compress_then_edit = pd.concat([compress_then_edit, baseline], axis=0)\n",
    "\n",
    "# Sort by 'wbits' in ascending order\n",
    "edit_then_compress = edit_then_compress.sort_values(by='wbits')\n",
    "compress_then_edit = compress_then_edit.sort_values(by='wbits')\n",
    "\n",
    "# Define the metrics to plot\n",
    "metrics_to_plot = ['Rewrite accuracy', 'Generalization', 'mmlu']\n",
    "x_axis_metric = 'wbits'\n",
    "\n",
    "# Compute baselines\n",
    "# edit_then_compress_baselines = {model: edit_then_compress[(edit_then_compress['model_name'] == model) & (edit_then_compress['sparsity_ratio'] == 0)][metrics_to_plot].mean() for model in included_models}\n",
    "# compress_then_edit_baselines = {model: compress_then_edit[(compress_then_edit['model_name'] == model) & (compress_then_edit['sparsity_ratio'] == 0)][metrics_to_plot].mean() for model in included_models}\n",
    "# edit_then_compress_baselines = categories['No Intervention']\n",
    "# compress_then_edit_baselines = categories['No Intervention']\n",
    "\n",
    "# Define plot parameters\n",
    "title_fontsize = 20\n",
    "label_fontsize = 20\n",
    "legend_fontsize = 18\n",
    "tick_fontsize = 18\n",
    "line_width = 3\n",
    "marker_size = 8\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, len(metrics_to_plot), figsize=(15, 5))\n",
    "\n",
    "# Iterate over each metric and plot\n",
    "for i, metric in enumerate(metrics_to_plot):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot the data with scatter and lines\n",
    "    ax.plot(edit_then_compress['wbits'], edit_then_compress[metric], linestyle='--', marker='o', markerfacecolor='purple', color='purple', label='Edit then compress',\n",
    "            linewidth=line_width, markersize=marker_size, markeredgewidth=line_width)\n",
    "    ax.plot(compress_then_edit['wbits'], compress_then_edit[metric], linestyle='-', marker='o', markerfacecolor='none', color='purple', label='Compress then edit',\n",
    "            linewidth=line_width, markersize=marker_size, markeredgewidth=line_width)\n",
    "    \n",
    "    # Fill the area between the lines\n",
    "    ax.fill_between(edit_then_compress['wbits'], edit_then_compress[metric], compress_then_edit[metric], color='purple', alpha=0.2)\n",
    "    \n",
    "    # Integrate baselines into the scatter plots\n",
    "    for model in included_models:\n",
    "        baseline_edit = edit_then_compress_baselines[metric]\n",
    "        baseline_compress = compress_then_edit_baselines[metric]\n",
    "        \n",
    "        if x_axis_metric == 'Average bits':\n",
    "            baseline_x = 16\n",
    "            ax.set_xlim(2, 16)\n",
    "        elif x_axis_metric == 'sparsity_ratio':\n",
    "            baseline_x = 0.0\n",
    "            ax.set_xlim(0, 1)\n",
    "        else:\n",
    "            baseline_x = 0  # Adjust based on your default x-axis range\n",
    "\n",
    "        # Add baselines to the scatter plots\n",
    "        # ax.scatter([baseline_x], [baseline_edit], color='purple', marker='o', s=marker_size**2, edgecolor='purple', linewidth=line_width)\n",
    "        # ax.scatter([baseline_x], [baseline_compress], color='purple', marker='o', s=marker_size**2, edgecolor='purple', linewidth=line_width)\n",
    "    if x_axis_metric == 'wbits':\n",
    "        ax.set_xlabel('Bits', fontsize=label_fontsize)\n",
    "    else:\n",
    "        ax.set_xlabel(x_axis_metric, fontsize=label_fontsize)\n",
    "    if metric == 'Rewrite accuracy':\n",
    "        ax.set_ylabel('Edit success', fontsize=label_fontsize)\n",
    "    else:\n",
    "        ax.set_ylabel(metric, fontsize=label_fontsize)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "\n",
    "# Move the legend to the bottom of the figure\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', fontsize=legend_fontsize, ncol=2)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.1, 1, 1])  # Adjust the bottom margin to make space for the legend\n",
    "plt.show()\n",
    "plt.savefig('figures/memit-gptq.pdf', format='pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
