{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import ast\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import wandb\n",
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Interventions\n",
    "# 31 RMU Compositions\n",
    "# Each editor in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting_columns = [\n",
    "    # Overall\n",
    "    \"tag\", \"seed\", \"_timestamp\",\n",
    "\n",
    "    # Interventions\n",
    "    \"interventions\", \"edit\", \"unlearn\", \"compression\", \"model_name\",\n",
    "\n",
    "    # Editing\n",
    "    \"edit_set\", \"edit_dataset\", \"number_of_edits\",\n",
    "\n",
    "    # Compression\n",
    "    \"wbits\", \"compression_dataset\", \"sparsity_ratio\",\n",
    "]\n",
    "evaluation_columns = [\n",
    "    \"qa_question_count_limit\",\n",
    "    \"mmlu accuracy\",\n",
    "    \"wmdp_bio accuracy\",\n",
    "    \"wmdp_cyber accuracy\",\n",
    "    \"PPL\",\n",
    "    \"PPL edits\",\n",
    "    \"PPl QA\",\n",
    "    \"Generalization\",\n",
    "    \"FLOPs\",\n",
    "    \"Success recall\",\n",
    "    \"Generalization recall\",\n",
    "    \"Locality\",\n",
    "    \"Average bits\",\n",
    "    \"Rewrite accuracy\",\n",
    "    \"PPl edits unmasked\",\n",
    "    \"Local recall\",\n",
    "    \"Latency\",\n",
    "]\n",
    "relevant_columns = setting_columns + evaluation_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/Composable_Interventions: 100%|██████████| 129/129 [00:00<00:00, 591.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing run n0iel6ok: '_timestamp'\n",
      "Error processing run xr5mede5: '_timestamp'\n",
      "Error processing run 27f8pxs0: '_timestamp'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/AK_Tests: 100%|██████████| 1624/1624 [00:04<00:00, 358.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# Replace 'username/project_name' with your specific project path\n",
    "# Composable_Interventions\n",
    "project_paths = ['dri-ice/Composable_Interventions', 'dri-ice/AK_Tests']\n",
    "\n",
    "filter_dict = { \n",
    "    \"state\": \"finished\",\n",
    "    # \"created_at\": {\"$gte\": \"2024-05-20\"}\n",
    "}\n",
    "data_frames = []\n",
    "for project_path in project_paths:\n",
    "    runs = api.runs(project_path, filters=filter_dict)\n",
    "    \n",
    "    # Iterate over eachrun and capture the config and summary metrics\n",
    "    for run in tqdm(runs, desc=project_path):\n",
    "        try:\n",
    "            run_start_datetime = datetime.fromtimestamp(run.summary_metrics[\"_timestamp\"])\n",
    "            start_cutoff = datetime.strptime(\"2024-05-1 12:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "            end_cutoff = datetime.strptime(\"2024-05-21 12:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "            if run_start_datetime >= end_cutoff:\n",
    "                continue\n",
    "\n",
    "            config_frame = pd.DataFrame([run.config])\n",
    "            summary_frame = pd.DataFrame([run.summary_metrics])\n",
    "            combined_frame = pd.concat([config_frame, summary_frame], axis=1)\n",
    "            data_frames.append(combined_frame)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing run {run.id}: {e}\")\n",
    "\n",
    "# Sort by 'tag' and '_timestamp' in descending order to have the most recent run first\n",
    "all_runs_df = pd.concat(data_frames, ignore_index=True)[relevant_columns]\n",
    "all_runs_df[\"interventions\"] = all_runs_df[\"interventions\"].astype(str)\n",
    "\n",
    "# WARNING: WHAT DOES EDIT SET 50 MEAN COMPARED TO EDIT SET 1?\n",
    "all_runs_df = all_runs_df[all_runs_df[\"edit_set\"] == 50]\n",
    "all_runs_df_sorted = all_runs_df.sort_values(by=['tag', '_timestamp'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag\n",
       "Compress_GPTQ2bit    3\n",
       "Compress_AWQ2bit     3\n",
       "Compress_AWQ4bit     3\n",
       "Compress_AWQ8bit     3\n",
       "Compress_GPTQ4bit    3\n",
       "                    ..\n",
       "gptq4bit-rmu         1\n",
       "gptq8bit-rmu         1\n",
       "AWQ2bit-to-memit     1\n",
       "memit-rmu            1\n",
       "wanda0.65\\%-rmu      1\n",
       "Name: count, Length: 61, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicates, keeping only the first occurrence (which is the most recent due to sorting)\n",
    "# all_runs_df_deduplicated = all_runs_df_sorted.drop_duplicates(subset=[col for col in setting_columns if col not in [\"_timestamp\", \"tag\"]], keep=\"first\")\n",
    "all_runs_df_deduplicated = all_runs_df_sorted\n",
    "all_runs_df_deduplicated[\"interventions\"] = all_runs_df_deduplicated[\"interventions\"].apply(lambda x : ast.literal_eval(x))\n",
    "\n",
    "rename_dict = {\n",
    "    \"meta-llama/Meta-Llama-3-8B\" : \"Llama-3 (8b)\",\n",
    "    \"ft\" : \"Fine-tune\",\n",
    "    \"memit\" : \"MEMIT\",\n",
    "    \"lora\" : \"Lora\",\n",
    "    \"wanda\" : \"Wanda\",\n",
    "    \"sparsegpt\" : \"SparseGPT\",\n",
    "    \"gptq\" : \"GPTQ\",\n",
    "    \"awq\" : \"AWQ\",\n",
    "    \"rmu\" : \"RMU\",\n",
    "}\n",
    "metrics = all_runs_df_deduplicated\n",
    "metrics[\"model_name\"] = metrics[\"model_name\"].apply(lambda x : rename_dict.get(x, None))\n",
    "metrics[\"edit\"] = metrics[\"edit\"].apply(lambda x : rename_dict.get(x, None))\n",
    "metrics[\"compression\"] = metrics[\"compression\"].apply(lambda x : rename_dict.get(x, None))\n",
    "metrics[\"unlearn\"] = metrics[\"unlearn\"].apply(lambda x : rename_dict.get(x, None))\n",
    "all_runs_df_deduplicated = metrics\n",
    "all_runs_df_deduplicated.value_counts(\"tag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>seed</th>\n",
       "      <th>_timestamp</th>\n",
       "      <th>interventions</th>\n",
       "      <th>edit</th>\n",
       "      <th>unlearn</th>\n",
       "      <th>compression</th>\n",
       "      <th>model_name</th>\n",
       "      <th>edit_set</th>\n",
       "      <th>edit_dataset</th>\n",
       "      <th>...</th>\n",
       "      <th>Generalization</th>\n",
       "      <th>FLOPs</th>\n",
       "      <th>Success recall</th>\n",
       "      <th>Generalization recall</th>\n",
       "      <th>Locality</th>\n",
       "      <th>Average bits</th>\n",
       "      <th>Rewrite accuracy</th>\n",
       "      <th>PPl edits unmasked</th>\n",
       "      <th>Local recall</th>\n",
       "      <th>Latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>rmu-sparsegpt0.25\\%</td>\n",
       "      <td>0</td>\n",
       "      <td>1.716234e+09</td>\n",
       "      <td>[unlearn, compress]</td>\n",
       "      <td>None</td>\n",
       "      <td>RMU</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>50</td>\n",
       "      <td>zsre</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013077</td>\n",
       "      <td>1.47 TFLOPS</td>\n",
       "      <td>0.017714</td>\n",
       "      <td>0.012857</td>\n",
       "      <td>0.040960</td>\n",
       "      <td>12.249977</td>\n",
       "      <td>0.018154</td>\n",
       "      <td>480.607880</td>\n",
       "      <td>0.039888</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rmu-sparsegpt0.45\\%</td>\n",
       "      <td>0</td>\n",
       "      <td>1.716234e+09</td>\n",
       "      <td>[unlearn, compress]</td>\n",
       "      <td>None</td>\n",
       "      <td>RMU</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>50</td>\n",
       "      <td>zsre</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021667</td>\n",
       "      <td>1.12 TFLOPS</td>\n",
       "      <td>0.020714</td>\n",
       "      <td>0.021667</td>\n",
       "      <td>0.036096</td>\n",
       "      <td>9.249988</td>\n",
       "      <td>0.021154</td>\n",
       "      <td>637.052124</td>\n",
       "      <td>0.036055</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rmu-sparsegpt0.65\\%</td>\n",
       "      <td>0</td>\n",
       "      <td>1.716234e+09</td>\n",
       "      <td>[unlearn, compress]</td>\n",
       "      <td>None</td>\n",
       "      <td>RMU</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>50</td>\n",
       "      <td>zsre</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>759.86 GFLOPS</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.024438</td>\n",
       "      <td>6.249982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1573.433228</td>\n",
       "      <td>0.022101</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sparsegpt0.25\\%-rmu</td>\n",
       "      <td>0</td>\n",
       "      <td>1.716237e+09</td>\n",
       "      <td>[compress, unlearn]</td>\n",
       "      <td>None</td>\n",
       "      <td>RMU</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>50</td>\n",
       "      <td>zsre</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025238</td>\n",
       "      <td>1.47 TFLOPS</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.025238</td>\n",
       "      <td>0.041017</td>\n",
       "      <td>12.249977</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>481.484344</td>\n",
       "      <td>0.040736</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sparsegpt0.45\\%-rmu</td>\n",
       "      <td>0</td>\n",
       "      <td>1.716237e+09</td>\n",
       "      <td>[compress, unlearn]</td>\n",
       "      <td>None</td>\n",
       "      <td>RMU</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>50</td>\n",
       "      <td>zsre</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>1.12 TFLOPS</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.023685</td>\n",
       "      <td>9.249988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>637.708252</td>\n",
       "      <td>0.023586</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sparsegpt0.65\\%-rmu</td>\n",
       "      <td>0</td>\n",
       "      <td>1.716237e+09</td>\n",
       "      <td>[compress, unlearn]</td>\n",
       "      <td>None</td>\n",
       "      <td>RMU</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>50</td>\n",
       "      <td>zsre</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>759.86 GFLOPS</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.022232</td>\n",
       "      <td>6.249982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1688.532227</td>\n",
       "      <td>0.020173</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tag  seed    _timestamp        interventions  edit  \\\n",
       "26  rmu-sparsegpt0.25\\%     0  1.716234e+09  [unlearn, compress]  None   \n",
       "24  rmu-sparsegpt0.45\\%     0  1.716234e+09  [unlearn, compress]  None   \n",
       "25  rmu-sparsegpt0.65\\%     0  1.716234e+09  [unlearn, compress]  None   \n",
       "17  sparsegpt0.25\\%-rmu     0  1.716237e+09  [compress, unlearn]  None   \n",
       "16  sparsegpt0.45\\%-rmu     0  1.716237e+09  [compress, unlearn]  None   \n",
       "15  sparsegpt0.65\\%-rmu     0  1.716237e+09  [compress, unlearn]  None   \n",
       "\n",
       "   unlearn compression    model_name  edit_set edit_dataset  ...  \\\n",
       "26     RMU   SparseGPT  Llama-3 (8b)        50         zsre  ...   \n",
       "24     RMU   SparseGPT  Llama-3 (8b)        50         zsre  ...   \n",
       "25     RMU   SparseGPT  Llama-3 (8b)        50         zsre  ...   \n",
       "17     RMU   SparseGPT  Llama-3 (8b)        50         zsre  ...   \n",
       "16     RMU   SparseGPT  Llama-3 (8b)        50         zsre  ...   \n",
       "15     RMU   SparseGPT  Llama-3 (8b)        50         zsre  ...   \n",
       "\n",
       "    Generalization          FLOPs Success recall  Generalization recall  \\\n",
       "26        0.013077    1.47 TFLOPS       0.017714               0.012857   \n",
       "24        0.021667    1.12 TFLOPS       0.020714               0.021667   \n",
       "25        0.006667  759.86 GFLOPS       0.000000               0.006667   \n",
       "17        0.025238    1.47 TFLOPS       0.005714               0.025238   \n",
       "16        0.005714    1.12 TFLOPS       0.000000               0.005000   \n",
       "15        0.006667  759.86 GFLOPS       0.000000               0.006667   \n",
       "\n",
       "    Locality  Average bits  Rewrite accuracy  PPl edits unmasked  \\\n",
       "26  0.040960     12.249977          0.018154          480.607880   \n",
       "24  0.036096      9.249988          0.021154          637.052124   \n",
       "25  0.024438      6.249982          0.000000         1573.433228   \n",
       "17  0.041017     12.249977          0.006154          481.484344   \n",
       "16  0.023685      9.249988          0.000000          637.708252   \n",
       "15  0.022232      6.249982          0.000000         1688.532227   \n",
       "\n",
       "    Local recall  Latency  \n",
       "26      0.039888     -1.0  \n",
       "24      0.036055     -1.0  \n",
       "25      0.022101     -1.0  \n",
       "17      0.040736     -1.0  \n",
       "16      0.023586     -1.0  \n",
       "15      0.020173     -1.0  \n",
       "\n",
       "[6 rows x 31 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_runs_df_deduplicated[all_runs_df_deduplicated[\"compression\"] == \"SparseGPT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(categories[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo Intervention\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(categories[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEditing\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;66;03m# Should be 3\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(categories[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompression\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m6\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(categories[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompression\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m12\u001b[39m \u001b[38;5;66;03m# Should be 18, 6 per\u001b[39;00m\n\u001b[1;32m     23\u001b[0m categories[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEdit to Compression\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = all_runs_df_deduplicated\n",
    "# print(data[\"interventions\"])\n",
    "# Select rows where the \"interventions\" column is exactly [\"edit\"]\n",
    "temp = data[data[\"interventions\"].apply(lambda x: x == [\"edit\", \"compress\"])]\n",
    "\n",
    "categories = {\n",
    "    \"No Intervention\": data[data[\"interventions\"].apply(lambda x: x == [])].copy(),\n",
    "    \"Editing\": data[data[\"interventions\"].apply(lambda x: x == [\"edit\"])].copy(),\n",
    "    \"Compression\": data[data[\"interventions\"].apply(lambda x: x == [\"compress\"])].copy(),\n",
    "    \"Edit to Compression\": data[data[\"interventions\"].apply(lambda x: x == [\"edit\", \"compress\"])].copy(),\n",
    "    \"Compression to Edit\": data[data[\"interventions\"].apply(lambda x: x == [\"compress\", \"edit\"])].copy(),\n",
    "    \"Unlearn\": data[data[\"interventions\"].apply(lambda x: x == [\"unlearn\"])].copy(),\n",
    "    \"Edit to Unlearn\": data[data[\"interventions\"].apply(lambda x: x == [\"edit\", \"unlearn\"])].copy(),\n",
    "    \"Unlearn to Edit\": data[data[\"interventions\"].apply(lambda x: x == [\"unlearn\", \"edit\"])].copy(),\n",
    "    \"Compress to Unlearn\": data[data[\"interventions\"].apply(lambda x: x == [\"compress\", \"unlearn\"])].copy(),\n",
    "    \"Unlearn to Compress\": data[data[\"interventions\"].apply(lambda x: x == [\"unlearn\", \"compress\"])].copy()\n",
    "}\n",
    "\n",
    "assert len(categories[\"No Intervention\"]) == 1\n",
    "assert len(categories[\"Editing\"]) == 2 # Should be 3\n",
    "assert len(categories[\"Compression\"]) == 6\n",
    "assert len(categories[\"Compression\"]) == 12 # Should be 18, 6 per\n",
    "categories[\"Edit to Compression\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def format_flops(value):\n",
    "    \"\"\" Format FLOPs with three significant figures and appropriate suffix. \"\"\"\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            value = clean_numeric_value(value)\n",
    "        if abs(value) < 1e6:  # Less than 1 million (below Mega)\n",
    "            return \"{:.3g}k\".format(value / 1e3)\n",
    "        elif abs(value) < 1e9:  # Mega to Giga range\n",
    "            return \"{:.3g}M\".format(value / 1e6)\n",
    "        elif abs(value) < 1e12:  # Giga to Tera range\n",
    "            return \"{:.3g}G\".format(value / 1e9)\n",
    "        else:  # Tera and above\n",
    "            return \"{:.3g}T\".format(value / 1e12)\n",
    "    except Exception as e:\n",
    "        print(f\"Error formatting FLOPs value {value}: {e}\")\n",
    "        return \"---\"\n",
    "\n",
    "def escape_latex_special_chars(s):\n",
    "    \"\"\" Escape special characters in LaTeX strings. \"\"\"\n",
    "    return str(s).replace('%', '\\\\%').replace('_', '\\\\_').replace('&', '\\\\&').replace('#', '\\\\#').replace('$', '\\\\$')\n",
    "\n",
    "def clean_numeric_value(value):\n",
    "    \"\"\" Convert a string with units to a numeric value. \"\"\"\n",
    "    try:\n",
    "        value = str(value)\n",
    "        if ' TFLOPS' in value:\n",
    "            return float(value.replace(' TFLOPS', '')) * 1e12\n",
    "        if ' GFLOPS' in value:\n",
    "            return float(value.replace(' GFLOPS', '')) * 1e9\n",
    "        if ' MFLOPS' in value:\n",
    "            return float(value.replace(' MFLOPS', '')) * 1e6\n",
    "        if ' kFLOPS' in value:\n",
    "            return float(value.replace(' kFLOPS', '')) * 1e3\n",
    "        return pd.to_numeric(value, errors='coerce')\n",
    "    except Exception as e:\n",
    "        print(f\"Error cleaning value {value}: {e}\")\n",
    "        return pd.NA\n",
    "\n",
    "def categorize_and_generate_latex(data):\n",
    "    # Define categories based on the provided criteria\n",
    "    categories = {\n",
    "    \"No Intervention\": data[data['interventions'].apply(lambda x: x == [])].copy(),\n",
    "    \"Editing\": data[data['interventions'].apply(lambda x: x == ['edit'])].copy(),\n",
    "    \"Compression\": data[data['interventions'].apply(lambda x: x == ['compress'])].copy(),\n",
    "    \"Edit to Compression\": data[data['interventions'].apply(lambda x: x == ['edit', 'compress'])].copy(),\n",
    "    \"Compression to Edit\": data[data['interventions'].apply(lambda x: x == ['compress', 'edit'])].copy(),\n",
    "    \"Unlearn\": data[data['interventions'].apply(lambda x: x == ['unlearn'])].copy(),\n",
    "    \"Edit to Unlearn\": data[data['interventions'].apply(lambda x: x == ['edit', 'unlearn'])].copy(),\n",
    "    \"Unlearn to Edit\": data[data['interventions'].apply(lambda x: x == ['unlearn', 'edit'])].copy(),\n",
    "    \"Compress to Unlearn\": data[data['interventions'].apply(lambda x: x == ['compress', 'unlearn'])].copy(),\n",
    "    \"Unlearn to Compress\": data[data['interventions'].apply(lambda x: x == ['unlearn', 'compress'])].copy()\n",
    "}\n",
    "    # Clean numeric columns\n",
    "    for col in [\"FLOPs\", \"Latency\"]:\n",
    "        if col in data.columns:\n",
    "            data.loc[:, col] = data[col].apply(clean_numeric_value)\n",
    "            data.loc[:, col] = pd.to_numeric(data[col], errors='coerce')  # Ensure all values are numeric\n",
    "\n",
    "    # Column mappings\n",
    "    column_mappings = {\n",
    "        \"Success\": \"Rewrite accuracy\",\n",
    "        \"Generalization\": \"Generalization\",\n",
    "        \"Locality\": \"Locality\",\n",
    "        \"Avg. Bits\": \"Average bits\",\n",
    "        \"FLOPs\": \"FLOPs\",\n",
    "        \"PPL\": \"PPL\",\n",
    "        \"MMLU\": \"mmlu accuracy\",\n",
    "        \"WMDP Bio\": \"wmdp_bio accuracy\",\n",
    "        \"WMDP Cyber\": \"wmdp_cyber accuracy\"\n",
    "    }\n",
    "    latex_columns = [\"Success\", \"Generalization\", \"Locality\", \"Avg. Bits\", \"FLOPs\", \"PPL\", \"MMLU\", \"WMDP Bio\", \"WMDP Cyber\"]\n",
    "\n",
    "    # Initialize output string\n",
    "    output_str = \"\"\n",
    "\n",
    "    for category, group in categories.items():\n",
    "        if group.empty:\n",
    "            continue\n",
    "        # output_str += f\"\\\\textbf{{{category}}} \\\\\\\\ \\\\midline\\n\"\n",
    "        for _, row in group.iterrows():\n",
    "            # Calculate mean and std for each relevant column within the group\n",
    "            stats = {}\n",
    "            for latex_col, csv_col in column_mappings.items():\n",
    "                if csv_col in row.index:\n",
    "                    value = row[csv_col]\n",
    "                    if pd.isna(value):\n",
    "                        stats[latex_col] = \"---\"\n",
    "                    else:\n",
    "                        # Custom formatting for FLOPs and Latency\n",
    "                        if latex_col == \"FLOPs\":\n",
    "                            mean_str = format_flops(value)\n",
    "                            stats[latex_col] = escape_latex_special_chars(mean_str)\n",
    "                        elif latex_col == \"Latency\":\n",
    "                            mean_str = f\"{value:.3f}s\"\n",
    "                            stats[latex_col] = escape_latex_special_chars(mean_str)\n",
    "                        else:\n",
    "                            mean_str = f\"{value:.3f}\"\n",
    "                            stats[latex_col] = escape_latex_special_chars(mean_str)\n",
    "                else:\n",
    "                    stats[latex_col] = \"---\"\n",
    "\n",
    "            # Prepare the LaTeX row for the current group\n",
    "            latex_row = escape_latex_special_chars(row['tag'])  # Use the tag name directly without escaping\n",
    "            for column in latex_columns:\n",
    "                latex_row += \" & \" + stats.get(column, \"---\")\n",
    "            latex_row += \" \\\\\\\\\"\n",
    "\n",
    "            # Append to output string\n",
    "            output_str += latex_row + \"\\n\"\n",
    "        \n",
    "        output_str += \"\\\\midrule\\n\"\n",
    "\n",
    "    return output_str\n",
    "\n",
    "latex_rows_with_categories = categorize_and_generate_latex(all_runs_df_deduplicated)\n",
    "print(latex_rows_with_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'included_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m ax\u001b[38;5;241m.\u001b[39mfill_between(edit_then_compress[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwbits\u001b[39m\u001b[38;5;124m'\u001b[39m], edit_then_compress[metric], compress_then_edit[metric], color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpurple\u001b[39m\u001b[38;5;124m'\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Integrate baselines into the scatter plots\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[43mincluded_models\u001b[49m:\n\u001b[1;32m     67\u001b[0m     baseline_edit \u001b[38;5;241m=\u001b[39m edit_then_compress_baselines[metric]\n\u001b[1;32m     68\u001b[0m     baseline_compress \u001b[38;5;241m=\u001b[39m compress_then_edit_baselines[metric]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'included_models' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the font family to serif\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "# Assuming 'metrics' DataFrame is already loaded from the CSV\n",
    "\n",
    "# Define the criteria for filtering\n",
    "selected_method = 'AWQ'\n",
    "edit_method = [\"FT\"]\n",
    "\n",
    "# Filter based on the criteria\n",
    "edit_then_compress = categories['Edit to Compression']\n",
    "compress_then_edit = categories['Compression to Edit']\n",
    "\n",
    "# Filter based on selected method\n",
    "edit_then_compress = edit_then_compress[edit_then_compress['compression']==selected_method]\n",
    "compress_then_edit = compress_then_edit[compress_then_edit['compression']==selected_method]\n",
    "\n",
    "# Add baselines to dfs\n",
    "baseline = categories['Editing']\n",
    "baseline['wbits'] = 16\n",
    "edit_then_compress = pd.concat([edit_then_compress, baseline], axis=0)\n",
    "compress_then_edit = pd.concat([compress_then_edit, baseline], axis=0)\n",
    "\n",
    "# Sort by 'wbits' in ascending order\n",
    "edit_then_compress = edit_then_compress.sort_values(by='wbits')\n",
    "compress_then_edit = compress_then_edit.sort_values(by='wbits')\n",
    "\n",
    "# Define the metrics to plot\n",
    "metrics_to_plot = ['Rewrite accuracy', 'Generalization', 'mmlu']\n",
    "x_axis_metric = 'wbits'\n",
    "\n",
    "# Compute baselines\n",
    "# edit_then_compress_baselines = {model: edit_then_compress[(edit_then_compress['model_name'] == model) & (edit_then_compress['sparsity_ratio'] == 0)][metrics_to_plot].mean() for model in included_models}\n",
    "# compress_then_edit_baselines = {model: compress_then_edit[(compress_then_edit['model_name'] == model) & (compress_then_edit['sparsity_ratio'] == 0)][metrics_to_plot].mean() for model in included_models}\n",
    "# edit_then_compress_baselines = categories['No Intervention']\n",
    "# compress_then_edit_baselines = categories['No Intervention']\n",
    "\n",
    "# Define plot parameters\n",
    "title_fontsize = 20\n",
    "label_fontsize = 20\n",
    "legend_fontsize = 18\n",
    "tick_fontsize = 18\n",
    "line_width = 3\n",
    "marker_size = 8\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, len(metrics_to_plot), figsize=(15, 5))\n",
    "\n",
    "# Iterate over each metric and plot\n",
    "for i, metric in enumerate(metrics_to_plot):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot the data with scatter and lines\n",
    "    ax.plot(edit_then_compress['wbits'], edit_then_compress[metric], linestyle='--', marker='o', markerfacecolor='purple', color='purple', label='Edit then compress',\n",
    "            linewidth=line_width, markersize=marker_size, markeredgewidth=line_width)\n",
    "    ax.plot(compress_then_edit['wbits'], compress_then_edit[metric], linestyle='-', marker='o', markerfacecolor='none', color='purple', label='Compress then edit',\n",
    "            linewidth=line_width, markersize=marker_size, markeredgewidth=line_width)\n",
    "    \n",
    "    # Fill the area between the lines\n",
    "    ax.fill_between(edit_then_compress['wbits'], edit_then_compress[metric], compress_then_edit[metric], color='purple', alpha=0.2)\n",
    "    \n",
    "    # Integrate baselines into the scatter plots\n",
    "    for model in included_models:\n",
    "        baseline_edit = edit_then_compress_baselines[metric]\n",
    "        baseline_compress = compress_then_edit_baselines[metric]\n",
    "        \n",
    "        if x_axis_metric == 'Average bits':\n",
    "            baseline_x = 16\n",
    "            ax.set_xlim(2, 16)\n",
    "        elif x_axis_metric == 'sparsity_ratio':\n",
    "            baseline_x = 0.0\n",
    "            ax.set_xlim(0, 1)\n",
    "        else:\n",
    "            baseline_x = 0  # Adjust based on your default x-axis range\n",
    "\n",
    "        # Add baselines to the scatter plots\n",
    "        # ax.scatter([baseline_x], [baseline_edit], color='purple', marker='o', s=marker_size**2, edgecolor='purple', linewidth=line_width)\n",
    "        # ax.scatter([baseline_x], [baseline_compress], color='purple', marker='o', s=marker_size**2, edgecolor='purple', linewidth=line_width)\n",
    "    if x_axis_metric == 'wbits':\n",
    "        ax.set_xlabel('Bits', fontsize=label_fontsize)\n",
    "    else:\n",
    "        ax.set_xlabel(x_axis_metric, fontsize=label_fontsize)\n",
    "    if metric == 'Rewrite accuracy':\n",
    "        ax.set_ylabel('Edit success', fontsize=label_fontsize)\n",
    "    else:\n",
    "        ax.set_ylabel(metric, fontsize=label_fontsize)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "\n",
    "# Move the legend to the bottom of the figure\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', fontsize=legend_fontsize, ncol=2)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.1, 1, 1])  # Adjust the bottom margin to make space for the legend\n",
    "plt.show()\n",
    "plt.savefig('figures/memit-gptq.pdf', format='pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
