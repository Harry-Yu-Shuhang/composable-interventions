{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import ast\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import wandb\n",
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Interventions\n",
    "# 31 RMU Compositions\n",
    "# Each editor in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting_columns = [\n",
    "    # Overall\n",
    "    \"tag\",\n",
    "    # \"seed\",\n",
    "    \"_timestamp\",\n",
    "\n",
    "    # Interventions\n",
    "    \"interventions\", \"edit\", \"unlearn\", \"compression\", \"model_name\",\n",
    "\n",
    "    # Editing\n",
    "    # \"edit_set\", \n",
    "    \"edit_dataset\", \"number_of_edits\",\n",
    "\n",
    "    # Compression\n",
    "    \"wbits\", \"compression_dataset\", \"sparsity_ratio\",\n",
    "]\n",
    "evaluation_columns = [\n",
    "    \"qa_question_count_limit\",\n",
    "    \"mmlu accuracy\",\n",
    "    \"wmdp_bio accuracy\",\n",
    "    \"wmdp_cyber accuracy\",\n",
    "    \"PPL\",\n",
    "    \"PPL edits\",\n",
    "    \"PPl QA\",\n",
    "    \"Generalization\",\n",
    "    \"FLOPs\",\n",
    "    \"Success recall\",\n",
    "    \"Generalization recall\",\n",
    "    \"Locality\",\n",
    "    \"Average bits\",\n",
    "    \"Rewrite accuracy\",\n",
    "    \"PPl edits unmasked\",\n",
    "    \"Local recall\",\n",
    "    \"Latency\",\n",
    "]\n",
    "relevant_columns = setting_columns + evaluation_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/Composable_Interventions:   0%|          | 0/150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/Composable_Interventions: 100%|██████████| 150/150 [00:00<00:00, 672.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing run n0iel6ok: '_timestamp'\n",
      "Error processing run xr5mede5: '_timestamp'\n",
      "Error processing run 27f8pxs0: '_timestamp'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/AK_Tests: 100%|██████████| 1624/1624 [00:00<00:00, 1767.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# Replace 'username/project_name' with your specific project path\n",
    "# Composable_Interventions\n",
    "project_paths = [\n",
    "    'dri-ice/Composable_Interventions',\n",
    "    'dri-ice/AK_Tests'\n",
    "]\n",
    "\n",
    "filter_dict = { \n",
    "    \"state\": \"finished\",\n",
    "    # \"created_at\": {\"$gte\": \"2024-05-20\"}\n",
    "}\n",
    "data_frames = []\n",
    "for project_path in project_paths:\n",
    "    runs = api.runs(project_path, filters=filter_dict)\n",
    "    \n",
    "    # Iterate over eachrun and capture the config and summary metrics\n",
    "    for run in tqdm(runs, desc=project_path):\n",
    "        try:\n",
    "            run_start_datetime = datetime.fromtimestamp(run.summary_metrics[\"_timestamp\"])\n",
    "            start_cutoff = datetime.strptime(\"2024-05-18 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "            end_cutoff = datetime.strptime(\"2024-05-21 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "            if run_start_datetime < start_cutoff or run_start_datetime > end_cutoff:\n",
    "                continue\n",
    "\n",
    "            skip_tags = [\"test\", \"hparam_search\", \"none\"]\n",
    "            should_skip = False\n",
    "            for tag in skip_tags:\n",
    "                if tag in run.config[\"tag\"].lower():\n",
    "                    should_skip = True\n",
    "            \n",
    "            if should_skip:\n",
    "                continue\n",
    "\n",
    "            config_frame = pd.DataFrame([run.config])\n",
    "            summary_frame = pd.DataFrame([run.summary_metrics])\n",
    "            combined_frame = pd.concat([config_frame, summary_frame], axis=1)\n",
    "            data_frames.append(combined_frame)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing run {run.id}: {e}\")\n",
    "\n",
    "# Sort by 'tag' and '_timestamp' in descending order to have the most recent run first\n",
    "all_runs_df = pd.concat(data_frames, ignore_index=True)[relevant_columns]\n",
    "all_runs_df[\"interventions\"] = all_runs_df[\"interventions\"].astype(str)\n",
    "\n",
    "# WARNING: WHAT DOES EDIT SET 50 MEAN COMPARED TO EDIT SET 1?\n",
    "# all_runs_df = all_runs_df[all_runs_df[\"edit_set\"] == 50]\n",
    "# all_runs_df_sorted = all_runs_df.sort_values(by=['tag', '_timestamp'], ascending=[True, False])\n",
    "all_runs_df[\"date\"] = pd.to_datetime(all_runs_df[\"_timestamp\"], unit='s')\n",
    "all_runs_df_sorted = all_runs_df.sort_values(by=['_timestamp'], ascending=[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>_timestamp</th>\n",
       "      <th>interventions</th>\n",
       "      <th>edit</th>\n",
       "      <th>unlearn</th>\n",
       "      <th>compression</th>\n",
       "      <th>model_name</th>\n",
       "      <th>edit_dataset</th>\n",
       "      <th>number_of_edits</th>\n",
       "      <th>wbits</th>\n",
       "      <th>...</th>\n",
       "      <th>FLOPs</th>\n",
       "      <th>Success recall</th>\n",
       "      <th>Generalization recall</th>\n",
       "      <th>Locality</th>\n",
       "      <th>Average bits</th>\n",
       "      <th>Rewrite accuracy</th>\n",
       "      <th>PPl edits unmasked</th>\n",
       "      <th>Local recall</th>\n",
       "      <th>Latency</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gptq4bit-rmu</td>\n",
       "      <td>1.716243e+09</td>\n",
       "      <td>['compress', 'unlearn']</td>\n",
       "      <td>none</td>\n",
       "      <td>rmu</td>\n",
       "      <td>gptq</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031642</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>507.698822</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>86.307608</td>\n",
       "      <td>2024-05-20 22:05:08.484089613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gptq2bit-rmu</td>\n",
       "      <td>1.716243e+09</td>\n",
       "      <td>['compress', 'unlearn']</td>\n",
       "      <td>none</td>\n",
       "      <td>rmu</td>\n",
       "      <td>gptq</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>150067.625000</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>86.962416</td>\n",
       "      <td>2024-05-20 22:03:10.347089291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gptq8bit-rmu</td>\n",
       "      <td>1.716243e+09</td>\n",
       "      <td>['compress', 'unlearn']</td>\n",
       "      <td>none</td>\n",
       "      <td>rmu</td>\n",
       "      <td>gptq</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.012381</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.032513</td>\n",
       "      <td>8.25</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>445.737610</td>\n",
       "      <td>0.032110</td>\n",
       "      <td>86.466912</td>\n",
       "      <td>2024-05-20 22:02:09.332513094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rmu-gptq2bit</td>\n",
       "      <td>1.716240e+09</td>\n",
       "      <td>['unlearn', 'compress']</td>\n",
       "      <td>none</td>\n",
       "      <td>rmu</td>\n",
       "      <td>gptq</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024140</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23385.773438</td>\n",
       "      <td>0.023029</td>\n",
       "      <td>88.352600</td>\n",
       "      <td>2024-05-20 21:26:17.526590109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rmu-gptq4bit</td>\n",
       "      <td>1.716240e+09</td>\n",
       "      <td>['unlearn', 'compress']</td>\n",
       "      <td>none</td>\n",
       "      <td>rmu</td>\n",
       "      <td>gptq</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.014524</td>\n",
       "      <td>0.019048</td>\n",
       "      <td>0.025801</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0.014744</td>\n",
       "      <td>525.068787</td>\n",
       "      <td>0.025197</td>\n",
       "      <td>86.940684</td>\n",
       "      <td>2024-05-20 21:23:45.248690844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>memit_Edit</td>\n",
       "      <td>1.716005e+09</td>\n",
       "      <td>['edit']</td>\n",
       "      <td>memit</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.92 TFLOPS</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>0.037923</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>641.421265</td>\n",
       "      <td>0.035993</td>\n",
       "      <td>124.798484</td>\n",
       "      <td>2024-05-18 04:06:08.118285894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>memit_Edit</td>\n",
       "      <td>1.716005e+09</td>\n",
       "      <td>['edit']</td>\n",
       "      <td>memit</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.92 TFLOPS</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>0.739667</td>\n",
       "      <td>0.021008</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>688.575256</td>\n",
       "      <td>0.020586</td>\n",
       "      <td>132.843399</td>\n",
       "      <td>2024-05-18 04:06:07.325703621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>memit_Edit</td>\n",
       "      <td>1.716005e+09</td>\n",
       "      <td>['edit']</td>\n",
       "      <td>memit</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.92 TFLOPS</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.063423</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>621.960205</td>\n",
       "      <td>0.061930</td>\n",
       "      <td>125.165364</td>\n",
       "      <td>2024-05-18 04:04:32.198839188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>memit_Edit</td>\n",
       "      <td>1.716005e+09</td>\n",
       "      <td>['edit']</td>\n",
       "      <td>memit</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.92 TFLOPS</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.043431</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>723.989441</td>\n",
       "      <td>0.042454</td>\n",
       "      <td>125.125785</td>\n",
       "      <td>2024-05-18 04:00:56.205363750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>memit_Edit</td>\n",
       "      <td>1.716005e+09</td>\n",
       "      <td>['edit']</td>\n",
       "      <td>memit</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.92 TFLOPS</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.936667</td>\n",
       "      <td>0.014648</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>750.062317</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>123.632746</td>\n",
       "      <td>2024-05-18 04:00:28.935862303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tag    _timestamp            interventions   edit unlearn  \\\n",
       "1    gptq4bit-rmu  1.716243e+09  ['compress', 'unlearn']   none     rmu   \n",
       "5    gptq2bit-rmu  1.716243e+09  ['compress', 'unlearn']   none     rmu   \n",
       "3    gptq8bit-rmu  1.716243e+09  ['compress', 'unlearn']   none     rmu   \n",
       "0    rmu-gptq2bit  1.716240e+09  ['unlearn', 'compress']   none     rmu   \n",
       "2    rmu-gptq4bit  1.716240e+09  ['unlearn', 'compress']   none     rmu   \n",
       "..            ...           ...                      ...    ...     ...   \n",
       "339    memit_Edit  1.716005e+09                 ['edit']  memit    none   \n",
       "341    memit_Edit  1.716005e+09                 ['edit']  memit    none   \n",
       "340    memit_Edit  1.716005e+09                 ['edit']  memit    none   \n",
       "342    memit_Edit  1.716005e+09                 ['edit']  memit    none   \n",
       "343    memit_Edit  1.716005e+09                 ['edit']  memit    none   \n",
       "\n",
       "    compression                  model_name edit_dataset  number_of_edits  \\\n",
       "1          gptq  meta-llama/Meta-Llama-3-8B         zsre               50   \n",
       "5          gptq  meta-llama/Meta-Llama-3-8B         zsre               50   \n",
       "3          gptq  meta-llama/Meta-Llama-3-8B         zsre               50   \n",
       "0          gptq  meta-llama/Meta-Llama-3-8B         zsre               50   \n",
       "2          gptq  meta-llama/Meta-Llama-3-8B         zsre               50   \n",
       "..          ...                         ...          ...              ...   \n",
       "339        none  meta-llama/Meta-Llama-3-8B         zsre               50   \n",
       "341        none  meta-llama/Meta-Llama-3-8B         zsre               50   \n",
       "340        none  meta-llama/Meta-Llama-3-8B         zsre               50   \n",
       "342        none  meta-llama/Meta-Llama-3-8B         zsre               50   \n",
       "343        none  meta-llama/Meta-Llama-3-8B         zsre               50   \n",
       "\n",
       "     wbits  ...        FLOPs  Success recall Generalization recall  Locality  \\\n",
       "1      4.0  ...           -1        0.000000              0.000000  0.031642   \n",
       "5      2.0  ...           -1        0.002857              0.006667  0.004933   \n",
       "3      8.0  ...           -1        0.012381              0.010000  0.032513   \n",
       "0      2.0  ...           -1        0.000000              0.000000  0.024140   \n",
       "2      4.0  ...           -1        0.014524              0.019048  0.025801   \n",
       "..     ...  ...          ...             ...                   ...       ...   \n",
       "339    NaN  ...  1.92 TFLOPS        0.990000              0.963333  0.037923   \n",
       "341    NaN  ...  1.92 TFLOPS        0.845000              0.739667  0.021008   \n",
       "340    NaN  ...  1.92 TFLOPS        0.986667              0.976000  0.063423   \n",
       "342    NaN  ...  1.92 TFLOPS        0.975000              0.950000  0.043431   \n",
       "343    NaN  ...  1.92 TFLOPS        0.986667              0.936667  0.014648   \n",
       "\n",
       "     Average bits  Rewrite accuracy  PPl edits unmasked  Local recall  \\\n",
       "1            4.25          0.000000          507.698822      0.031800   \n",
       "5            2.25          0.002857       150067.625000      0.004262   \n",
       "3            8.25          0.012821          445.737610      0.032110   \n",
       "0            2.25          0.000000        23385.773438      0.023029   \n",
       "2            4.25          0.014744          525.068787      0.025197   \n",
       "..            ...               ...                 ...           ...   \n",
       "339         16.00          0.990000          641.421265      0.035993   \n",
       "341         16.00          0.845000          688.575256      0.020586   \n",
       "340         16.00          0.989333          621.960205      0.061930   \n",
       "342         16.00          0.975000          723.989441      0.042454   \n",
       "343         16.00          0.986667          750.062317      0.014500   \n",
       "\n",
       "        Latency                          date  \n",
       "1     86.307608 2024-05-20 22:05:08.484089613  \n",
       "5     86.962416 2024-05-20 22:03:10.347089291  \n",
       "3     86.466912 2024-05-20 22:02:09.332513094  \n",
       "0     88.352600 2024-05-20 21:26:17.526590109  \n",
       "2     86.940684 2024-05-20 21:23:45.248690844  \n",
       "..          ...                           ...  \n",
       "339  124.798484 2024-05-18 04:06:08.118285894  \n",
       "341  132.843399 2024-05-18 04:06:07.325703621  \n",
       "340  125.165364 2024-05-18 04:04:32.198839188  \n",
       "342  125.125785 2024-05-18 04:00:56.205363750  \n",
       "343  123.632746 2024-05-18 04:00:28.935862303  \n",
       "\n",
       "[344 rows x 30 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_runs_df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>_timestamp</th>\n",
       "      <th>interventions</th>\n",
       "      <th>edit</th>\n",
       "      <th>unlearn</th>\n",
       "      <th>compression</th>\n",
       "      <th>model_name</th>\n",
       "      <th>edit_dataset</th>\n",
       "      <th>number_of_edits</th>\n",
       "      <th>wbits</th>\n",
       "      <th>...</th>\n",
       "      <th>FLOPs</th>\n",
       "      <th>Success recall</th>\n",
       "      <th>Generalization recall</th>\n",
       "      <th>Locality</th>\n",
       "      <th>Average bits</th>\n",
       "      <th>Rewrite accuracy</th>\n",
       "      <th>PPl edits unmasked</th>\n",
       "      <th>Local recall</th>\n",
       "      <th>Latency</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lora-rmu</td>\n",
       "      <td>1.716237e+09</td>\n",
       "      <td>['edit', 'unlearn']</td>\n",
       "      <td>lora</td>\n",
       "      <td>rmu</td>\n",
       "      <td>none</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.79 TFLOPS</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.618571</td>\n",
       "      <td>0.057981</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>25660.986328</td>\n",
       "      <td>0.058719</td>\n",
       "      <td>512.197093</td>\n",
       "      <td>2024-05-20 20:31:09.500632286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rmu-lora</td>\n",
       "      <td>1.716237e+09</td>\n",
       "      <td>['unlearn', 'edit']</td>\n",
       "      <td>lora</td>\n",
       "      <td>rmu</td>\n",
       "      <td>none</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.79 TFLOPS</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.054210</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>10560.212891</td>\n",
       "      <td>0.054559</td>\n",
       "      <td>515.848708</td>\n",
       "      <td>2024-05-20 20:28:42.994992018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>memit-rmu</td>\n",
       "      <td>1.716234e+09</td>\n",
       "      <td>['edit', 'unlearn']</td>\n",
       "      <td>memit</td>\n",
       "      <td>rmu</td>\n",
       "      <td>none</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.92 TFLOPS</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.932000</td>\n",
       "      <td>0.018525</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.952</td>\n",
       "      <td>435.951874</td>\n",
       "      <td>0.018666</td>\n",
       "      <td>95.736313</td>\n",
       "      <td>2024-05-20 19:38:41.118072510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ft-rmu</td>\n",
       "      <td>1.716234e+09</td>\n",
       "      <td>['edit', 'unlearn']</td>\n",
       "      <td>ft</td>\n",
       "      <td>rmu</td>\n",
       "      <td>none</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.92 TFLOPS</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.799857</td>\n",
       "      <td>0.144349</td>\n",
       "      <td>15.999969</td>\n",
       "      <td>1.000</td>\n",
       "      <td>542.750366</td>\n",
       "      <td>0.142683</td>\n",
       "      <td>96.744370</td>\n",
       "      <td>2024-05-20 19:38:26.891535759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rmu-memit</td>\n",
       "      <td>1.716234e+09</td>\n",
       "      <td>['unlearn', 'edit']</td>\n",
       "      <td>memit</td>\n",
       "      <td>rmu</td>\n",
       "      <td>none</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.92 TFLOPS</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.034166</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.985</td>\n",
       "      <td>433.229065</td>\n",
       "      <td>0.033793</td>\n",
       "      <td>95.927453</td>\n",
       "      <td>2024-05-20 19:37:23.770762682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rmu-ft</td>\n",
       "      <td>1.716234e+09</td>\n",
       "      <td>['unlearn', 'edit']</td>\n",
       "      <td>ft</td>\n",
       "      <td>rmu</td>\n",
       "      <td>none</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.92 TFLOPS</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.131125</td>\n",
       "      <td>15.999967</td>\n",
       "      <td>1.000</td>\n",
       "      <td>579.778748</td>\n",
       "      <td>0.129552</td>\n",
       "      <td>96.837090</td>\n",
       "      <td>2024-05-20 19:33:35.887049198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tag    _timestamp        interventions   edit unlearn compression  \\\n",
       "8    lora-rmu  1.716237e+09  ['edit', 'unlearn']   lora     rmu        none   \n",
       "11   rmu-lora  1.716237e+09  ['unlearn', 'edit']   lora     rmu        none   \n",
       "6   memit-rmu  1.716234e+09  ['edit', 'unlearn']  memit     rmu        none   \n",
       "7      ft-rmu  1.716234e+09  ['edit', 'unlearn']     ft     rmu        none   \n",
       "9   rmu-memit  1.716234e+09  ['unlearn', 'edit']  memit     rmu        none   \n",
       "10     rmu-ft  1.716234e+09  ['unlearn', 'edit']     ft     rmu        none   \n",
       "\n",
       "                    model_name edit_dataset  number_of_edits  wbits  ...  \\\n",
       "8   meta-llama/Meta-Llama-3-8B         zsre               50   16.0  ...   \n",
       "11  meta-llama/Meta-Llama-3-8B         zsre               50   16.0  ...   \n",
       "6   meta-llama/Meta-Llama-3-8B         zsre               50   16.0  ...   \n",
       "7   meta-llama/Meta-Llama-3-8B         zsre               50   16.0  ...   \n",
       "9   meta-llama/Meta-Llama-3-8B         zsre               50   16.0  ...   \n",
       "10  meta-llama/Meta-Llama-3-8B         zsre               50   16.0  ...   \n",
       "\n",
       "          FLOPs  Success recall Generalization recall  Locality  Average bits  \\\n",
       "8   1.79 TFLOPS           1.000              0.618571  0.057981     16.000000   \n",
       "11  1.79 TFLOPS           1.000              0.615000  0.054210     16.000000   \n",
       "6   1.92 TFLOPS           0.952              0.932000  0.018525     16.000000   \n",
       "7   1.92 TFLOPS           1.000              0.799857  0.144349     15.999969   \n",
       "9   1.92 TFLOPS           0.985              0.950000  0.034166     16.000000   \n",
       "10  1.92 TFLOPS           1.000              0.780000  0.131125     15.999967   \n",
       "\n",
       "    Rewrite accuracy  PPl edits unmasked  Local recall     Latency  \\\n",
       "8              1.000        25660.986328      0.058719  512.197093   \n",
       "11             1.000        10560.212891      0.054559  515.848708   \n",
       "6              0.952          435.951874      0.018666   95.736313   \n",
       "7              1.000          542.750366      0.142683   96.744370   \n",
       "9              0.985          433.229065      0.033793   95.927453   \n",
       "10             1.000          579.778748      0.129552   96.837090   \n",
       "\n",
       "                            date  \n",
       "8  2024-05-20 20:31:09.500632286  \n",
       "11 2024-05-20 20:28:42.994992018  \n",
       "6  2024-05-20 19:38:41.118072510  \n",
       "7  2024-05-20 19:38:26.891535759  \n",
       "9  2024-05-20 19:37:23.770762682  \n",
       "10 2024-05-20 19:33:35.887049198  \n",
       "\n",
       "[6 rows x 30 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_runs_df_sorted[(all_runs_df_sorted[\"wbits\"] == 16) & (all_runs_df_sorted[\"compression\"] == \"none\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_58538/169473594.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_runs_df_deduplicated[\"interventions\"] = all_runs_df_deduplicated[\"interventions\"].apply(lambda x : ast.literal_eval(x))\n",
      "/tmp/ipykernel_58538/169473594.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metrics[\"model_name\"] = metrics[\"model_name\"].apply(lambda x : rename_dict.get(x, None))\n",
      "/tmp/ipykernel_58538/169473594.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metrics[\"edit\"] = metrics[\"edit\"].apply(lambda x : rename_dict.get(x, None))\n",
      "/tmp/ipykernel_58538/169473594.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metrics[\"compression\"] = metrics[\"compression\"].apply(lambda x : rename_dict.get(x, None))\n",
      "/tmp/ipykernel_58538/169473594.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metrics[\"unlearn\"] = metrics[\"unlearn\"].apply(lambda x : rename_dict.get(x, None))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tag\n",
       "AWQ2bit-to-ft              1\n",
       "memit-to-SparseGPT0.45%    1\n",
       "memit-to-GPTQ8bit          1\n",
       "memit-to-GPTQ4bit          1\n",
       "memit-to-GPTQ2bit          1\n",
       "                          ..\n",
       "SparseGPT0.65%-to-memit    1\n",
       "SparseGPT0.65%-to-lora     1\n",
       "SparseGPT0.65%-to-ft       1\n",
       "SparseGPT0.45%-to-memit    1\n",
       "wanda0.65\\%-rmu            1\n",
       "Name: count, Length: 107, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicates, keeping only the first occurrence (which is the most recent due to sorting)\n",
    "all_runs_df_deduplicated = all_runs_df_sorted.drop_duplicates(subset=[col for col in setting_columns if col not in [\"_timestamp\", \"tag\", \"date\"]], keep=\"first\")\n",
    "# all_runs_df_deduplicated = all_runs_df_sorted\n",
    "all_runs_df_deduplicated[\"interventions\"] = all_runs_df_deduplicated[\"interventions\"].apply(lambda x : ast.literal_eval(x))\n",
    "\n",
    "rename_dict = {\n",
    "    \"meta-llama/Meta-Llama-3-8B\" : \"Llama-3 (8b)\",\n",
    "    \"ft\" : \"Fine-tune\",\n",
    "    \"memit\" : \"MEMIT\",\n",
    "    \"lora\" : \"Lora\",\n",
    "    \"wanda\" : \"Wanda\",\n",
    "    \"sparsegpt\" : \"SparseGPT\",\n",
    "    \"gptq\" : \"GPTQ\",\n",
    "    \"awq\" : \"AWQ\",\n",
    "    \"rmu\" : \"RMU\",\n",
    "}\n",
    "metrics = all_runs_df_deduplicated\n",
    "metrics[\"model_name\"] = metrics[\"model_name\"].apply(lambda x : rename_dict.get(x, None))\n",
    "metrics[\"edit\"] = metrics[\"edit\"].apply(lambda x : rename_dict.get(x, None))\n",
    "metrics[\"compression\"] = metrics[\"compression\"].apply(lambda x : rename_dict.get(x, None))\n",
    "metrics[\"unlearn\"] = metrics[\"unlearn\"].apply(lambda x : rename_dict.get(x, None))\n",
    "all_runs_df_deduplicated = metrics\n",
    "all_runs_df_deduplicated.value_counts(\"tag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>_timestamp</th>\n",
       "      <th>interventions</th>\n",
       "      <th>edit</th>\n",
       "      <th>unlearn</th>\n",
       "      <th>compression</th>\n",
       "      <th>model_name</th>\n",
       "      <th>edit_dataset</th>\n",
       "      <th>number_of_edits</th>\n",
       "      <th>wbits</th>\n",
       "      <th>...</th>\n",
       "      <th>FLOPs</th>\n",
       "      <th>Success recall</th>\n",
       "      <th>Generalization recall</th>\n",
       "      <th>Locality</th>\n",
       "      <th>Average bits</th>\n",
       "      <th>Rewrite accuracy</th>\n",
       "      <th>PPl edits unmasked</th>\n",
       "      <th>Local recall</th>\n",
       "      <th>Latency</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sparsegpt0.65\\%-rmu</td>\n",
       "      <td>1.716237e+09</td>\n",
       "      <td>[compress, unlearn]</td>\n",
       "      <td>None</td>\n",
       "      <td>RMU</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>759.86 GFLOPS</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.022232</td>\n",
       "      <td>6.249982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1688.532227</td>\n",
       "      <td>0.020173</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-20 20:26:57.591763496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sparsegpt0.45\\%-rmu</td>\n",
       "      <td>1.716237e+09</td>\n",
       "      <td>[compress, unlearn]</td>\n",
       "      <td>None</td>\n",
       "      <td>RMU</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.12 TFLOPS</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.023685</td>\n",
       "      <td>9.249988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>637.708252</td>\n",
       "      <td>0.023586</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-20 20:26:14.456046343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sparsegpt0.25\\%-rmu</td>\n",
       "      <td>1.716237e+09</td>\n",
       "      <td>[compress, unlearn]</td>\n",
       "      <td>None</td>\n",
       "      <td>RMU</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.47 TFLOPS</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.025238</td>\n",
       "      <td>0.041017</td>\n",
       "      <td>12.249977</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>481.484344</td>\n",
       "      <td>0.040736</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-20 20:24:09.416608095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>rmu-sparsegpt0.45\\%</td>\n",
       "      <td>1.716234e+09</td>\n",
       "      <td>[unlearn, compress]</td>\n",
       "      <td>None</td>\n",
       "      <td>RMU</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.12 TFLOPS</td>\n",
       "      <td>0.020714</td>\n",
       "      <td>0.021667</td>\n",
       "      <td>0.036096</td>\n",
       "      <td>9.249988</td>\n",
       "      <td>0.021154</td>\n",
       "      <td>637.052124</td>\n",
       "      <td>0.036055</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-20 19:38:30.983223438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>rmu-sparsegpt0.65\\%</td>\n",
       "      <td>1.716234e+09</td>\n",
       "      <td>[unlearn, compress]</td>\n",
       "      <td>None</td>\n",
       "      <td>RMU</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>759.86 GFLOPS</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.024438</td>\n",
       "      <td>6.249982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1573.433228</td>\n",
       "      <td>0.022101</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-20 19:36:36.984816551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>rmu-sparsegpt0.25\\%</td>\n",
       "      <td>1.716234e+09</td>\n",
       "      <td>[unlearn, compress]</td>\n",
       "      <td>None</td>\n",
       "      <td>RMU</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.47 TFLOPS</td>\n",
       "      <td>0.017714</td>\n",
       "      <td>0.012857</td>\n",
       "      <td>0.040960</td>\n",
       "      <td>12.249977</td>\n",
       "      <td>0.018154</td>\n",
       "      <td>480.607880</td>\n",
       "      <td>0.039888</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-20 19:35:36.819632053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>SparseGPT0.65%-to-lora</td>\n",
       "      <td>1.716164e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Lora</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>625.35 GFLOPS</td>\n",
       "      <td>0.316333</td>\n",
       "      <td>0.195222</td>\n",
       "      <td>0.013377</td>\n",
       "      <td>6.249982</td>\n",
       "      <td>0.316333</td>\n",
       "      <td>1176.053467</td>\n",
       "      <td>0.012868</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-20 00:21:08.571938038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>SparseGPT0.45%-to-lora</td>\n",
       "      <td>1.716164e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Lora</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>982.69 GFLOPS</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>0.329556</td>\n",
       "      <td>0.033835</td>\n",
       "      <td>9.249988</td>\n",
       "      <td>0.711231</td>\n",
       "      <td>1712.821167</td>\n",
       "      <td>0.034028</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-20 00:20:46.149566889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>SparseGPT0.25%-to-lora</td>\n",
       "      <td>1.716164e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Lora</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.34 TFLOPS</td>\n",
       "      <td>0.878667</td>\n",
       "      <td>0.528333</td>\n",
       "      <td>0.036167</td>\n",
       "      <td>12.249977</td>\n",
       "      <td>0.878667</td>\n",
       "      <td>2798.604980</td>\n",
       "      <td>0.036143</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-20 00:06:42.644053936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>lora-to-SparseGPT0.45%</td>\n",
       "      <td>1.716161e+09</td>\n",
       "      <td>[edit, compress]</td>\n",
       "      <td>Lora</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>982.69 GFLOPS</td>\n",
       "      <td>0.224667</td>\n",
       "      <td>0.207333</td>\n",
       "      <td>0.030890</td>\n",
       "      <td>9.249987</td>\n",
       "      <td>0.224667</td>\n",
       "      <td>2524.844482</td>\n",
       "      <td>0.030844</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-19 23:29:09.522534609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>lora-to-SparseGPT0.65%</td>\n",
       "      <td>1.716161e+09</td>\n",
       "      <td>[edit, compress]</td>\n",
       "      <td>Lora</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>625.35 GFLOPS</td>\n",
       "      <td>0.069556</td>\n",
       "      <td>0.026222</td>\n",
       "      <td>0.016391</td>\n",
       "      <td>6.249982</td>\n",
       "      <td>0.072889</td>\n",
       "      <td>7437.687500</td>\n",
       "      <td>0.015972</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-19 23:28:35.285866499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>lora-to-SparseGPT0.25%</td>\n",
       "      <td>1.716161e+09</td>\n",
       "      <td>[edit, compress]</td>\n",
       "      <td>Lora</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.34 TFLOPS</td>\n",
       "      <td>0.798000</td>\n",
       "      <td>0.475333</td>\n",
       "      <td>0.019578</td>\n",
       "      <td>12.249977</td>\n",
       "      <td>0.798000</td>\n",
       "      <td>3136.567383</td>\n",
       "      <td>0.019594</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-19 23:27:11.065227509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Compress_SparseGPT0.65%</td>\n",
       "      <td>1.716159e+09</td>\n",
       "      <td>[compress]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>759.83 GFLOPS</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024302</td>\n",
       "      <td>6.249982</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>1471.645752</td>\n",
       "      <td>0.024060</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-19 22:51:20.123609066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Compress_SparseGPT0.45%</td>\n",
       "      <td>1.716159e+09</td>\n",
       "      <td>[compress]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.12 TFLOPS</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>0.020667</td>\n",
       "      <td>0.024713</td>\n",
       "      <td>9.249987</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>629.839539</td>\n",
       "      <td>0.024177</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-19 22:49:25.270934343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Compress_SparseGPT0.25%</td>\n",
       "      <td>1.716159e+09</td>\n",
       "      <td>[compress]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.47 TFLOPS</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.025896</td>\n",
       "      <td>12.249977</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>540.646484</td>\n",
       "      <td>0.026476</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-19 22:48:30.484580517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>SparseGPT0.65%-to-ft</td>\n",
       "      <td>1.716075e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>759.83 GFLOPS</td>\n",
       "      <td>0.864556</td>\n",
       "      <td>0.488000</td>\n",
       "      <td>0.032478</td>\n",
       "      <td>6.249982</td>\n",
       "      <td>0.864556</td>\n",
       "      <td>975.367554</td>\n",
       "      <td>0.032788</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-18 23:35:18.639262915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>SparseGPT0.45%-to-ft</td>\n",
       "      <td>1.716075e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.12 TFLOPS</td>\n",
       "      <td>0.968889</td>\n",
       "      <td>0.661667</td>\n",
       "      <td>0.030979</td>\n",
       "      <td>9.249987</td>\n",
       "      <td>0.968889</td>\n",
       "      <td>551.007019</td>\n",
       "      <td>0.030288</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-18 23:24:38.509175777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>SparseGPT0.25%-to-ft</td>\n",
       "      <td>1.716074e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.47 TFLOPS</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.090888</td>\n",
       "      <td>12.249977</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>523.214600</td>\n",
       "      <td>0.091150</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-18 23:21:38.737693071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>ft-to-SparseGPT0.45%</td>\n",
       "      <td>1.716073e+09</td>\n",
       "      <td>[edit, compress]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.12 TFLOPS</td>\n",
       "      <td>0.657333</td>\n",
       "      <td>0.492333</td>\n",
       "      <td>0.058865</td>\n",
       "      <td>9.249988</td>\n",
       "      <td>0.657333</td>\n",
       "      <td>538.705139</td>\n",
       "      <td>0.057511</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-18 22:50:02.530201197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>ft-to-SparseGPT0.25%</td>\n",
       "      <td>1.716072e+09</td>\n",
       "      <td>[edit, compress]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.47 TFLOPS</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.109315</td>\n",
       "      <td>12.249977</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>639.486328</td>\n",
       "      <td>0.109288</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-18 22:43:20.304731369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>ft-to-SparseGPT0.65%</td>\n",
       "      <td>1.716072e+09</td>\n",
       "      <td>[edit, compress]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>759.83 GFLOPS</td>\n",
       "      <td>0.102889</td>\n",
       "      <td>0.087889</td>\n",
       "      <td>0.031966</td>\n",
       "      <td>6.249982</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>1188.221191</td>\n",
       "      <td>0.031549</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-18 22:43:19.089725494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>SparseGPT0.65%-to-memit</td>\n",
       "      <td>1.716071e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>759.83 GFLOPS</td>\n",
       "      <td>0.100889</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.011810</td>\n",
       "      <td>6.249982</td>\n",
       "      <td>0.100889</td>\n",
       "      <td>1374.303467</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-18 22:25:23.128047943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>SparseGPT0.45%-to-memit</td>\n",
       "      <td>1.716071e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.12 TFLOPS</td>\n",
       "      <td>0.608889</td>\n",
       "      <td>0.510556</td>\n",
       "      <td>0.026271</td>\n",
       "      <td>9.249987</td>\n",
       "      <td>0.608376</td>\n",
       "      <td>457.136444</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-18 22:24:59.891652107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>SparseGPT0.25%-to-memit</td>\n",
       "      <td>1.716070e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.47 TFLOPS</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.029503</td>\n",
       "      <td>12.249977</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>515.356689</td>\n",
       "      <td>0.030130</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-18 22:12:42.628662109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>memit-to-SparseGPT0.25%</td>\n",
       "      <td>1.716069e+09</td>\n",
       "      <td>[edit, compress]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.47 TFLOPS</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.832222</td>\n",
       "      <td>0.011584</td>\n",
       "      <td>12.249977</td>\n",
       "      <td>0.766938</td>\n",
       "      <td>499.069885</td>\n",
       "      <td>0.011976</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-18 21:42:24.331947088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>memit-to-SparseGPT0.45%</td>\n",
       "      <td>1.716069e+09</td>\n",
       "      <td>[edit, compress]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.12 TFLOPS</td>\n",
       "      <td>0.533889</td>\n",
       "      <td>0.435667</td>\n",
       "      <td>0.018130</td>\n",
       "      <td>9.249987</td>\n",
       "      <td>0.533889</td>\n",
       "      <td>499.762878</td>\n",
       "      <td>0.017788</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-18 21:42:07.662075043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>memit-to-SparseGPT0.65%</td>\n",
       "      <td>1.716068e+09</td>\n",
       "      <td>[edit, compress]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>759.83 GFLOPS</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.010670</td>\n",
       "      <td>6.249982</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>1540.579346</td>\n",
       "      <td>0.010011</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2024-05-18 21:41:28.956569910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         tag    _timestamp        interventions       edit  \\\n",
       "12       sparsegpt0.65\\%-rmu  1.716237e+09  [compress, unlearn]       None   \n",
       "13       sparsegpt0.45\\%-rmu  1.716237e+09  [compress, unlearn]       None   \n",
       "14       sparsegpt0.25\\%-rmu  1.716237e+09  [compress, unlearn]       None   \n",
       "21       rmu-sparsegpt0.45\\%  1.716234e+09  [unlearn, compress]       None   \n",
       "22       rmu-sparsegpt0.65\\%  1.716234e+09  [unlearn, compress]       None   \n",
       "23       rmu-sparsegpt0.25\\%  1.716234e+09  [unlearn, compress]       None   \n",
       "87    SparseGPT0.65%-to-lora  1.716164e+09     [compress, edit]       Lora   \n",
       "88    SparseGPT0.45%-to-lora  1.716164e+09     [compress, edit]       Lora   \n",
       "89    SparseGPT0.25%-to-lora  1.716164e+09     [compress, edit]       Lora   \n",
       "92    lora-to-SparseGPT0.45%  1.716161e+09     [edit, compress]       Lora   \n",
       "94    lora-to-SparseGPT0.65%  1.716161e+09     [edit, compress]       Lora   \n",
       "95    lora-to-SparseGPT0.25%  1.716161e+09     [edit, compress]       Lora   \n",
       "99   Compress_SparseGPT0.65%  1.716159e+09           [compress]       None   \n",
       "100  Compress_SparseGPT0.45%  1.716159e+09           [compress]       None   \n",
       "101  Compress_SparseGPT0.25%  1.716159e+09           [compress]       None   \n",
       "133     SparseGPT0.65%-to-ft  1.716075e+09     [compress, edit]  Fine-tune   \n",
       "134     SparseGPT0.45%-to-ft  1.716075e+09     [compress, edit]  Fine-tune   \n",
       "135     SparseGPT0.25%-to-ft  1.716074e+09     [compress, edit]  Fine-tune   \n",
       "138     ft-to-SparseGPT0.45%  1.716073e+09     [edit, compress]  Fine-tune   \n",
       "139     ft-to-SparseGPT0.25%  1.716072e+09     [edit, compress]  Fine-tune   \n",
       "141     ft-to-SparseGPT0.65%  1.716072e+09     [edit, compress]  Fine-tune   \n",
       "167  SparseGPT0.65%-to-memit  1.716071e+09     [compress, edit]      MEMIT   \n",
       "169  SparseGPT0.45%-to-memit  1.716071e+09     [compress, edit]      MEMIT   \n",
       "172  SparseGPT0.25%-to-memit  1.716070e+09     [compress, edit]      MEMIT   \n",
       "170  memit-to-SparseGPT0.25%  1.716069e+09     [edit, compress]      MEMIT   \n",
       "171  memit-to-SparseGPT0.45%  1.716069e+09     [edit, compress]      MEMIT   \n",
       "175  memit-to-SparseGPT0.65%  1.716068e+09     [edit, compress]      MEMIT   \n",
       "\n",
       "    unlearn compression    model_name edit_dataset  number_of_edits  wbits  \\\n",
       "12      RMU   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "13      RMU   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "14      RMU   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "21      RMU   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "22      RMU   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "23      RMU   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "87     None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "88     None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "89     None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "92     None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "94     None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "95     None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "99     None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "100    None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "101    None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "133    None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "134    None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "135    None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "138    None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "139    None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "141    None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "167    None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "169    None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "172    None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "170    None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "171    None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "175    None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "\n",
       "     ...          FLOPs  Success recall Generalization recall  Locality  \\\n",
       "12   ...  759.86 GFLOPS        0.000000              0.006667  0.022232   \n",
       "13   ...    1.12 TFLOPS        0.000000              0.005000  0.023685   \n",
       "14   ...    1.47 TFLOPS        0.005714              0.025238  0.041017   \n",
       "21   ...    1.12 TFLOPS        0.020714              0.021667  0.036096   \n",
       "22   ...  759.86 GFLOPS        0.000000              0.006667  0.024438   \n",
       "23   ...    1.47 TFLOPS        0.017714              0.012857  0.040960   \n",
       "87   ...  625.35 GFLOPS        0.316333              0.195222  0.013377   \n",
       "88   ...  982.69 GFLOPS        0.712000              0.329556  0.033835   \n",
       "89   ...    1.34 TFLOPS        0.878667              0.528333  0.036167   \n",
       "92   ...  982.69 GFLOPS        0.224667              0.207333  0.030890   \n",
       "94   ...  625.35 GFLOPS        0.069556              0.026222  0.016391   \n",
       "95   ...    1.34 TFLOPS        0.798000              0.475333  0.019578   \n",
       "99   ...  759.83 GFLOPS        0.008889              0.000000  0.024302   \n",
       "100  ...    1.12 TFLOPS        0.008889              0.020667  0.024713   \n",
       "101  ...    1.47 TFLOPS        0.008889              0.016667  0.025896   \n",
       "133  ...  759.83 GFLOPS        0.864556              0.488000  0.032478   \n",
       "134  ...    1.12 TFLOPS        0.968889              0.661667  0.030979   \n",
       "135  ...    1.47 TFLOPS        0.995000              0.666667  0.090888   \n",
       "138  ...    1.12 TFLOPS        0.657333              0.492333  0.058865   \n",
       "139  ...    1.47 TFLOPS        0.985000              0.710000  0.109315   \n",
       "141  ...  759.83 GFLOPS        0.102889              0.087889  0.031966   \n",
       "167  ...  759.83 GFLOPS        0.100889              0.040000  0.011810   \n",
       "169  ...    1.12 TFLOPS        0.608889              0.510556  0.026271   \n",
       "172  ...    1.47 TFLOPS        0.940000              0.910000  0.029503   \n",
       "170  ...    1.47 TFLOPS        0.766667              0.832222  0.011584   \n",
       "171  ...    1.12 TFLOPS        0.533889              0.435667  0.018130   \n",
       "175  ...  759.83 GFLOPS        0.002222              0.006667  0.010670   \n",
       "\n",
       "     Average bits  Rewrite accuracy  PPl edits unmasked  Local recall  \\\n",
       "12       6.249982          0.000000         1688.532227      0.020173   \n",
       "13       9.249988          0.000000          637.708252      0.023586   \n",
       "14      12.249977          0.006154          481.484344      0.040736   \n",
       "21       9.249988          0.021154          637.052124      0.036055   \n",
       "22       6.249982          0.000000         1573.433228      0.022101   \n",
       "23      12.249977          0.018154          480.607880      0.039888   \n",
       "87       6.249982          0.316333         1176.053467      0.012868   \n",
       "88       9.249988          0.711231         1712.821167      0.034028   \n",
       "89      12.249977          0.878667         2798.604980      0.036143   \n",
       "92       9.249987          0.224667         2524.844482      0.030844   \n",
       "94       6.249982          0.072889         7437.687500      0.015972   \n",
       "95      12.249977          0.798000         3136.567383      0.019594   \n",
       "99       6.249982          0.008889         1471.645752      0.024060   \n",
       "100      9.249987          0.008889          629.839539      0.024177   \n",
       "101     12.249977          0.008889          540.646484      0.026476   \n",
       "133      6.249982          0.864556          975.367554      0.032788   \n",
       "134      9.249987          0.968889          551.007019      0.030288   \n",
       "135     12.249977          0.995000          523.214600      0.091150   \n",
       "138      9.249988          0.657333          538.705139      0.057511   \n",
       "139     12.249977          0.985000          639.486328      0.109288   \n",
       "141      6.249982          0.104000         1188.221191      0.031549   \n",
       "167      6.249982          0.100889         1374.303467      0.011261   \n",
       "169      9.249987          0.608376          457.136444      0.026400   \n",
       "172     12.249977          0.940000          515.356689      0.030130   \n",
       "170     12.249977          0.766938          499.069885      0.011976   \n",
       "171      9.249987          0.533889          499.762878      0.017788   \n",
       "175      6.249982          0.002222         1540.579346      0.010011   \n",
       "\n",
       "     Latency                          date  \n",
       "12      -1.0 2024-05-20 20:26:57.591763496  \n",
       "13      -1.0 2024-05-20 20:26:14.456046343  \n",
       "14      -1.0 2024-05-20 20:24:09.416608095  \n",
       "21      -1.0 2024-05-20 19:38:30.983223438  \n",
       "22      -1.0 2024-05-20 19:36:36.984816551  \n",
       "23      -1.0 2024-05-20 19:35:36.819632053  \n",
       "87      -1.0 2024-05-20 00:21:08.571938038  \n",
       "88      -1.0 2024-05-20 00:20:46.149566889  \n",
       "89      -1.0 2024-05-20 00:06:42.644053936  \n",
       "92      -1.0 2024-05-19 23:29:09.522534609  \n",
       "94      -1.0 2024-05-19 23:28:35.285866499  \n",
       "95      -1.0 2024-05-19 23:27:11.065227509  \n",
       "99      -1.0 2024-05-19 22:51:20.123609066  \n",
       "100     -1.0 2024-05-19 22:49:25.270934343  \n",
       "101     -1.0 2024-05-19 22:48:30.484580517  \n",
       "133     -1.0 2024-05-18 23:35:18.639262915  \n",
       "134     -1.0 2024-05-18 23:24:38.509175777  \n",
       "135     -1.0 2024-05-18 23:21:38.737693071  \n",
       "138     -1.0 2024-05-18 22:50:02.530201197  \n",
       "139     -1.0 2024-05-18 22:43:20.304731369  \n",
       "141     -1.0 2024-05-18 22:43:19.089725494  \n",
       "167     -1.0 2024-05-18 22:25:23.128047943  \n",
       "169     -1.0 2024-05-18 22:24:59.891652107  \n",
       "172     -1.0 2024-05-18 22:12:42.628662109  \n",
       "170     -1.0 2024-05-18 21:42:24.331947088  \n",
       "171     -1.0 2024-05-18 21:42:07.662075043  \n",
       "175     -1.0 2024-05-18 21:41:28.956569910  \n",
       "\n",
       "[27 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_runs_df_deduplicated[all_runs_df_deduplicated[\"compression\"] == \"SparseGPT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>_timestamp</th>\n",
       "      <th>interventions</th>\n",
       "      <th>edit</th>\n",
       "      <th>unlearn</th>\n",
       "      <th>compression</th>\n",
       "      <th>model_name</th>\n",
       "      <th>edit_dataset</th>\n",
       "      <th>number_of_edits</th>\n",
       "      <th>wbits</th>\n",
       "      <th>...</th>\n",
       "      <th>FLOPs</th>\n",
       "      <th>Success recall</th>\n",
       "      <th>Generalization recall</th>\n",
       "      <th>Locality</th>\n",
       "      <th>Average bits</th>\n",
       "      <th>Rewrite accuracy</th>\n",
       "      <th>PPl edits unmasked</th>\n",
       "      <th>Local recall</th>\n",
       "      <th>Latency</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>GPTQ2bit-to-memit</td>\n",
       "      <td>1.716229e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>GPTQ</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.010902</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>1.657478e+05</td>\n",
       "      <td>0.009673</td>\n",
       "      <td>88.586112</td>\n",
       "      <td>2024-05-20 18:13:41.270603180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>GPTQ4bit-to-memit</td>\n",
       "      <td>1.716229e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>GPTQ</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.780238</td>\n",
       "      <td>0.717095</td>\n",
       "      <td>0.033183</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.780238</td>\n",
       "      <td>4.845504e+02</td>\n",
       "      <td>0.034467</td>\n",
       "      <td>87.214703</td>\n",
       "      <td>2024-05-20 18:09:37.249646425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>GPTQ8bit-to-memit</td>\n",
       "      <td>1.716229e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>GPTQ</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.976429</td>\n",
       "      <td>0.885095</td>\n",
       "      <td>0.027154</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>0.976429</td>\n",
       "      <td>4.812392e+02</td>\n",
       "      <td>0.026999</td>\n",
       "      <td>87.147286</td>\n",
       "      <td>2024-05-20 18:09:00.776746988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>AWQ8bit-to-ft</td>\n",
       "      <td>1.716227e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>AWQ</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.845714</td>\n",
       "      <td>0.160518</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.776783e+02</td>\n",
       "      <td>0.159670</td>\n",
       "      <td>91.074401</td>\n",
       "      <td>2024-05-20 17:43:14.585030079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>AWQ4bit-to-ft</td>\n",
       "      <td>1.716227e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>AWQ</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.845714</td>\n",
       "      <td>0.169455</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.407035e+02</td>\n",
       "      <td>0.169852</td>\n",
       "      <td>90.909752</td>\n",
       "      <td>2024-05-20 17:40:15.012472868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>AWQ2bit-to-ft</td>\n",
       "      <td>1.716227e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>AWQ</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.855423e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.894511</td>\n",
       "      <td>2024-05-20 17:38:54.680141449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>AWQ2bit-to-memit</td>\n",
       "      <td>1.716224e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>AWQ</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.074956e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.283724</td>\n",
       "      <td>2024-05-20 17:01:28.464071751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>AWQ4bit-to-memit</td>\n",
       "      <td>1.716224e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>AWQ</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.941762</td>\n",
       "      <td>0.877476</td>\n",
       "      <td>0.035476</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.942641</td>\n",
       "      <td>4.761157e+02</td>\n",
       "      <td>0.033445</td>\n",
       "      <td>91.889338</td>\n",
       "      <td>2024-05-20 17:01:01.431791544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>AWQ8bit-to-memit</td>\n",
       "      <td>1.716224e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>AWQ</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>0.029943</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>5.144988e+02</td>\n",
       "      <td>0.030221</td>\n",
       "      <td>91.659650</td>\n",
       "      <td>2024-05-20 17:00:40.140754700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>GPTQ8bit-to-lora</td>\n",
       "      <td>1.716168e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Lora</td>\n",
       "      <td>None</td>\n",
       "      <td>GPTQ</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.140889</td>\n",
       "      <td>0.045889</td>\n",
       "      <td>0.023484</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.140889</td>\n",
       "      <td>4.293976e+03</td>\n",
       "      <td>0.023364</td>\n",
       "      <td>88.206251</td>\n",
       "      <td>2024-05-20 01:21:30.996167183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>AWQ4bit-to-lora</td>\n",
       "      <td>1.716165e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Lora</td>\n",
       "      <td>None</td>\n",
       "      <td>AWQ</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.674000</td>\n",
       "      <td>0.091904</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.190034e+04</td>\n",
       "      <td>0.092327</td>\n",
       "      <td>88.332665</td>\n",
       "      <td>2024-05-20 00:26:37.579696417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>SparseGPT0.65%-to-lora</td>\n",
       "      <td>1.716164e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Lora</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>625.35 GFLOPS</td>\n",
       "      <td>0.316333</td>\n",
       "      <td>0.195222</td>\n",
       "      <td>0.013377</td>\n",
       "      <td>6.249982</td>\n",
       "      <td>0.316333</td>\n",
       "      <td>1.176053e+03</td>\n",
       "      <td>0.012868</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2024-05-20 00:21:08.571938038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>SparseGPT0.45%-to-lora</td>\n",
       "      <td>1.716164e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Lora</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>982.69 GFLOPS</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>0.329556</td>\n",
       "      <td>0.033835</td>\n",
       "      <td>9.249988</td>\n",
       "      <td>0.711231</td>\n",
       "      <td>1.712821e+03</td>\n",
       "      <td>0.034028</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2024-05-20 00:20:46.149566889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>SparseGPT0.25%-to-lora</td>\n",
       "      <td>1.716164e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Lora</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.34 TFLOPS</td>\n",
       "      <td>0.878667</td>\n",
       "      <td>0.528333</td>\n",
       "      <td>0.036167</td>\n",
       "      <td>12.249977</td>\n",
       "      <td>0.878667</td>\n",
       "      <td>2.798605e+03</td>\n",
       "      <td>0.036143</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2024-05-20 00:06:42.644053936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Wanda0.45%-to-lora</td>\n",
       "      <td>1.716161e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Lora</td>\n",
       "      <td>None</td>\n",
       "      <td>Wanda</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>982.76 GFLOPS</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.451111</td>\n",
       "      <td>0.029763</td>\n",
       "      <td>9.250592</td>\n",
       "      <td>0.813077</td>\n",
       "      <td>1.826007e+03</td>\n",
       "      <td>0.030011</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2024-05-19 23:15:48.294344425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Wanda0.65%-to-lora</td>\n",
       "      <td>1.716160e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Lora</td>\n",
       "      <td>None</td>\n",
       "      <td>Wanda</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>625.49 GFLOPS</td>\n",
       "      <td>0.341889</td>\n",
       "      <td>0.150222</td>\n",
       "      <td>0.028507</td>\n",
       "      <td>6.251183</td>\n",
       "      <td>0.341889</td>\n",
       "      <td>1.061044e+03</td>\n",
       "      <td>0.028355</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2024-05-19 23:14:44.013562202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Wanda0.25%-to-lora</td>\n",
       "      <td>1.716160e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Lora</td>\n",
       "      <td>None</td>\n",
       "      <td>Wanda</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.34 TFLOPS</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.512222</td>\n",
       "      <td>0.046421</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>4.470393e+03</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2024-05-19 23:14:22.782137394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>GPTQ4bit-to-ft</td>\n",
       "      <td>1.716079e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>GPTQ</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.338556</td>\n",
       "      <td>0.176222</td>\n",
       "      <td>0.025550</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.338556</td>\n",
       "      <td>5.004747e+02</td>\n",
       "      <td>0.025288</td>\n",
       "      <td>126.959890</td>\n",
       "      <td>2024-05-19 00:33:46.810805798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>SparseGPT0.65%-to-ft</td>\n",
       "      <td>1.716075e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>759.83 GFLOPS</td>\n",
       "      <td>0.864556</td>\n",
       "      <td>0.488000</td>\n",
       "      <td>0.032478</td>\n",
       "      <td>6.249982</td>\n",
       "      <td>0.864556</td>\n",
       "      <td>9.753676e+02</td>\n",
       "      <td>0.032788</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2024-05-18 23:35:18.639262915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>SparseGPT0.45%-to-ft</td>\n",
       "      <td>1.716075e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.12 TFLOPS</td>\n",
       "      <td>0.968889</td>\n",
       "      <td>0.661667</td>\n",
       "      <td>0.030979</td>\n",
       "      <td>9.249987</td>\n",
       "      <td>0.968889</td>\n",
       "      <td>5.510070e+02</td>\n",
       "      <td>0.030288</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2024-05-18 23:24:38.509175777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>SparseGPT0.25%-to-ft</td>\n",
       "      <td>1.716074e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.47 TFLOPS</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.090888</td>\n",
       "      <td>12.249977</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>5.232146e+02</td>\n",
       "      <td>0.091150</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2024-05-18 23:21:38.737693071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Wanda0.65%-to-ft</td>\n",
       "      <td>1.716072e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>Wanda</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>759.97 GFLOPS</td>\n",
       "      <td>0.477222</td>\n",
       "      <td>0.232222</td>\n",
       "      <td>0.033438</td>\n",
       "      <td>6.251183</td>\n",
       "      <td>0.477222</td>\n",
       "      <td>9.829271e+02</td>\n",
       "      <td>0.032650</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2024-05-18 22:38:38.038841009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Wanda0.45%-to-ft</td>\n",
       "      <td>1.716072e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>Wanda</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.12 TFLOPS</td>\n",
       "      <td>0.936667</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.051999</td>\n",
       "      <td>9.250592</td>\n",
       "      <td>0.936667</td>\n",
       "      <td>4.697008e+02</td>\n",
       "      <td>0.051660</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2024-05-18 22:38:19.358913183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Wanda0.25%-to-ft</td>\n",
       "      <td>1.716071e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>Fine-tune</td>\n",
       "      <td>None</td>\n",
       "      <td>Wanda</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.47 TFLOPS</td>\n",
       "      <td>0.952222</td>\n",
       "      <td>0.740667</td>\n",
       "      <td>0.051188</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>0.952353</td>\n",
       "      <td>4.678279e+02</td>\n",
       "      <td>0.051744</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2024-05-18 22:31:19.300002813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>SparseGPT0.65%-to-memit</td>\n",
       "      <td>1.716071e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>759.83 GFLOPS</td>\n",
       "      <td>0.100889</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.011810</td>\n",
       "      <td>6.249982</td>\n",
       "      <td>0.100889</td>\n",
       "      <td>1.374303e+03</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2024-05-18 22:25:23.128047943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>SparseGPT0.45%-to-memit</td>\n",
       "      <td>1.716071e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.12 TFLOPS</td>\n",
       "      <td>0.608889</td>\n",
       "      <td>0.510556</td>\n",
       "      <td>0.026271</td>\n",
       "      <td>9.249987</td>\n",
       "      <td>0.608376</td>\n",
       "      <td>4.571364e+02</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2024-05-18 22:24:59.891652107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>SparseGPT0.25%-to-memit</td>\n",
       "      <td>1.716070e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>SparseGPT</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.47 TFLOPS</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.029503</td>\n",
       "      <td>12.249977</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>5.153567e+02</td>\n",
       "      <td>0.030130</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2024-05-18 22:12:42.628662109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Wanda0.65%-to-memit</td>\n",
       "      <td>1.716068e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>Wanda</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>759.97 GFLOPS</td>\n",
       "      <td>0.028889</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.030544</td>\n",
       "      <td>6.251183</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>1.160411e+03</td>\n",
       "      <td>0.030150</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2024-05-18 21:33:00.197047710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Wanda0.25%-to-memit</td>\n",
       "      <td>1.716068e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>Wanda</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.47 TFLOPS</td>\n",
       "      <td>0.834889</td>\n",
       "      <td>0.781000</td>\n",
       "      <td>0.032117</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>0.835231</td>\n",
       "      <td>4.133093e+02</td>\n",
       "      <td>0.032459</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2024-05-18 21:30:05.436139584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Wanda0.45%-to-memit</td>\n",
       "      <td>1.716068e+09</td>\n",
       "      <td>[compress, edit]</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>Wanda</td>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>zsre</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.12 TFLOPS</td>\n",
       "      <td>0.700667</td>\n",
       "      <td>0.610556</td>\n",
       "      <td>0.020522</td>\n",
       "      <td>9.250592</td>\n",
       "      <td>0.700154</td>\n",
       "      <td>4.329367e+02</td>\n",
       "      <td>0.021077</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2024-05-18 21:29:51.960963488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         tag    _timestamp     interventions       edit  \\\n",
       "51         GPTQ2bit-to-memit  1.716229e+09  [compress, edit]      MEMIT   \n",
       "62         GPTQ4bit-to-memit  1.716229e+09  [compress, edit]      MEMIT   \n",
       "61         GPTQ8bit-to-memit  1.716229e+09  [compress, edit]      MEMIT   \n",
       "30             AWQ8bit-to-ft  1.716227e+09  [compress, edit]  Fine-tune   \n",
       "32             AWQ4bit-to-ft  1.716227e+09  [compress, edit]  Fine-tune   \n",
       "33             AWQ2bit-to-ft  1.716227e+09  [compress, edit]  Fine-tune   \n",
       "52          AWQ2bit-to-memit  1.716224e+09  [compress, edit]      MEMIT   \n",
       "57          AWQ4bit-to-memit  1.716224e+09  [compress, edit]      MEMIT   \n",
       "58          AWQ8bit-to-memit  1.716224e+09  [compress, edit]      MEMIT   \n",
       "69          GPTQ8bit-to-lora  1.716168e+09  [compress, edit]       Lora   \n",
       "73           AWQ4bit-to-lora  1.716165e+09  [compress, edit]       Lora   \n",
       "87    SparseGPT0.65%-to-lora  1.716164e+09  [compress, edit]       Lora   \n",
       "88    SparseGPT0.45%-to-lora  1.716164e+09  [compress, edit]       Lora   \n",
       "89    SparseGPT0.25%-to-lora  1.716164e+09  [compress, edit]       Lora   \n",
       "91        Wanda0.45%-to-lora  1.716161e+09  [compress, edit]       Lora   \n",
       "90        Wanda0.65%-to-lora  1.716160e+09  [compress, edit]       Lora   \n",
       "93        Wanda0.25%-to-lora  1.716160e+09  [compress, edit]       Lora   \n",
       "118           GPTQ4bit-to-ft  1.716079e+09  [compress, edit]  Fine-tune   \n",
       "133     SparseGPT0.65%-to-ft  1.716075e+09  [compress, edit]  Fine-tune   \n",
       "134     SparseGPT0.45%-to-ft  1.716075e+09  [compress, edit]  Fine-tune   \n",
       "135     SparseGPT0.25%-to-ft  1.716074e+09  [compress, edit]  Fine-tune   \n",
       "136         Wanda0.65%-to-ft  1.716072e+09  [compress, edit]  Fine-tune   \n",
       "137         Wanda0.45%-to-ft  1.716072e+09  [compress, edit]  Fine-tune   \n",
       "140         Wanda0.25%-to-ft  1.716071e+09  [compress, edit]  Fine-tune   \n",
       "167  SparseGPT0.65%-to-memit  1.716071e+09  [compress, edit]      MEMIT   \n",
       "169  SparseGPT0.45%-to-memit  1.716071e+09  [compress, edit]      MEMIT   \n",
       "172  SparseGPT0.25%-to-memit  1.716070e+09  [compress, edit]      MEMIT   \n",
       "173      Wanda0.65%-to-memit  1.716068e+09  [compress, edit]      MEMIT   \n",
       "176      Wanda0.25%-to-memit  1.716068e+09  [compress, edit]      MEMIT   \n",
       "174      Wanda0.45%-to-memit  1.716068e+09  [compress, edit]      MEMIT   \n",
       "\n",
       "    unlearn compression    model_name edit_dataset  number_of_edits  wbits  \\\n",
       "51     None        GPTQ  Llama-3 (8b)         zsre               50    2.0   \n",
       "62     None        GPTQ  Llama-3 (8b)         zsre               50    4.0   \n",
       "61     None        GPTQ  Llama-3 (8b)         zsre               50    8.0   \n",
       "30     None         AWQ  Llama-3 (8b)         zsre               50    8.0   \n",
       "32     None         AWQ  Llama-3 (8b)         zsre               50    4.0   \n",
       "33     None         AWQ  Llama-3 (8b)         zsre               50    2.0   \n",
       "52     None         AWQ  Llama-3 (8b)         zsre               50    2.0   \n",
       "57     None         AWQ  Llama-3 (8b)         zsre               50    4.0   \n",
       "58     None         AWQ  Llama-3 (8b)         zsre               50    8.0   \n",
       "69     None        GPTQ  Llama-3 (8b)         zsre               50    4.0   \n",
       "73     None         AWQ  Llama-3 (8b)         zsre               50    8.0   \n",
       "87     None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "88     None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "89     None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "91     None       Wanda  Llama-3 (8b)         zsre               50    4.0   \n",
       "90     None       Wanda  Llama-3 (8b)         zsre               50    4.0   \n",
       "93     None       Wanda  Llama-3 (8b)         zsre               50    4.0   \n",
       "118    None        GPTQ  Llama-3 (8b)         zsre               50    4.0   \n",
       "133    None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "134    None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "135    None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "136    None       Wanda  Llama-3 (8b)         zsre               50    4.0   \n",
       "137    None       Wanda  Llama-3 (8b)         zsre               50    4.0   \n",
       "140    None       Wanda  Llama-3 (8b)         zsre               50    4.0   \n",
       "167    None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "169    None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "172    None   SparseGPT  Llama-3 (8b)         zsre               50    4.0   \n",
       "173    None       Wanda  Llama-3 (8b)         zsre               50    4.0   \n",
       "176    None       Wanda  Llama-3 (8b)         zsre               50    4.0   \n",
       "174    None       Wanda  Llama-3 (8b)         zsre               50    4.0   \n",
       "\n",
       "     ...          FLOPs  Success recall Generalization recall  Locality  \\\n",
       "51   ...             -1        0.002857              0.005000  0.010902   \n",
       "62   ...             -1        0.780238              0.717095  0.033183   \n",
       "61   ...             -1        0.976429              0.885095  0.027154   \n",
       "30   ...             -1        1.000000              0.845714  0.160518   \n",
       "32   ...             -1        1.000000              0.845714  0.169455   \n",
       "33   ...             -1        0.000000              0.000000  0.000000   \n",
       "52   ...             -1        0.000000              0.000000  0.000000   \n",
       "57   ...             -1        0.941762              0.877476  0.035476   \n",
       "58   ...             -1        0.965000              0.955000  0.029943   \n",
       "69   ...             -1        0.140889              0.045889  0.023484   \n",
       "73   ...             -1        1.000000              0.674000  0.091904   \n",
       "87   ...  625.35 GFLOPS        0.316333              0.195222  0.013377   \n",
       "88   ...  982.69 GFLOPS        0.712000              0.329556  0.033835   \n",
       "89   ...    1.34 TFLOPS        0.878667              0.528333  0.036167   \n",
       "91   ...  982.76 GFLOPS        0.813333              0.451111  0.029763   \n",
       "90   ...  625.49 GFLOPS        0.341889              0.150222  0.028507   \n",
       "93   ...    1.34 TFLOPS        0.930000              0.512222  0.046421   \n",
       "118  ...             -1        0.338556              0.176222  0.025550   \n",
       "133  ...  759.83 GFLOPS        0.864556              0.488000  0.032478   \n",
       "134  ...    1.12 TFLOPS        0.968889              0.661667  0.030979   \n",
       "135  ...    1.47 TFLOPS        0.995000              0.666667  0.090888   \n",
       "136  ...  759.97 GFLOPS        0.477222              0.232222  0.033438   \n",
       "137  ...    1.12 TFLOPS        0.936667              0.650000  0.051999   \n",
       "140  ...    1.47 TFLOPS        0.952222              0.740667  0.051188   \n",
       "167  ...  759.83 GFLOPS        0.100889              0.040000  0.011810   \n",
       "169  ...    1.12 TFLOPS        0.608889              0.510556  0.026271   \n",
       "172  ...    1.47 TFLOPS        0.940000              0.910000  0.029503   \n",
       "173  ...  759.97 GFLOPS        0.028889              0.026667  0.030544   \n",
       "176  ...    1.47 TFLOPS        0.834889              0.781000  0.032117   \n",
       "174  ...    1.12 TFLOPS        0.700667              0.610556  0.020522   \n",
       "\n",
       "     Average bits  Rewrite accuracy  PPl edits unmasked  Local recall  \\\n",
       "51       2.250000          0.003333        1.657478e+05      0.009673   \n",
       "62       4.250000          0.780238        4.845504e+02      0.034467   \n",
       "61       8.250000          0.976429        4.812392e+02      0.026999   \n",
       "30       8.250000          1.000000        7.776783e+02      0.159670   \n",
       "32       4.250000          1.000000        5.407035e+02      0.169852   \n",
       "33       2.250000          0.000000        7.855423e+04      0.000000   \n",
       "52       2.250000          0.000000        1.074956e+06      0.000000   \n",
       "57       4.250000          0.942641        4.761157e+02      0.033445   \n",
       "58       8.250000          0.965000        5.144988e+02      0.030221   \n",
       "69       4.250000          0.140889        4.293976e+03      0.023364   \n",
       "73       8.250000          1.000000        1.190034e+04      0.092327   \n",
       "87       6.249982          0.316333        1.176053e+03      0.012868   \n",
       "88       9.249988          0.711231        1.712821e+03      0.034028   \n",
       "89      12.249977          0.878667        2.798605e+03      0.036143   \n",
       "91       9.250592          0.813077        1.826007e+03      0.030011   \n",
       "90       6.251183          0.341889        1.061044e+03      0.028355   \n",
       "93      12.250000          0.930000        4.470393e+03      0.046528   \n",
       "118      4.250000          0.338556        5.004747e+02      0.025288   \n",
       "133      6.249982          0.864556        9.753676e+02      0.032788   \n",
       "134      9.249987          0.968889        5.510070e+02      0.030288   \n",
       "135     12.249977          0.995000        5.232146e+02      0.091150   \n",
       "136      6.251183          0.477222        9.829271e+02      0.032650   \n",
       "137      9.250592          0.936667        4.697008e+02      0.051660   \n",
       "140     12.250000          0.952353        4.678279e+02      0.051744   \n",
       "167      6.249982          0.100889        1.374303e+03      0.011261   \n",
       "169      9.249987          0.608376        4.571364e+02      0.026400   \n",
       "172     12.249977          0.940000        5.153567e+02      0.030130   \n",
       "173      6.251183          0.029333        1.160411e+03      0.030150   \n",
       "176     12.250000          0.835231        4.133093e+02      0.032459   \n",
       "174      9.250592          0.700154        4.329367e+02      0.021077   \n",
       "\n",
       "        Latency                          date  \n",
       "51    88.586112 2024-05-20 18:13:41.270603180  \n",
       "62    87.214703 2024-05-20 18:09:37.249646425  \n",
       "61    87.147286 2024-05-20 18:09:00.776746988  \n",
       "30    91.074401 2024-05-20 17:43:14.585030079  \n",
       "32    90.909752 2024-05-20 17:40:15.012472868  \n",
       "33    90.894511 2024-05-20 17:38:54.680141449  \n",
       "52    90.283724 2024-05-20 17:01:28.464071751  \n",
       "57    91.889338 2024-05-20 17:01:01.431791544  \n",
       "58    91.659650 2024-05-20 17:00:40.140754700  \n",
       "69    88.206251 2024-05-20 01:21:30.996167183  \n",
       "73    88.332665 2024-05-20 00:26:37.579696417  \n",
       "87    -1.000000 2024-05-20 00:21:08.571938038  \n",
       "88    -1.000000 2024-05-20 00:20:46.149566889  \n",
       "89    -1.000000 2024-05-20 00:06:42.644053936  \n",
       "91    -1.000000 2024-05-19 23:15:48.294344425  \n",
       "90    -1.000000 2024-05-19 23:14:44.013562202  \n",
       "93    -1.000000 2024-05-19 23:14:22.782137394  \n",
       "118  126.959890 2024-05-19 00:33:46.810805798  \n",
       "133   -1.000000 2024-05-18 23:35:18.639262915  \n",
       "134   -1.000000 2024-05-18 23:24:38.509175777  \n",
       "135   -1.000000 2024-05-18 23:21:38.737693071  \n",
       "136   -1.000000 2024-05-18 22:38:38.038841009  \n",
       "137   -1.000000 2024-05-18 22:38:19.358913183  \n",
       "140   -1.000000 2024-05-18 22:31:19.300002813  \n",
       "167   -1.000000 2024-05-18 22:25:23.128047943  \n",
       "169   -1.000000 2024-05-18 22:24:59.891652107  \n",
       "172   -1.000000 2024-05-18 22:12:42.628662109  \n",
       "173   -1.000000 2024-05-18 21:33:00.197047710  \n",
       "176   -1.000000 2024-05-18 21:30:05.436139584  \n",
       "174   -1.000000 2024-05-18 21:29:51.960963488  \n",
       "\n",
       "[30 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(categories[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEdit to Compression\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m32\u001b[39m \u001b[38;5;66;03m# Should be 36 Missing LoRA Quant\u001b[39;00m\n\u001b[1;32m     23\u001b[0m display(categories[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompression to Edit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(categories[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompression to Edit\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = all_runs_df_deduplicated\n",
    "# print(data[\"interventions\"])\n",
    "# Select rows where the \"interventions\" column is exactly [\"edit\"]\n",
    "temp = data[data[\"interventions\"].apply(lambda x: x == [\"edit\", \"compress\"])]\n",
    "\n",
    "categories = {\n",
    "    \"No Intervention\": data[data[\"interventions\"].apply(lambda x: x == [])].copy(),\n",
    "    \"Editing\": data[data[\"interventions\"].apply(lambda x: x == [\"edit\"])].copy(),\n",
    "    \"Compression\": data[data[\"interventions\"].apply(lambda x: x == [\"compress\"])].copy(),\n",
    "    \"Edit to Compression\": data[data[\"interventions\"].apply(lambda x: x == [\"edit\", \"compress\"])].copy(),\n",
    "    \"Compression to Edit\": data[data[\"interventions\"].apply(lambda x: x == [\"compress\", \"edit\"])].copy(),\n",
    "    \"Unlearn\": data[data[\"interventions\"].apply(lambda x: x == [\"unlearn\"])].copy(),\n",
    "    \"Edit to Unlearn\": data[data[\"interventions\"].apply(lambda x: x == [\"edit\", \"unlearn\"])].copy(),\n",
    "    \"Unlearn to Edit\": data[data[\"interventions\"].apply(lambda x: x == [\"unlearn\", \"edit\"])].copy(),\n",
    "    \"Compress to Unlearn\": data[data[\"interventions\"].apply(lambda x: x == [\"compress\", \"unlearn\"])].copy(),\n",
    "    \"Unlearn to Compress\": data[data[\"interventions\"].apply(lambda x: x == [\"unlearn\", \"compress\"])].copy()\n",
    "}\n",
    "\n",
    "assert len(categories[\"No Intervention\"]) == 0 # Should be 1\n",
    "assert len(categories[\"Editing\"]) == 3 \n",
    "assert len(categories[\"Compression\"]) == 12\n",
    "assert len(categories[\"Edit to Compression\"]) == 32 # Should be 36 Missing LoRA Quant\n",
    "display(categories[\"Compression to Edit\"])\n",
    "assert len(categories[\"Compression to Edit\"]) == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_flops(value):\n",
    "    \"\"\" Format FLOPs with three significant figures and appropriate suffix. \"\"\"\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            value = clean_numeric_value(value)\n",
    "        if abs(value) < 1e6:  # Less than 1 million (below Mega)\n",
    "            return \"{:.3g}k\".format(value / 1e3)\n",
    "        elif abs(value) < 1e9:  # Mega to Giga range\n",
    "            return \"{:.3g}M\".format(value / 1e6)\n",
    "        elif abs(value) < 1e12:  # Giga to Tera range\n",
    "            return \"{:.3g}G\".format(value / 1e9)\n",
    "        else:  # Tera and above\n",
    "            return \"{:.3g}T\".format(value / 1e12)\n",
    "    except Exception as e:\n",
    "        print(f\"Error formatting FLOPs value {value}: {e}\")\n",
    "        return \"---\"\n",
    "\n",
    "def escape_latex_special_chars(s):\n",
    "    \"\"\" Escape special characters in LaTeX strings. \"\"\"\n",
    "    return str(s).replace('%', '\\\\%').replace('_', '\\\\_').replace('&', '\\\\&').replace('#', '\\\\#').replace('$', '\\\\$')\n",
    "\n",
    "def clean_numeric_value(value):\n",
    "    \"\"\" Convert a string with units to a numeric value. \"\"\"\n",
    "    try:\n",
    "        value = str(value)\n",
    "        if ' TFLOPS' in value:\n",
    "            return float(value.replace(' TFLOPS', '')) * 1e12\n",
    "        if ' GFLOPS' in value:\n",
    "            return float(value.replace(' GFLOPS', '')) * 1e9\n",
    "        if ' MFLOPS' in value:\n",
    "            return float(value.replace(' MFLOPS', '')) * 1e6\n",
    "        if ' kFLOPS' in value:\n",
    "            return float(value.replace(' kFLOPS', '')) * 1e3\n",
    "        return pd.to_numeric(value, errors='coerce')\n",
    "    except Exception as e:\n",
    "        print(f\"Error cleaning value {value}: {e}\")\n",
    "        return pd.NA\n",
    "\n",
    "def categorize_and_generate_latex(data):\n",
    "    # Define categories based on the provided criteria\n",
    "    categories = {\n",
    "    \"No Intervention\": data[data['interventions'].apply(lambda x: x == [])].copy(),\n",
    "    \"Editing\": data[data['interventions'].apply(lambda x: x == ['edit'])].copy(),\n",
    "    \"Compression\": data[data['interventions'].apply(lambda x: x == ['compress'])].copy(),\n",
    "    \"Edit to Compression\": data[data['interventions'].apply(lambda x: x == ['edit', 'compress'])].copy(),\n",
    "    \"Compression to Edit\": data[data['interventions'].apply(lambda x: x == ['compress', 'edit'])].copy(),\n",
    "    \"Unlearn\": data[data['interventions'].apply(lambda x: x == ['unlearn'])].copy(),\n",
    "    \"Edit to Unlearn\": data[data['interventions'].apply(lambda x: x == ['edit', 'unlearn'])].copy(),\n",
    "    \"Unlearn to Edit\": data[data['interventions'].apply(lambda x: x == ['unlearn', 'edit'])].copy(),\n",
    "    \"Compress to Unlearn\": data[data['interventions'].apply(lambda x: x == ['compress', 'unlearn'])].copy(),\n",
    "    \"Unlearn to Compress\": data[data['interventions'].apply(lambda x: x == ['unlearn', 'compress'])].copy()\n",
    "}\n",
    "    # Clean numeric columns\n",
    "    for col in [\"FLOPs\", \"Latency\"]:\n",
    "        if col in data.columns:\n",
    "            data.loc[:, col] = data[col].apply(clean_numeric_value)\n",
    "            data.loc[:, col] = pd.to_numeric(data[col], errors='coerce')  # Ensure all values are numeric\n",
    "\n",
    "    # Column mappings\n",
    "    column_mappings = {\n",
    "        \"Success\": \"Rewrite accuracy\",\n",
    "        \"Generalization\": \"Generalization\",\n",
    "        \"Locality\": \"Locality\",\n",
    "        \"Avg. Bits\": \"Average bits\",\n",
    "        \"FLOPs\": \"FLOPs\",\n",
    "        \"PPL\": \"PPL\",\n",
    "        \"MMLU\": \"mmlu accuracy\",\n",
    "        \"WMDP Bio\": \"wmdp_bio accuracy\",\n",
    "        \"WMDP Cyber\": \"wmdp_cyber accuracy\"\n",
    "    }\n",
    "    latex_columns = [\"Success\", \"Generalization\", \"Locality\", \"Avg. Bits\", \"FLOPs\", \"PPL\", \"MMLU\", \"WMDP Bio\", \"WMDP Cyber\"]\n",
    "\n",
    "    # Initialize output string\n",
    "    output_str = \"\"\n",
    "\n",
    "    for category, group in categories.items():\n",
    "        if group.empty:\n",
    "            continue\n",
    "        # output_str += f\"\\\\textbf{{{category}}} \\\\\\\\ \\\\midline\\n\"\n",
    "        for _, row in group.iterrows():\n",
    "            # Calculate mean and std for each relevant column within the group\n",
    "            stats = {}\n",
    "            for latex_col, csv_col in column_mappings.items():\n",
    "                if csv_col in row.index:\n",
    "                    value = row[csv_col]\n",
    "                    if pd.isna(value):\n",
    "                        stats[latex_col] = \"---\"\n",
    "                    else:\n",
    "                        # Custom formatting for FLOPs and Latency\n",
    "                        if latex_col == \"FLOPs\":\n",
    "                            mean_str = format_flops(value)\n",
    "                            stats[latex_col] = escape_latex_special_chars(mean_str)\n",
    "                        elif latex_col == \"Latency\":\n",
    "                            mean_str = f\"{value:.3f}s\"\n",
    "                            stats[latex_col] = escape_latex_special_chars(mean_str)\n",
    "                        else:\n",
    "                            mean_str = f\"{value:.3f}\"\n",
    "                            stats[latex_col] = escape_latex_special_chars(mean_str)\n",
    "                else:\n",
    "                    stats[latex_col] = \"---\"\n",
    "\n",
    "            # Prepare the LaTeX row for the current group\n",
    "            latex_row = escape_latex_special_chars(row['tag'])  # Use the tag name directly without escaping\n",
    "            for column in latex_columns:\n",
    "                latex_row += \" & \" + stats.get(column, \"---\")\n",
    "            latex_row += \" \\\\\\\\\"\n",
    "\n",
    "            # Append to output string\n",
    "            output_str += latex_row + \"\\n\"\n",
    "        \n",
    "        output_str += \"\\\\midrule\\n\"\n",
    "\n",
    "    return output_str\n",
    "\n",
    "latex_rows_with_categories = categorize_and_generate_latex(all_runs_df_deduplicated)\n",
    "print(latex_rows_with_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the font family to serif\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "# Assuming 'metrics' DataFrame is already loaded from the CSV\n",
    "\n",
    "# Define the criteria for filtering\n",
    "selected_method = 'AWQ'\n",
    "edit_method = [\"FT\"]\n",
    "\n",
    "# Filter based on the criteria\n",
    "edit_then_compress = categories['Edit to Compression']\n",
    "compress_then_edit = categories['Compression to Edit']\n",
    "\n",
    "# Filter based on selected method\n",
    "edit_then_compress = edit_then_compress[edit_then_compress['compression']==selected_method]\n",
    "compress_then_edit = compress_then_edit[compress_then_edit['compression']==selected_method]\n",
    "\n",
    "# Add baselines to dfs\n",
    "baseline = categories['Editing']\n",
    "baseline['wbits'] = 16\n",
    "edit_then_compress = pd.concat([edit_then_compress, baseline], axis=0)\n",
    "compress_then_edit = pd.concat([compress_then_edit, baseline], axis=0)\n",
    "\n",
    "# Sort by 'wbits' in ascending order\n",
    "edit_then_compress = edit_then_compress.sort_values(by='wbits')\n",
    "compress_then_edit = compress_then_edit.sort_values(by='wbits')\n",
    "\n",
    "# Define the metrics to plot\n",
    "metrics_to_plot = ['Rewrite accuracy', 'Generalization', 'mmlu']\n",
    "x_axis_metric = 'wbits'\n",
    "\n",
    "# Compute baselines\n",
    "# edit_then_compress_baselines = {model: edit_then_compress[(edit_then_compress['model_name'] == model) & (edit_then_compress['sparsity_ratio'] == 0)][metrics_to_plot].mean() for model in included_models}\n",
    "# compress_then_edit_baselines = {model: compress_then_edit[(compress_then_edit['model_name'] == model) & (compress_then_edit['sparsity_ratio'] == 0)][metrics_to_plot].mean() for model in included_models}\n",
    "# edit_then_compress_baselines = categories['No Intervention']\n",
    "# compress_then_edit_baselines = categories['No Intervention']\n",
    "\n",
    "# Define plot parameters\n",
    "title_fontsize = 20\n",
    "label_fontsize = 20\n",
    "legend_fontsize = 18\n",
    "tick_fontsize = 18\n",
    "line_width = 3\n",
    "marker_size = 8\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, len(metrics_to_plot), figsize=(15, 5))\n",
    "\n",
    "# Iterate over each metric and plot\n",
    "for i, metric in enumerate(metrics_to_plot):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot the data with scatter and lines\n",
    "    ax.plot(edit_then_compress['wbits'], edit_then_compress[metric], linestyle='--', marker='o', markerfacecolor='purple', color='purple', label='Edit then compress',\n",
    "            linewidth=line_width, markersize=marker_size, markeredgewidth=line_width)\n",
    "    ax.plot(compress_then_edit['wbits'], compress_then_edit[metric], linestyle='-', marker='o', markerfacecolor='none', color='purple', label='Compress then edit',\n",
    "            linewidth=line_width, markersize=marker_size, markeredgewidth=line_width)\n",
    "    \n",
    "    # Fill the area between the lines\n",
    "    ax.fill_between(edit_then_compress['wbits'], edit_then_compress[metric], compress_then_edit[metric], color='purple', alpha=0.2)\n",
    "    \n",
    "    # Integrate baselines into the scatter plots\n",
    "    for model in included_models:\n",
    "        baseline_edit = edit_then_compress_baselines[metric]\n",
    "        baseline_compress = compress_then_edit_baselines[metric]\n",
    "        \n",
    "        if x_axis_metric == 'Average bits':\n",
    "            baseline_x = 16\n",
    "            ax.set_xlim(2, 16)\n",
    "        elif x_axis_metric == 'sparsity_ratio':\n",
    "            baseline_x = 0.0\n",
    "            ax.set_xlim(0, 1)\n",
    "        else:\n",
    "            baseline_x = 0  # Adjust based on your default x-axis range\n",
    "\n",
    "        # Add baselines to the scatter plots\n",
    "        # ax.scatter([baseline_x], [baseline_edit], color='purple', marker='o', s=marker_size**2, edgecolor='purple', linewidth=line_width)\n",
    "        # ax.scatter([baseline_x], [baseline_compress], color='purple', marker='o', s=marker_size**2, edgecolor='purple', linewidth=line_width)\n",
    "    if x_axis_metric == 'wbits':\n",
    "        ax.set_xlabel('Bits', fontsize=label_fontsize)\n",
    "    else:\n",
    "        ax.set_xlabel(x_axis_metric, fontsize=label_fontsize)\n",
    "    if metric == 'Rewrite accuracy':\n",
    "        ax.set_ylabel('Edit success', fontsize=label_fontsize)\n",
    "    else:\n",
    "        ax.set_ylabel(metric, fontsize=label_fontsize)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "\n",
    "# Move the legend to the bottom of the figure\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', fontsize=legend_fontsize, ncol=2)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.1, 1, 1])  # Adjust the bottom margin to make space for the legend\n",
    "plt.show()\n",
    "plt.savefig('figures/memit-gptq.pdf', format='pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
