#!/bin/bash
#SBATCH --partition=a100
#SBATCH --job-name=qwen_gptq_awq
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --gpus-per-node=1
#SBATCH --cpus-per-task=8
#SBATCH --time=12:00:00
#SBATCH --mem=128G
#SBATCH --output=logs/qwen2.5-32b-instruct/output_qwen_quant.log
#SBATCH --error=logs/qwen2.5-32b-instruct/error_qwen_quant.log

LOG_DIR=logs/qwen2.5-32b-instruct
OUT_LOG=$LOG_DIR/output_qwen_quant.log
ERR_LOG=$LOG_DIR/error_qwen_quant.log

mkdir -p "$LOG_DIR"
: > "$OUT_LOG"
: > "$ERR_LOG"

set -eEuo pipefail
trap 'echo "âŒ ä»»åŠ¡å¤±è´¥: è¡Œå· $LINENOï¼Œé€€å‡ºç  $?"; exit 1' ERR

echo "ğŸ” ä»»åŠ¡å¼€å§‹: $(date)"
echo "ğŸ“‚ å½“å‰ç›®å½•: $(pwd)"
cd "$SLURM_SUBMIT_DIR" || { echo "âŒ æ— æ³•è¿›å…¥æäº¤ç›®å½•ï¼Œé€€å‡º"; exit 1; }

# ===== åŠ è½½ Apptainer æ¨¡å— =====
if [ -f /etc/profile.d/modules.sh ]; then
    source /etc/profile.d/modules.sh || true
    module load apptainer || echo "âš ï¸ æ— æ³•åŠ è½½ apptainerï¼Œç¡®ä¿å·²å®‰è£…"
fi

# ===== æ„å»ºé•œåƒï¼ˆä»…å½“å¿…è¦æ—¶ï¼‰=====
DEF_FILE="build_apptainer/qwen-compression.def"
SIF_FILE="build_apptainer/qwen-compression.sif"

if [ ! -f "$SIF_FILE" ] || [ "$DEF_FILE" -nt "$SIF_FILE" ]; then
    echo "ğŸ“¦ æ„å»ºå®¹å™¨é•œåƒ: $SIF_FILE"
    apptainer build --force "$SIF_FILE" "$DEF_FILE"
else
    echo "âœ… é•œåƒå·²æ˜¯æœ€æ–°: $SIF_FILE"
fi

# ===== æ¨¡å‹ä¸è¾“å‡ºè·¯å¾„ =====
REMOTE_MODEL="Qwen/Qwen2.5-32B-Instruct"
# ===== æ¨¡å‹ä¸è¾“å‡ºè·¯å¾„ =====
# LOCAL_MODEL="/mnt/fast/nobackup/scratch4weeks/ly0008/ysh/composable-interventions/models/Qwen2.5-32B-Instruct"
WORKDIR="$SLURM_SUBMIT_DIR"
OUTPUT_DIR_GPTQ="$WORKDIR/compressed_models/qwen2.5-32b-gptq"
OUTPUT_DIR_AWQ="$WORKDIR/compressed_models/qwen2.5-32b-awq"

# ===== GPTQ å‹ç¼© =====
echo "ğŸš€ å¼€å§‹ GPTQ å‹ç¼©..."
apptainer exec --nv "$SIF_FILE" bash -c "
    source /opt/conda/etc/profile.d/conda.sh &&
    conda activate qwen-compression &&
    export TRANSFORMERS_CACHE=/tmp/hf_cache &&
    export HF_HOME=/tmp/hf_cache &&
    export PYTHONPATH=/opt/app &&
    python /opt/app/main_quantize.py \
        --method quant \
        --quant_method autogptq \
        --model '$REMOTE_MODEL' \
        --save_model '$OUTPUT_DIR_GPTQ' \
        --wbits 4 \
        --groupsize 128
"

# ===== AWQ å‹ç¼© =====
echo "ğŸš€ å¼€å§‹ AWQ å‹ç¼©..."
apptainer exec --nv "$SIF_FILE" bash -c "
    source /opt/conda/etc/profile.d/conda.sh &&
    conda activate qwen-compression &&
    export TRANSFORMERS_CACHE=/tmp/hf_cache &&
    export HF_HOME=/tmp/hf_cache &&
    export PYTHONPATH=/opt/app &&
    python /opt/app/main_quantize.py \
        --method quant \
        --quant_method autoawq \
        --model '$REMOTE_MODEL' \
        --save_model '$OUTPUT_DIR_AWQ' \
        --wbits 4 \
        --groupsize 128 \
        --zero_point
"
